This is sicp, produced by makeinfo version 4.13 from sicp.texi.

INFO-DIR-SECTION The Algorithmic Language Scheme
START-INFO-DIR-ENTRY
* SICP: (sicp). Structure and Interpretation of Computer Programs
END-INFO-DIR-ENTRY


File: sicp,  Node: 2-2-4,  Prev: 2-2-3,  Up: 2-2

2.2.4 Example: A Picture Language
---------------------------------

This section presents a simple language for drawing pictures that
illustrates the power of data abstraction and closure, and also
exploits higher-order procedures in an essential way.  The language is
designed to make it easy to experiment with patterns such as the ones
in *note Figure 2-9::, which are composed of repeated elements that are
shifted and scaled.(1) In this language, the data objects being
combined are represented as procedures rather than as list structure.
Just as `cons', which satisfies the closure property, allowed us to
easily build arbitrarily complicated list structure, the operations in
this language, which also satisfy the closure property, allow us to
easily build arbitrarily complicated patterns.

     *Figure 2.9:* Designs generated with the picture language.

     [two graphic images not included]

The picture language
....................

When we began our study of programming in section *note 1-1::, we
emphasized the importance of describing a language by focusing on the
language's primitives, its means of combination, and its means of
abstraction.  We'll follow that framework here.

   Part of the elegance of this picture language is that there is only
one kind of element, called a "painter".  A painter draws an image that
is shifted and scaled to fit within a designated parallelogram-shaped
frame.  For example, there's a primitive painter we'll call `wave' that
makes a crude line drawing, as shown in *note Figure 2-10::.  The
actual shape of the drawing depends on the frame--all four images in
*note Figure 2-10:: are produced by the same `wave' painter, but with
respect to four different frames.  Painters can be more elaborate than
this: The primitive painter called `rogers' paints a picture of MIT's
founder, William Barton Rogers, as shown in *note Figure 2-11::.(2) The
four images in *note Figure 2-11:: are drawn with respect to the same
four frames as the `wave' images in *note Figure 2-10::.

   To combine images, we use various operations that construct new
painters from given painters.  For example, the `beside' operation
takes two painters and produces a new, compound painter that draws the
first painter's image in the left half of the frame and the second
painter's image in the right half of the frame.  Similarly, `below'
takes two painters and produces a compound painter that draws the first
painter's image below the second painter's image.  Some operations
transform a single painter to produce a new painter.  For example,
`flip-vert' takes a painter and produces a painter that draws its image
upside-down, and `flip-horiz' produces a painter that draws the
original painter's image left-to-right reversed.

     *Figure 2.10:* Images produced by the `wave' painter, with respect
     to four different frames.  The frames, shown with dotted lines,
     are not part of the images.

     [four graphic images not included]

     *Figure 2.11:* Images of William Barton Rogers, founder and first
     president of MIT, painted with respect to the same four frames as
     in *note Figure 2-10:: (original image reprinted with the
     permission of the MIT Museum).

     [four graphic images not included]

   *note Figure 2-12:: shows the drawing of a painter called `wave4'
that is built up in two stages starting from `wave':

     (define wave2 (beside wave (flip-vert wave)))
     (define wave4 (below wave2 wave2))

     *Figure 2.12:* Creating a complex figure, starting from the `wave'
     painter of *note Figure 2-10::.

     [two graphic images not included]

          (define wave2                         (define wave4
            (beside wave (flip-vert wave)))       (below wave2 wave2))

   In building up a complex image in this manner we are exploiting the
fact that painters are closed under the language's means of
combination.  The `beside' or `below' of two painters is itself a
painter; therefore, we can use it as an element in making more complex
painters.  As with building up list structure using `cons', the closure
of our data under the means of combination is crucial to the ability to
create complex structures while using only a few operations.

   Once we can combine painters, we would like to be able to abstract
typical patterns of combining painters.  We will implement the painter
operations as Scheme procedures.  This means that we don't need a
special abstraction mechanism in the picture language: Since the means
of combination are ordinary Scheme procedures, we automatically have
the capability to do anything with painter operations that we can do
with procedures.  For example, we can abstract the pattern in `wave4' as

     (define (flipped-pairs painter)
       (let ((painter2 (beside painter (flip-vert painter))))
         (below painter2 painter2)))

and define `wave4' as an instance of this pattern:

     (define wave4 (flipped-pairs wave))

   We can also define recursive operations.  Here's one that makes
painters split and branch towards the right as shown in figures *note
Figure 2-13:: and *note Figure 2-14:::

     (define (right-split painter n)
       (if (= n 0)
           painter
           (let ((smaller (right-split painter (- n 1))))
             (beside painter (below smaller smaller)))))

     *Figure 2.13:* Recursive plans for `right-split' and
     `corner-split'.

          +-------------+-------------+    +------+------+-------------+
          |             |             |    | up-  | up-  |             |
          |             | right-split |    | split| split| corner-split|
          |             |             |    |      |      |             |
          |             |     n-1     |    |  n-1 |  n-1 |     n-1     |
          |             |             |    |      |      |             |
          |  identity   +-------------+    +------+------+-------------+
          |             |             |    |             | right-split |
          |             | right-split |    |             |     n-1     |
          |             |             |    |  identity   +-------------+
          |             |     n-1     |    |             | right-split |
          |             |             |    |             |     n-1     |
          +-------------+-------------+    +-------------+-------------+

                 right-split n                    corner-split n

   We can produce balanced patterns by branching upwards as well as
towards the right (see *note Exercise 2-44:: and figures *note Figure
2-13:: and *note Figure 2-14::):

     (define (corner-split painter n)
       (if (= n 0)
           painter
           (let ((up (up-split painter (- n 1)))
                 (right (right-split painter (- n 1))))
             (let ((top-left (beside up up))
                   (bottom-right (below right right))
                   (corner (corner-split painter (- n 1))))
               (beside (below painter top-left)
                       (below bottom-right corner))))))

     *Figure 2.14:* The recursive operations `right-split' and
     `corner-split' applied to the painters `wave' and `rogers'.
     Combining four `corner-split' figures produces symmetric
     `square-limit' designs as shown in *note Figure 2-9::.

     [two graphic images not included]

          (right-split wave 4)         (right-split rogers 4)

     [two graphic images not included]

          (corner-split wave 4)        (corner-split rogers 4)

   By placing four copies of a `corner-split' appropriately, we obtain a
pattern called `square-limit', whose application to `wave' and `rogers'
is shown in *note Figure 2-9:::

     (define (square-limit painter n)
       (let ((quarter (corner-split painter n)))
         (let ((half (beside (flip-horiz quarter) quarter)))
           (below (flip-vert half) half))))

     *Exercise 2.44:* Define the procedure `up-split' used by
     `corner-split'.  It is similar to `right-split', except that it
     switches the roles of `below' and `beside'.

Higher-order operations
.......................

In addition to abstracting patterns of combining painters, we can work
at a higher level, abstracting patterns of combining painter
operations.  That is, we can view the painter operations as elements to
manipulate and can write means of combination for these
elements--procedures that take painter operations as arguments and
create new painter operations.

   For example, `flipped-pairs' and `square-limit' each arrange four
copies of a painter's image in a square pattern; they differ only in
how they orient the copies.  One way to abstract this pattern of
painter combination is with the following procedure, which takes four
one-argument painter operations and produces a painter operation that
transforms a given painter with those four operations and arranges the
results in a square.  `Tl', `tr', `bl', and `br' are the
transformations to apply to the top left copy, the top right copy, the
bottom left copy, and the bottom right copy, respectively.

     (define (square-of-four tl tr bl br)
       (lambda (painter)
         (let ((top (beside (tl painter) (tr painter)))
               (bottom (beside (bl painter) (br painter))))
           (below bottom top))))

   Then `flipped-pairs' can be defined in terms of `square-of-four' as
follows:(3)

     (define (flipped-pairs painter)
       (let ((combine4 (square-of-four identity flip-vert
                                       identity flip-vert)))
         (combine4 painter)))

and `square-limit' can be expressed as(4)

     (define (square-limit painter n)
       (let ((combine4 (square-of-four flip-horiz identity
                                       rotate180 flip-vert)))
         (combine4 (corner-split painter n))))

     *Exercise 2.45:* `Right-split' and `up-split' can be expressed as
     instances of a general splitting operation.  Define a procedure
     `split' with the property that evaluating

          (define right-split (split beside below))
          (define up-split (split below beside))

     produces procedures `right-split' and `up-split' with the same
     behaviors as the ones already defined.

Frames
......

Before we can show how to implement painters and their means of
combination, we must first consider frames.  A frame can be described
by three vectors--an origin vector and two edge vectors.  The origin
vector specifies the offset of the frame's origin from some absolute
origin in the plane, and the edge vectors specify the offsets of the
frame's corners from its origin.  If the edges are perpendicular, the
frame will be rectangular.  Otherwise the frame will be a more general
parallelogram.

   *note Figure 2-15:: shows a frame and its associated vectors.  In
accordance with data abstraction, we need not be specific yet about how
frames are represented, other than to say that there is a constructor
`make-frame', which takes three vectors and produces a frame, and three
corresponding selectors `origin-frame', `edge1-frame', and
`edge2-frame' (see *note Exercise 2-47::).

     *Figure 2.15:* A frame is described by three vectors - an origin
     and two edges.

                                   __
                               __--  \
                           __--       \
                __     __--            \   __
               |\  __--                 \__-|
                 \-                  __--
          frame   \              __--
          edge2    \         __--    frame
          vector    \    __--        edge1
                     \_--            vector
                      -   <--+
                    frame    |
                    origin   +-- (0,0) point
                    vector       on display screen

   We will use coordinates in the unit square (0<= x,y<= 1) to specify
images.  With each frame, we associate a "frame coordinate map", which
will be used to shift and scale images to fit the frame.  The map
transforms the unit square into the frame by mapping the vector v =
(x,y) to the vector sum

     Origin(Frame) + r * Edge_1(Frame) + y * Edge_2(Frame)

For example, (0,0) is mapped to the origin of the frame, (1,1) to the
vertex diagonally opposite the origin, and (0.5,0.5) to the center of
the frame.  We can create a frame's coordinate map with the following
procedure:(5)

     (define (frame-coord-map frame)
       (lambda (v)
         (add-vect
          (origin-frame frame)
          (add-vect (scale-vect (xcor-vect v)
                                (edge1-frame frame))
                    (scale-vect (ycor-vect v)
                                (edge2-frame frame))))))

   Observe that applying `frame-coord-map' to a frame returns a
procedure that, given a vector, returns a vector.  If the argument
vector is in the unit square, the result vector will be in the frame.
For example,

     ((frame-coord-map a-frame) (make-vect 0 0))

returns the same vector as

     (origin-frame a-frame)

     *Exercise 2.46:* A two-dimensional vector v running from the
     origin to a point can be represented as a pair consisting of an
     x-coordinate and a y-coordinate.  Implement a data abstraction for
     vectors by giving a constructor `make-vect' and corresponding
     selectors `xcor-vect' and `ycor-vect'.  In terms of your selectors
     and constructor, implement procedures `add-vect', `sub-vect', and
     `scale-vect' that perform the operations vector addition, vector
     subtraction, and multiplying a vector by a scalar:

          (x_1, y_1) + (x_2, y_2) = (x_1 + x_2, y_1 + y_2)
          (x_1, y_1) - (x_2, y_2) = (x_1 - x_2, y_1 - y_2)
                       s * (x, y) = (sx, sy)

     *Exercise 2.47:* Here are two possible constructors for frames:

          (define (make-frame origin edge1 edge2)
            (list origin edge1 edge2))

          (define (make-frame origin edge1 edge2)
            (cons origin (cons edge1 edge2)))

     For each constructor supply the appropriate selectors to produce an
     implementation for frames.

Painters
........

A painter is represented as a procedure that, given a frame as
argument, draws a particular image shifted and scaled to fit the frame.
That is to say, if `p' is a painter and `f' is a frame, then we produce
`p''s image in `f' by calling `p' with `f' as argument.

   The details of how primitive painters are implemented depend on the
particular characteristics of the graphics system and the type of image
to be drawn.  For instance, suppose we have a procedure `draw-line'
that draws a line on the screen between two specified points.  Then we
can create painters for line drawings, such as the `wave' painter in
*note Figure 2-10::, from lists of line segments as follows:(6)

     (define (segments->painter segment-list)
       (lambda (frame)
         (for-each
          (lambda (segment)
            (draw-line
             ((frame-coord-map frame) (start-segment segment))
             ((frame-coord-map frame) (end-segment segment))))
          segment-list)))

   The segments are given using coordinates with respect to the unit
square.  For each segment in the list, the painter transforms the
segment endpoints with the frame coordinate map and draws a line
between the transformed points.

   Representing painters as procedures erects a powerful abstraction
barrier in the picture language.  We can create and intermix all sorts
of primitive painters, based on a variety of graphics capabilities. The
details of their implementation do not matter.  Any procedure can serve
as a painter, provided that it takes a frame as argument and draws
something scaled to fit the frame.(7)

     *Exercise 2.48:* A directed line segment in the plane can be
     represented as a pair of vectors--the vector running from the
     origin to the start-point of the segment, and the vector running
     from the origin to the end-point of the segment.  Use your vector
     representation from *note Exercise 2-46:: to define a
     representation for segments with a constructor `make-segment' and
     selectors `start-segment' and `end-segment'.

     *Exercise 2.49:* Use `segments->painter' to define the following
     primitive painters:

       a. The painter that draws the outline of the designated frame.

       b. The painter that draws an "X" by connecting opposite corners
          of the frame.

       c. The painter that draws a diamond shape by connecting the
          midpoints of the sides of the frame.

       d. The `wave' painter.


Transforming and combining painters
...................................

An operation on painters (such as `flip-vert' or `beside') works by
creating a painter that invokes the original painters with respect to
frames derived from the argument frame.  Thus, for example, `flip-vert'
doesn't have to know how a painter works in order to flip it--it just
has to know how to turn a frame upside down: The flipped painter just
uses the original painter, but in the inverted frame.

   Painter operations are based on the procedure `transform-painter',
which takes as arguments a painter and information on how to transform
a frame and produces a new painter.  The transformed painter, when
called on a frame, transforms the frame and calls the original painter
on the transformed frame.  The arguments to `transform-painter' are
points (represented as vectors) that specify the corners of the new
frame: When mapped into the frame, the first point specifies the new
frame's origin and the other two specify the ends of its edge vectors.
Thus, arguments within the unit square specify a frame contained within
the original frame.

     (define (transform-painter painter origin corner1 corner2)
       (lambda (frame)
         (let ((m (frame-coord-map frame)))
           (let ((new-origin (m origin)))
             (painter
              (make-frame new-origin
                          (sub-vect (m corner1) new-origin)
                          (sub-vect (m corner2) new-origin)))))))

   Here's how to flip painter images vertically:

     (define (flip-vert painter)
       (transform-painter painter
                          (make-vect 0.0 1.0)   ; new `origin'
                          (make-vect 1.0 1.0)   ; new end of `edge1'
                          (make-vect 0.0 0.0))) ; new end of `edge2'

   Using `transform-painter', we can easily define new transformations.
For example, we can define a painter that shrinks its image to the
upper-right quarter of the frame it is given:

     (define (shrink-to-upper-right painter)
       (transform-painter painter
                          (make-vect 0.5 0.5)
                          (make-vect 1.0 0.5)
                          (make-vect 0.5 1.0)))

   Other transformations rotate images counterclockwise by 90 degrees(8)

     (define (rotate90 painter)
       (transform-painter painter
                          (make-vect 1.0 0.0)
                          (make-vect 1.0 1.0)
                          (make-vect 0.0 0.0)))

or squash images towards the center of the frame:(9)

     (define (squash-inwards painter)
       (transform-painter painter
                          (make-vect 0.0 0.0)
                          (make-vect 0.65 0.35)
                          (make-vect 0.35 0.65)))

   Frame transformation is also the key to defining means of combining
two or more painters.  The `beside' procedure, for example, takes two
painters, transforms them to paint in the left and right halves of an
argument frame respectively, and produces a new, compound painter.
When the compound painter is given a frame, it calls the first
transformed painter to paint in the left half of the frame and calls
the second transformed painter to paint in the right half of the frame:

     (define (beside painter1 painter2)
       (let ((split-point (make-vect 0.5 0.0)))
         (let ((paint-left
                (transform-painter painter1
                                   (make-vect 0.0 0.0)
                                   split-point
                                   (make-vect 0.0 1.0)))
               (paint-right
                (transform-painter painter2
                                   split-point
                                   (make-vect 1.0 0.0)
                                   (make-vect 0.5 1.0))))
           (lambda (frame)
             (paint-left frame)
             (paint-right frame)))))

   Observe how the painter data abstraction, and in particular the
representation of painters as procedures, makes `beside' easy to
implement.  The `beside' procedure need not know anything about the
details of the component painters other than that each painter will
draw something in its designated frame.

     *Exercise 2.50:* Define the transformation `flip-horiz', which
     flips painters horizontally, and transformations that rotate
     painters counterclockwise by 180 degrees and 270 degrees.

     *Exercise 2.51:* Define the `below' operation for painters.
     `Below' takes two painters as arguments.  The resulting painter,
     given a frame, draws with the first painter in the bottom of the
     frame and with the second painter in the top.  Define `below' in
     two different ways--first by writing a procedure that is analogous
     to the `beside' procedure given above, and again in terms of
     `beside' and suitable rotation operations (from *note Exercise
     2-50::).

Levels of language for robust design
....................................

The picture language exercises some of the critical ideas we've
introduced about abstraction with procedures and data.  The fundamental
data abstractions, painters, are implemented using procedural
representations, which enables the language to handle different basic
drawing capabilities in a uniform way.  The means of combination
satisfy the closure property, which permits us to easily build up
complex designs.  Finally, all the tools for abstracting procedures are
available to us for abstracting means of combination for painters.

   We have also obtained a glimpse of another crucial idea about
languages and program design.  This is the approach of "stratified
design", the notion that a complex system should be structured as a
sequence of levels that are described using a sequence of languages.
Each level is constructed by combining parts that are regarded as
primitive at that level, and the parts constructed at each level are
used as primitives at the next level.  The language used at each level
of a stratified design has primitives, means of combination, and means
of abstraction appropriate to that level of detail.

   Stratified design pervades the engineering of complex systems.  For
example, in computer engineering, resistors and transistors are
combined (and described using a language of analog circuits) to produce
parts such as and-gates and or-gates, which form the primitives of a
language for digital-circuit design.(10) These parts are combined to
build processors, bus structures, and memory systems, which are in turn
combined to form computers, using languages appropriate to computer
architecture.  Computers are combined to form distributed systems, using
languages appropriate for describing network interconnections, and so
on.

   As a tiny example of stratification, our picture language uses
primitive elements (primitive painters) that are created using a
language that specifies points and lines to provide the lists of line
segments for `segments->painter', or the shading details for a painter
like `rogers'.  The bulk of our description of the picture language
focused on combining these primitives, using geometric combiners such
as `beside' and `below'.  We also worked at a higher level, regarding
`beside' and `below' as primitives to be manipulated in a language
whose operations, such as `square-of-four', capture common patterns of
combining geometric combiners.

   Stratified design helps make programs "robust", that is, it makes it
likely that small changes in a specification will require
correspondingly small changes in the program.  For instance, suppose we
wanted to change the image based on `wave' shown in *note Figure 2-9::.
We could work at the lowest level to change the detailed appearance of
the `wave' element; we could work at the middle level to change the way
`corner-split' replicates the `wave'; we could work at the highest
level to change how `square-limit' arranges the four copies of the
corner.  In general, each level of a stratified design provides a
different vocabulary for expressing the characteristics of the system,
and a different kind of ability to change it.

     *Exercise 2.52:* Make changes to the square limit of `wave' shown
     in *note Figure 2-9:: by working at each of the levels described
     above.  In particular:

       a. Add some segments to the primitive `wave' painter of *note
          Exercise 2-49:: (to add a smile, for example).

       b. Change the pattern constructed by `corner-split' (for
          example, by using only one copy of the `up-split' and
          `right-split' images instead of two).

       c. Modify the version of `square-limit' that uses
          `square-of-four' so as to assemble the corners in a different
          pattern.  (For example, you might make the big Mr. Rogers
          look outward from each corner of the square.)


   ---------- Footnotes ----------

   (1) The picture language is based on the language Peter Henderson
created to construct images like M.C. Escher's "Square Limit" woodcut
(see Henderson 1982).  The woodcut incorporates a repeated scaled
pattern, similar to the arrangements drawn using the `square-limit'
procedure in this section.

   (2) William Barton Rogers (1804-1882) was the founder and first
president of MIT.  A geologist and talented teacher, he taught at
William and Mary College and at the University of Virginia.  In 1859 he
moved to Boston, where he had more time for research, worked on a plan
for establishing a "polytechnic institute," and served as
Massachusetts's first State Inspector of Gas Meters.

   When MIT was established in 1861, Rogers was elected its first
president.  Rogers espoused an ideal of "useful learning" that was
different from the university education of the time, with its
overemphasis on the classics, which, as he wrote, "stand in the way of
the broader, higher and more practical instruction and discipline of
the natural and social sciences."  This education was likewise to be
different from narrow trade-school education.  In Rogers's words:

     The world-enforced distinction between the practical and the
     scientific worker is utterly futile, and the whole experience of
     modern times has demonstrated its utter worthlessness.

   Rogers served as president of MIT until 1870, when he resigned due to
ill health.  In 1878 the second president of MIT, John Runkle, resigned
under the pressure of a financial crisis brought on by the Panic of
1873 and strain of fighting off attempts by Harvard to take over MIT.
Rogers returned to hold the office of president until 1881.

   Rogers collapsed and died while addressing MIT's graduating class at
the commencement exercises of 1882.  Runkle quoted Rogers's last words
in a memorial address delivered that same year:

     "As I stand here today and see what the Institute is, ... I call
     to mind the beginnings of science.  I remember one hundred and
     fifty years ago Stephen Hales published a pamphlet on the subject
     of illuminating gas, in which he stated that his researches had
     demonstrated that 128 grains of bituminous coal - " "Bituminous
     coal," these were his last words on earth.  Here he bent forward,
     as if consulting some notes on the table before him, then slowly
     regaining an erect position, threw up his hands, and was
     translated from the scene of his earthly labors and triumphs to
     "the tomorrow of death," where the mysteries of life are solved,
     and the disembodied spirit finds unending satisfaction in
     contemplating the new and still unfathomable mysteries of the
     infinite future.

   In the words of Francis A. Walker (MIT's third president):

     All his life he had borne himself most faithfully and heroically,
     and he died as so good a knight would surely have wished, in
     harness, at his post, and in the very part and act of public duty.

   (3) Equivalently, we could write

     (define flipped-pairs
       (square-of-four identity flip-vert identity flip-vert))

   (4) `Rotate180' rotates a painter by 180 degrees (see *note Exercise
2-50::).  Instead of `rotate180' we could say `(compose flip-vert
flip-horiz)', using the `compose' procedure from *note Exercise 1-42::.

   (5) `Frame-coord-map' uses the vector operations described in *note
Exercise 2-46:: below, which we assume have been implemented using some
representation for vectors.  Because of data abstraction, it doesn't
matter what this vector representation is, so long as the vector
operations behave correctly.

   (6) `Segments->painter' uses the representation for line segments
described in *note Exercise 2-48:: below.  It also uses the `for-each'
procedure described in *note Exercise 2-23::.

   (7) For example, the `rogers' painter of *note Figure 2-11:: was
constructed from a gray-level image.  For each point in a given frame,
the `rogers' painter determines the point in the image that is mapped
to it under the frame coordinate map, and shades it accordingly.  By
allowing different types of painters, we are capitalizing on the
abstract data idea discussed in section *note 2-1-3::, where we argued
that a rational-number representation could be anything at all that
satisfies an appropriate condition.  Here we're using the fact that a
painter can be implemented in any way at all, so long as it draws
something in the designated frame.  Section *note 2-1-3:: also showed
how pairs could be implemented as procedures.  Painters are our second
example of a procedural representation for data.

   (8) `Rotate90' is a pure rotation only for square frames, because it
also stretches and shrinks the image to fit into the rotated frame.

   (9) The diamond-shaped images in figures *note Figure 2-10:: and
*note Figure 2-11:: were created with `squash-inwards' applied to
`wave' and `rogers'.

   (10) Section *note 3-3-4:: describes one such language.


File: sicp,  Node: 2-3,  Next: 2-4,  Prev: 2-2,  Up: Chapter 2

2.3 Symbolic Data
=================

All the compound data objects we have used so far were constructed
ultimately from numbers.  In this section we extend the
representational capability of our language by introducing the ability
to work with arbitrary symbols as data.

* Menu:

* 2-3-1::            Quotation
* 2-3-2::            Example: Symbolic Differentiation
* 2-3-3::            Example: Representing Sets
* 2-3-4::            Example: Huffman Encoding Trees


File: sicp,  Node: 2-3-1,  Next: 2-3-2,  Prev: 2-3,  Up: 2-3

2.3.1 Quotation
---------------

If we can form compound data using symbols, we can have lists such as

     (a b c d)
     (23 45 17)
     ((Norah 12) (Molly 9) (Anna 7) (Lauren 6) (Charlotte 4))

   Lists containing symbols can look just like the expressions of our
language:

     (* (+ 23 45) (+ x 9))

     (define (fact n) (if (= n 1) 1 (* n (fact (- n 1)))))

   In order to manipulate symbols we need a new element in our
language: the ability to "quote" a data object.  Suppose we want to
construct the list `(a b)'.  We can't accomplish this with `(list a
b)', because this expression constructs a list of the "values" of `a'
and `b' rather than the symbols themselves.  This issue is well known
in the context of natural languages, where words and sentences may be
regarded either as semantic entities or as character strings (syntactic
entities).  The common practice in natural languages is to use
quotation marks to indicate that a word or a sentence is to be treated
literally as a string of characters.  For instance, the first letter of
"John" is clearly "J."  If we tell somebody "say your name aloud," we
expect to hear that person's name.  However, if we tell somebody "say
`your name' aloud," we expect to hear the words "your name."  Note that
we are forced to nest quotation marks to describe what somebody else
might say.(1)

   We can follow this same practice to identify lists and symbols that
are to be treated as data objects rather than as expressions to be
evaluated.  However, our format for quoting differs from that of
natural languages in that we place a quotation mark (traditionally, the
single quote symbol `'') only at the beginning of the object to be
quoted.  We can get away with this in Scheme syntax because we rely on
blanks and parentheses to delimit objects.  Thus, the meaning of the
single quote character is to quote the next object.(2)

   Now we can distinguish between symbols and their values:

     (define a 1)

     (define b 2)

     (list a b)
     (1 2)

     (list 'a 'b)
     (a b)

     (list 'a b)
     (a 2)

   Quotation also allows us to type in compound objects, using the
conventional printed representation for lists:(3)

     (car '(a b c))
     a

     (cdr '(a b c))
     (b c)

   In keeping with this, we can obtain the empty list by evaluating
`'()', and thus dispense with the variable `nil'.

   One additional primitive used in manipulating symbols is `eq?', which
takes two symbols as arguments and tests whether they are the same.(4)
Using `eq?', we can implement a useful procedure called `memq'.  This
takes two arguments, a symbol and a list.  If the symbol is not
contained in the list (i.e., is not `eq?' to any item in the list),
then `memq' returns false.  Otherwise, it returns the sublist of the
list beginning with the first occurrence of the symbol:

     (define (memq item x)
       (cond ((null? x) false)
             ((eq? item (car x)) x)
             (else (memq item (cdr x)))))

   For example, the value of

     (memq 'apple '(pear banana prune))

is false, whereas the value of

     (memq 'apple '(x (apple sauce) y apple pear))

is `(apple pear)'.

     *Exercise 2.53:* What would the interpreter print in response to
     evaluating each of the following expressions?

          (list 'a 'b 'c)

          (list (list 'george))

          (cdr '((x1 x2) (y1 y2)))

          (cadr '((x1 x2) (y1 y2)))

          (pair? (car '(a short list)))

          (memq 'red '((red shoes) (blue socks)))

          (memq 'red '(red shoes blue socks))

     *Exercise 2.54:* Two lists are said to be `equal?' if they contain
     equal elements arranged in the same order.  For example,

          (equal? '(this is a list) '(this is a list))

     is true, but

          (equal? '(this is a list) '(this (is a) list))

     is false.  To be more precise, we can define `equal?'  recursively
     in terms of the basic `eq?' equality of symbols by saying that `a'
     and `b' are `equal?' if they are both symbols and the symbols are
     `eq?', or if they are both lists such that `(car a)' is `equal?'
     to `(car b)' and `(cdr a)' is `equal?' to `(cdr b)'.  Using this
     idea, implement `equal?' as a procedure.(5)

     *Exercise 2.55:* Eva Lu Ator types to the interpreter the
     expression

          (car ''abracadabra)

     To her surprise, the interpreter prints back `quote'.  Explain.

   ---------- Footnotes ----------

   (1) Allowing quotation in a language wreaks havoc with the ability
to reason about the language in simple terms, because it destroys the
notion that equals can be substituted for equals.  For example, three
is one plus two, but the word "three" is not the phrase "one plus two."
Quotation is powerful because it gives us a way to build expressions
that manipulate other expressions (as we will see when we write an
interpreter in *note Chapter 4::). But allowing statements in a
language that talk about other statements in that language makes it
very difficult to maintain any coherent principle of what "equals can
be substituted for equals" should mean.  For example, if we know that
the evening star is the morning star, then from the statement "the
evening star is Venus" we can deduce "the morning star is Venus."
However, given that "John knows that the evening star is Venus" we
cannot infer that "John knows that the morning star is Venus."

   (2) The single quote is different from the double quote we have been
using to enclose character strings to be printed.  Whereas the single
quote can be used to denote lists or symbols, the double quote is used
only with character strings.  In this book, the only use for character
strings is as items to be printed.

   (3) Strictly, our use of the quotation mark violates the general
rule that all compound expressions in our language should be delimited
by parentheses and look like lists.  We can recover this consistency by
introducing a special form `quote', which serves the same purpose as
the quotation mark.  Thus, we would type `(quote a)' instead of `'a',
and we would type `(quote (a b c))' instead of `'(a b c)'.  This is
precisely how the interpreter works.  The quotation mark is just a
single-character abbreviation for wrapping the next complete expression
with `quote' to form `(quote <EXPRESSION>)'.  This is important because
it maintains the principle that any expression seen by the interpreter
can be manipulated as a data object.  For instance, we could construct
the expression `(car '(a b c))', which is the same as `(car (quote (a b
c)))', by evaluating `(list 'car (list 'quote '(a b c)))'.

   (4) We can consider two symbols to be "the same" if they consist of
the same characters in the same order.  Such a definition skirts a deep
issue that we are not yet ready to address: the meaning of "sameness"
in a programming language.  We will return to this in *note Chapter 3::
(section *note 3-1-3::).

   (5) In practice, programmers use `equal?' to compare lists that
contain numbers as well as symbols.  Numbers are not considered to be
symbols.  The question of whether two numerically equal numbers (as
tested by `=') are also `eq?' is highly implementation-dependent.  A
better definition of `equal?' (such as the one that comes as a
primitive in Scheme) would also stipulate that if `a' and `b' are both
numbers, then `a' and `b' are `equal?' if they are numerically equal.


File: sicp,  Node: 2-3-2,  Next: 2-3-3,  Prev: 2-3-1,  Up: 2-3

2.3.2 Example: Symbolic Differentiation
---------------------------------------

As an illustration of symbol manipulation and a further illustration of
data abstraction, consider the design of a procedure that performs
symbolic differentiation of algebraic expressions.  We would like the
procedure to take as arguments an algebraic expression and a variable
and to return the derivative of the expression with respect to the
variable.  For example, if the arguments to the procedure are ax^2 + bx
+ c and x, the procedure should return 2ax + b.  Symbolic
differentiation is of special historical significance in Lisp.  It was
one of the motivating examples behind the development of a computer
language for symbol manipulation.  Furthermore, it marked the beginning
of the line of research that led to the development of powerful systems
for symbolic mathematical work, which are currently being used by a
growing number of applied mathematicians and physicists.

   In developing the symbolic-differentiation program, we will follow
the same strategy of data abstraction that we followed in developing
the rational-number system of section *note 2-1-1::.  That is, we will
first define a differentiation algorithm that operates on abstract
objects such as "sums," "products," and "variables" without worrying
about how these are to be represented.  Only afterward will we address
the representation problem.

The differentiation program with abstract data
..............................................

In order to keep things simple, we will consider a very simple
symbolic-differentiation program that handles expressions that are
built up using only the operations of addition and multiplication with
two arguments.  Differentiation of any such expression can be carried
out by applying the following reduction rules:

     dc
     -- = 0  for c a constant, or a variable different from x
     dx

     dx
     -- = 1
     dx

     d(u + v)   du   dv
     -------- = -- + --
        dx      dx   dx

     d(uv)     / dv \     / du \
     ----- = u | -- | + v | -- |
      dx       \ dx /     \ dx /

   Observe that the latter two rules are recursive in nature.  That is,
to obtain the derivative of a sum we first find the derivatives of the
terms and add them.  Each of the terms may in turn be an expression
that needs to be decomposed.  Decomposing into smaller and smaller
pieces will eventually produce pieces that are either constants or
variables, whose derivatives will be either 0 or 1.

   To embody these rules in a procedure we indulge in a little wishful
thinking, as we did in designing the rational-number implementation.
If we had a means for representing algebraic expressions, we should be
able to tell whether an expression is a sum, a product, a constant, or
a variable.  We should be able to extract the parts of an expression.
For a sum, for example we want to be able to extract the addend (first
term) and the augend (second term).  We should also be able to
construct expressions from parts.  Let us assume that we already have
procedures to implement the following selectors, constructors, and
predicates:

     (variable? e)          Is `e' a variable?
     (same-variable? v1 v2) Are `v1' and `v2' the same variable?
     (sum? e)               Is `e' a sum?
     (addend e)             Addend of the sum `e'.
     (augend e)             Augend of the sum `e'.
     (make-sum a1 a2)       Construct the sum of `a1' and `a2'.
     (product? e)           Is `e' a product?
     (multiplier e)         Multiplier of the product `e'.
     (multiplicand e)       Multiplicand of the product `e'.
     (make-product m1 m2)   Construct the product of `m1' and `m2'.

   Using these, and the primitive predicate `number?', which identifies
numbers, we can express the differentiation rules as the following
procedure:

     (define (deriv exp var)
       (cond ((number? exp) 0)
             ((variable? exp)
              (if (same-variable? exp var) 1 0))
             ((sum? exp)
              (make-sum (deriv (addend exp) var)
                        (deriv (augend exp) var)))
             ((product? exp)
              (make-sum
                (make-product (multiplier exp)
                              (deriv (multiplicand exp) var))
                (make-product (deriv (multiplier exp) var)
                              (multiplicand exp))))
             (else
              (error "unknown expression type -- DERIV" exp))))

   This `deriv' procedure incorporates the complete differentiation
algorithm.  Since it is expressed in terms of abstract data, it will
work no matter how we choose to represent algebraic expressions, as
long as we design a proper set of selectors and constructors.  This is
the issue we must address next.

Representing algebraic expressions
..................................

We can imagine many ways to use list structure to represent algebraic
expressions.  For example, we could use lists of symbols that mirror
the usual algebraic notation, representing ax + b as the list `(a * x +
b)' .  However, one especially straightforward choice is to use the same
parenthesized prefix notation that Lisp uses for combinations; that is,
to represent ax + b as `(+ (* a x) b)'.  Then our data representation
for the differentiation problem is as follows:

   * The variables are symbols.  They are identified by the primitive
     predicate `symbol?':

          (define (variable? x) (symbol? x))

   * Two variables are the same if the symbols representing them are
     `eq?':

          (define (same-variable? v1 v2)
            (and (variable? v1) (variable? v2) (eq? v1 v2)))

   * Sums and products are constructed as lists:

          (define (make-sum a1 a2) (list '+ a1 a2))

          (define (make-product m1 m2) (list '* m1 m2))

   * A sum is a list whose first element is the symbol `+':

          (define (sum? x)
            (and (pair? x) (eq? (car x) '+)))

   * The addend is the second item of the sum list:

          (define (addend s) (cadr s))

   * The augend is the third item of the sum list:

          (define (augend s) (caddr s))

   * A product is a list whose first element is the symbol `*':

          (define (product? x)
            (and (pair? x) (eq? (car x) '*)))

   * The multiplier is the second item of the product list:

          (define (multiplier p) (cadr p))

   * The multiplicand is the third item of the product list:

          (define (multiplicand p) (caddr p))


   Thus, we need only combine these with the algorithm as embodied by
`deriv' in order to have a working symbolic-differentiation program.
Let us look at some examples of its behavior:

     (deriv '(+ x 3) 'x)
     (+ 1 0)

     (deriv '(* x y) 'x)
     (+ (* x 0) (* 1 y))

     (deriv '(* (* x y) (+ x 3)) 'x)
        (+ (* (* x y) (+ 1 0))
        (* (+ (* x 0) (* 1 y))
           (+  x 3)))

   The program produces answers that are correct; however, they are
unsimplified.  It is true that

     d(xy)
     ----- = x * 0 + 1 * y
      dx

but we would like the program to know that x * 0 = 0, 1 * y = y, and 0
+ y = y.  The answer for the second example should have been simply
`y'.  As the third example shows, this becomes a serious issue when the
expressions are complex.

   Our difficulty is much like the one we encountered with the
rational-number implementation: we haven't reduced answers to simplest
form.  To accomplish the rational-number reduction, we needed to change
only the constructors and the selectors of the implementation.  We can
adopt a similar strategy here.  We won't change `deriv' at all.
Instead, we will change `make-sum' so that if both summands are
numbers, `make-sum' will add them and return their sum.  Also, if one
of the summands is 0, then `make-sum' will return the other summand.

     (define (make-sum a1 a2)
       (cond ((=number? a1 0) a2)
             ((=number? a2 0) a1)
             ((and (number? a1) (number? a2)) (+ a1 a2))
             (else (list '+ a1 a2))))

   This uses the procedure `=number?', which checks whether an
expression is equal to a given number:

     (define (=number? exp num)
       (and (number? exp) (= exp num)))

   Similarly, we will change `make-product' to build in the rules that 0
times anything is 0 and 1 times anything is the thing itself:

     (define (make-product m1 m2)
       (cond ((or (=number? m1 0) (=number? m2 0)) 0)
             ((=number? m1 1) m2)
             ((=number? m2 1) m1)
             ((and (number? m1) (number? m2)) (* m1 m2))
             (else (list '* m1 m2))))

   Here is how this version works on our three examples:

     (deriv '(+ x 3) 'x)
     1

     (deriv '(* x y) 'x)
     y

     (deriv '(* (* x y) (+ x 3)) 'x)
     (+ (* x y) (* y (+ x 3)))

   Although this is quite an improvement, the third example shows that
there is still a long way to go before we get a program that puts
expressions into a form that we might agree is "simplest."  The problem
of algebraic simplification is complex because, among other reasons, a
form that may be simplest for one purpose may not be for another.

     *Exercise 2.56:* Show how to extend the basic differentiator to
     handle more kinds of expressions.  For instance, implement the
     differentiation rule

          n_1   n_2
          --- = ---  if and only if n_1 d_2 = n_2 d_1
          d_1   d_2

     by adding a new clause to the `deriv' program and defining
     appropriate procedures `exponentiation?', `base', `exponent', and
     `make-exponentiation'.  (You may use the symbol `**' to denote
     exponentiation.)  Build in the rules that anything raised to the
     power 0 is 1 and anything raised to the power 1 is the thing
     itself.

     *Exercise 2.57:* Extend the differentiation program to handle sums
     and products of arbitrary numbers of (two or more) terms.  Then
     the last example above could be expressed as

          (deriv '(* x y (+ x 3)) 'x)

     Try to do this by changing only the representation for sums and
     products, without changing the `deriv' procedure at all.  For
     example, the `addend' of a sum would be the first term, and the
     `augend' would be the sum of the rest of the terms.

     *Exercise 2.58:* Suppose we want to modify the differentiation
     program so that it works with ordinary mathematical notation, in
     which `+' and `*' are infix rather than prefix operators.  Since
     the differentiation program is defined in terms of abstract data,
     we can modify it to work with different representations of
     expressions solely by changing the predicates, selectors, and
     constructors that define the representation of the algebraic
     expressions on which the differentiator is to operate.

       a. Show how to do this in order to differentiate algebraic
          expressions presented in infix form, such as `(x + (3 * (x +
          (y + 2))))'.  To simplify the task, assume that `+' and `*'
          always take two arguments and that expressions are fully
          parenthesized.

       b. The problem becomes substantially harder if we allow standard
          algebraic notation, such as `(x + 3 * (x + y + 2))', which
          drops unnecessary parentheses and assumes that multiplication
          is done before addition.  Can you design appropriate
          predicates, selectors, and constructors for this notation
          such that our derivative program still works?



File: sicp,  Node: 2-3-3,  Next: 2-3-4,  Prev: 2-3-2,  Up: 2-3

2.3.3 Example: Representing Sets
--------------------------------

In the previous examples we built representations for two kinds of
compound data objects: rational numbers and algebraic expressions.  In
one of these examples we had the choice of simplifying (reducing) the
expressions at either construction time or selection time, but other
than that the choice of a representation for these structures in terms
of lists was straightforward. When we turn to the representation of
sets, the choice of a representation is not so obvious.  Indeed, there
are a number of possible representations, and they differ significantly
from one another in several ways.

   Informally, a set is simply a collection of distinct objects.  To
give a more precise definition we can employ the method of data
abstraction.  That is, we define "set" by specifying the operations
that are to be used on sets.  These are `union-set',
`intersection-set', `element-of-set?', and `adjoin-set'.
`Element-of-set?' is a predicate that determines whether a given
element is a member of a set.  `Adjoin-set' takes an object and a set
as arguments and returns a set that contains the elements of the
original set and also the adjoined element.  `Union-set' computes the
union of two sets, which is the set containing each element that
appears in either argument.  `Intersection-set' computes the
intersection of two sets, which is the set containing only elements
that appear in both arguments.  From the viewpoint of data abstraction,
we are free to design any representation that implements these
operations in a way consistent with the interpretations given above.(1)

Sets as unordered lists
.......................

One way to represent a set is as a list of its elements in which no
element appears more than once.  The empty set is represented by the
empty list.  In this representation, `element-of-set?' is similar to
the procedure `memq' of section *note 2-3-1::.  It uses `equal?'
instead of `eq?' so that the set elements need not be symbols:

     (define (element-of-set? x set)
       (cond ((null? set) false)
             ((equal? x (car set)) true)
             (else (element-of-set? x (cdr set)))))

   Using this, we can write `adjoin-set'.  If the object to be adjoined
is already in the set, we just return the set.  Otherwise, we use
`cons' to add the object to the list that represents the set:

     (define (adjoin-set x set)
       (if (element-of-set? x set)
           set
           (cons x set)))

   For `intersection-set' we can use a recursive strategy.  If we know
how to form the intersection of `set2' and the `cdr' of `set1', we only
need to decide whether to include the `car' of `set1' in this.  But
this depends on whether `(car set1)' is also in `set2'.  Here is the
resulting procedure:

     (define (intersection-set set1 set2)
       (cond ((or (null? set1) (null? set2)) '())
             ((element-of-set? (car set1) set2)
              (cons (car set1)
                    (intersection-set (cdr set1) set2)))
             (else (intersection-set (cdr set1) set2))))

   In designing a representation, one of the issues we should be
concerned with is efficiency.  Consider the number of steps required by
our set operations.  Since they all use `element-of-set?', the speed of
this operation has a major impact on the efficiency of the set
implementation as a whole.  Now, in order to check whether an object is
a member of a set, `element-of-set?' may have to scan the entire set.
(In the worst case, the object turns out not to be in the set.)  Hence,
if the set has n elements, `element-of-set?'  might take up to n steps.
Thus, the number of steps required grows as [theta](n).  The number of
steps required by `adjoin-set', which uses this operation, also grows
as [theta](n).  For `intersection-set', which does an `element-of-set?'
check for each element of `set1', the number of steps required grows as
the product of the sizes of the sets involved, or [theta](n^2) for two
sets of size n.  The same will be true of `union-set'.

     *Exercise 2.59:* Implement the `union-set' operation for the
     unordered-list representation of sets.

     *Exercise 2.60:* We specified that a set would be represented as a
     list with no duplicates.  Now suppose we allow duplicates.  For
     instance, the set {1,2,3} could be represented as the list `(2 3 2
     1 3 2 2)'.  Design procedures `element-of-set?', `adjoin-set',
     `union-set', and `intersection-set' that operate on this
     representation.  How does the efficiency of each compare with the
     corresponding procedure for the non-duplicate representation?  Are
     there applications for which you would use this representation in
     preference to the non-duplicate one?

Sets as ordered lists
.....................

One way to speed up our set operations is to change the representation
so that the set elements are listed in increasing order.  To do this,
we need some way to compare two objects so that we can say which is
bigger.  For example, we could compare symbols lexicographically, or we
could agree on some method for assigning a unique number to an object
and then compare the elements by comparing the corresponding numbers.
To keep our discussion simple, we will consider only the case where the
set elements are numbers, so that we can compare elements using `>' and
`<'.  We will represent a set of numbers by listing its elements in
increasing order.  Whereas our first representation above allowed us to
represent the set {1,3,6,10} by listing the elements in any order, our
new representation allows only the list `(1 3 6 10)'.

   One advantage of ordering shows up in `element-of-set?': In checking
for the presence of an item, we no longer have to scan the entire set.
If we reach a set element that is larger than the item we are looking
for, then we know that the item is not in the set:

     (define (element-of-set? x set)
       (cond ((null? set) false)
             ((= x (car set)) true)
             ((< x (car set)) false)
             (else (element-of-set? x (cdr set)))))

   How many steps does this save?  In the worst case, the item we are
looking for may be the largest one in the set, so the number of steps
is the same as for the unordered representation.  On the other hand, if
we search for items of many different sizes we can expect that
sometimes we will be able to stop searching at a point near the
beginning of the list and that other times we will still need to
examine most of the list.  On the average we should expect to have to
examine about half of the items in the set.  Thus, the average number
of steps required will be about n/2.  This is still [theta](n) growth,
but it does save us, on the average, a factor of 2 in number of steps
over the previous implementation.

   We obtain a more impressive speedup with `intersection-set'.  In the
unordered representation this operation required [theta](n^2) steps,
because we performed a complete scan of `set2' for each element of
`set1'.  But with the ordered representation, we can use a more clever
method.  Begin by comparing the initial elements, `x1' and `x2', of the
two sets.  If `x1' equals `x2', then that gives an element of the
intersection, and the rest of the intersection is the intersection of
the `cdr's of the two sets.  Suppose, however, that `x1' is less than
`x2'.  Since `x2' is the smallest element in `set2', we can immediately
conclude that `x1' cannot appear anywhere in `set2' and hence is not in
the intersection.  Hence, the intersection is equal to the intersection
of `set2' with the `cdr' of `set1'.  Similarly, if `x2' is less than
`x1', then the intersection is given by the intersection of `set1' with
the `cdr' of `set2'.  Here is the procedure:

     (define (intersection-set set1 set2)
       (if (or (null? set1) (null? set2))
           '()
           (let ((x1 (car set1)) (x2 (car set2)))
             (cond ((= x1 x2)
                    (cons x1
                          (intersection-set (cdr set1)
                                            (cdr set2))))
                   ((< x1 x2)
                    (intersection-set (cdr set1) set2))
                   ((< x2 x1)
                    (intersection-set set1 (cdr set2)))))))

   To estimate the number of steps required by this process, observe
that at each step we reduce the intersection problem to computing
intersections of smaller sets--removing the first element from `set1'
or `set2' or both.  Thus, the number of steps required is at most the
sum of the sizes of `set1' and `set2', rather than the product of the
sizes as with the unordered representation.  This is [theta](n) growth
rather than [theta](n^2)--a considerable speedup, even for sets of
moderate size.

     *Exercise 2.61:* Give an implementation of `adjoin-set' using the
     ordered representation.  By analogy with `element-of-set?' show
     how to take advantage of the ordering to produce a procedure that
     requires on the average about half as many steps as with the
     unordered representation.

     *Exercise 2.62:* Give a [theta](n) implementation of `union-set'
     for sets represented as ordered lists.

Sets as binary trees
....................

We can do better than the ordered-list representation by arranging the
set elements in the form of a tree.  Each node of the tree holds one
element of the set, called the "entry" at that node, and a link to each
of two other (possibly empty) nodes.  The "left" link points to
elements smaller than the one at the node, and the "right" link to
elements greater than the one at the node.  *note Figure 2-16:: shows
some trees that represent the set {1,3,5,7,9,11}.  The same set may be
represented by a tree in a number of different ways.  The only thing we
require for a valid representation is that all elements in the left
subtree be smaller than the node entry and that all elements in the
right subtree be larger.

     *Figure 2.16:* Various binary trees that represent the set
     {1,3,5,7,9,11}.

             7          3             5
             /\         /\            /\
            3  9       1  7          3  9
           /\   \         /\        /   /\
          1  5  11       5  9      1   7  11
                             \
                             11

   The advantage of the tree representation is this: Suppose we want to
check whether a number x is contained in a set.  We begin by comparing
x with the entry in the top node.  If x is less than this, we know that
we need only search the left subtree; if x is greater, we need only
search the right subtree.  Now, if the tree is "balanced," each of
these subtrees will be about half the size of the original.  Thus, in
one step we have reduced the problem of searching a tree of size n to
searching a tree of size n/2.  Since the size of the tree is halved at
each step, we should expect that the number of steps needed to search a
tree of size n grows as [theta](`log' n).(2) For large sets, this will
be a significant speedup over the previous representations.

   We can represent trees by using lists.  Each node will be a list of
three items: the entry at the node, the left subtree, and the right
subtree.  A left or a right subtree of the empty list will indicate
that there is no subtree connected there.  We can describe this
representation by the following procedures:(3)

     (define (entry tree) (car tree))

     (define (left-branch tree) (cadr tree))

     (define (right-branch tree) (caddr tree))

     (define (make-tree entry left right)
       (list entry left right))

   Now we can write the `element-of-set?' procedure using the strategy
described above:

     (define (element-of-set? x set)
       (cond ((null? set) false)
             ((= x (entry set)) true)
             ((< x (entry set))
              (element-of-set? x (left-branch set)))
             ((> x (entry set))
              (element-of-set? x (right-branch set)))))

   Adjoining an item to a set is implemented similarly and also requires
[theta](`log' n) steps.  To adjoin an item `x', we compare `x' with the
node entry to determine whether `x' should be added to the right or to
the left branch, and having adjoined `x' to the appropriate branch we
piece this newly constructed branch together with the original entry
and the other branch.  If `x' is equal to the entry, we just return the
node.  If we are asked to adjoin `x' to an empty tree, we generate a
tree that has `x' as the entry and empty right and left branches.  Here
is the procedure:

     (define (adjoin-set x set)
       (cond ((null? set) (make-tree x '() '()))
             ((= x (entry set)) set)
             ((< x (entry set))
              (make-tree (entry set)
                         (adjoin-set x (left-branch set))
                         (right-branch set)))
             ((> x (entry set))
              (make-tree (entry set)
                         (left-branch set)
                         (adjoin-set x (right-branch set))))))

   The above claim that searching the tree can be performed in a
logarithmic number of steps rests on the assumption that the tree is
"balanced," i.e., that the left and the right subtree of every tree
have approximately the same number of elements, so that each subtree
contains about half the elements of its parent.  But how can we be
certain that the trees we construct will be balanced?  Even if we start
with a balanced tree, adding elements with `adjoin-set' may produce an
unbalanced result.  Since the position of a newly adjoined element
depends on how the element compares with the items already in the set,
we can expect that if we add elements "randomly" the tree will tend to
be balanced on the average.  But this is not a guarantee.  For example,
if we start with an empty set and adjoin the numbers 1 through 7 in
sequence we end up with the highly unbalanced tree shown in *note
Figure 2-17::.  In this tree all the left subtrees are empty, so it has
no advantage over a simple ordered list.  One way to solve this problem
is to define an operation that transforms an arbitrary tree into a
balanced tree with the same elements.  Then we can perform this
transformation after every few `adjoin-set' operations to keep our set
in balance.  There are also other ways to solve this problem, most of
which involve designing new data structures for which searching and
insertion both can be done in [theta](`log' n) steps.(4)

     *Figure 2.17:* Unbalanced tree produced by adjoining 1 through 7
     in sequence.

          1
           \
            2
             \
              4
               \
                5
                 \
                  6
                   \
                    7

     *Exercise 2.63:* Each of the following two procedures converts a
     binary tree to a list.

          (define (tree->list-1 tree)
            (if (null? tree)
                '()
                (append (tree->list-1 (left-branch tree))
                        (cons (entry tree)
                              (tree->list-1 (right-branch tree))))))

          (define (tree->list-2 tree)
            (define (copy-to-list tree result-list)
              (if (null? tree)
                  result-list
                  (copy-to-list (left-branch tree)
                                (cons (entry tree)
                                      (copy-to-list (right-branch tree)
                                                    result-list)))))
            (copy-to-list tree '()))

       a. Do the two procedures produce the same result for every tree?
          If not, how do the results differ?  What lists do the two
          procedures produce for the trees in *note Figure 2-16::?

       b. Do the two procedures have the same order of growth in the
          number of steps required to convert a balanced tree with n
          elements to a list?  If not, which one grows more slowly?


     *Exercise 2.64:* The following procedure `list->tree' converts an
     ordered list to a balanced binary tree.  The helper procedure
     `partial-tree' takes as arguments an integer n and list of at
     least n elements and constructs a balanced tree containing the
     first n elements of the list.  The result returned by
     `partial-tree' is a pair (formed with `cons') whose `car' is the
     constructed tree and whose `cdr' is the list of elements not
     included in the tree.

          (define (list->tree elements)
            (car (partial-tree elements (length elements))))

          (define (partial-tree elts n)
            (if (= n 0)
                (cons '() elts)
                (let ((left-size (quotient (- n 1) 2)))
                  (let ((left-result (partial-tree elts left-size)))
                    (let ((left-tree (car left-result))
                          (non-left-elts (cdr left-result))
                          (right-size (- n (+ left-size 1))))
                      (let ((this-entry (car non-left-elts))
                            (right-result (partial-tree (cdr non-left-elts)
                                                        right-size)))
                        (let ((right-tree (car right-result))
                              (remaining-elts (cdr right-result)))
                          (cons (make-tree this-entry left-tree right-tree)
                                remaining-elts))))))))

       a. Write a short paragraph explaining as clearly as you can how
          `partial-tree' works.  Draw the tree produced by `list->tree'
          for the list `(1 3 5 7 9 11)'.

       b. What is the order of growth in the number of steps required by
          `list->tree' to convert a list of n elements?


     *Exercise 2.65:* Use the results of *note Exercise 2-63:: and
     *note Exercise 2-64:: to give [theta](n) implementations of
     `union-set' and `intersection-set' for sets implemented as
     (balanced) binary trees.(5)

Sets and information retrieval
..............................

We have examined options for using lists to represent sets and have
seen how the choice of representation for a data object can have a
large impact on the performance of the programs that use the data.
Another reason for concentrating on sets is that the techniques
discussed here appear again and again in applications involving
information retrieval.

   Consider a data base containing a large number of individual
records, such as the personnel files for a company or the transactions
in an accounting system.  A typical data-management system spends a
large amount of time accessing or modifying the data in the records and
therefore requires an efficient method for accessing records.  This is
done by identifying a part of each record to serve as an identifying "key".
A key can be anything that uniquely identifies the record.  For a
personnel file, it might be an employee's ID number.  For an accounting
system, it might be a transaction number.  Whatever the key is, when we
define the record as a data structure we should include a `key'
selector procedure that retrieves the key associated with a given
record.

   Now we represent the data base as a set of records. To locate the
record with a given key we use a procedure `lookup', which takes as
arguments a key and a data base and which returns the record that has
that key, or false if there is no such record.  `Lookup' is implemented
in almost the same way as `element-of-set?'.  For example, if the set
of records is implemented as an unordered list, we could use

     (define (lookup given-key set-of-records)
       (cond ((null? set-of-records) false)
             ((equal? given-key (key (car set-of-records)))
              (car set-of-records))
             (else (lookup given-key (cdr set-of-records)))))

   Of course, there are better ways to represent large sets than as
unordered lists.  Information-retrieval systems in which records have
to be "randomly accessed" are typically implemented by a tree-based
method, such as the binary-tree representation discussed previously.
In designing such a system the methodology of data abstraction can be a
great help.  The designer can create an initial implementation using a
simple, straightforward representation such as unordered lists.  This
will be unsuitable for the eventual system, but it can be useful in
providing a "quick and dirty" data base with which to test the rest of
the system.  Later on, the data representation can be modified to be
more sophisticated.  If the data base is accessed in terms of abstract
selectors and constructors, this change in representation will not
require any changes to the rest of the system.

     *Exercise 2.66:* Implement the `lookup' procedure for the case
     where the set of records is structured as a binary tree, ordered
     by the numerical values of the keys.

   ---------- Footnotes ----------

   (1) If we want to be more formal, we can specify "consistent with
the interpretations given above" to mean that the operations satisfy a
collection of rules such as these:

   * For any set `S' and any object `x', `(element-of-set? x
     (adjoin-set x S))' is true (informally: "Adjoining an object to a
     set produces a set that contains the object").

   * For any sets `S' and `T' and any object `x', `(element-of-set? x
     (union-set S T))' is equal to `(or (element-of-set? x S)
     (element-of-set? x T))' (informally: "The elements of `(union S
     T)' are the elements that are in `S' or in `T'").

   * For any object `x', `(element-of-set? x '())' is false
     (informally: "No object is an element of the empty set").


   (2) Halving the size of the problem at each step is the
distinguishing characteristic of logarithmic growth, as we saw with the
fast-exponentiation algorithm of section *note 1-2-4:: and the
half-interval search method of section *note 1-3-3::.

   (3) We are representing sets in terms of trees, and trees in terms
of lists--in effect, a data abstraction built upon a data abstraction.
We can regard the procedures `entry', `left-branch', `right-branch',
and `make-tree' as a way of isolating the abstraction of a "binary
tree" from the particular way we might wish to represent such a tree in
terms of list structure.

   (4) Examples of such structures include "B-trees" and "red-black
trees".  There is a large literature on data structures devoted to this
problem.  See Cormen, Leiserson, and Rivest 1990.

   (5) *note Exercise 2-63:: through *note Exercise 2-65:: are due to
Paul Hilfinger.


File: sicp,  Node: 2-3-4,  Prev: 2-3-3,  Up: 2-3

2.3.4 Example: Huffman Encoding Trees
-------------------------------------

This section provides practice in the use of list structure and data
abstraction to manipulate sets and trees.  The application is to
methods for representing data as sequences of ones and zeros (bits).
For example, the ASCII standard code used to represent text in
computers encodes each character as a sequence of seven bits.  Using
seven bits allows us to distinguish 2^(7), or 128, possible different
characters.  In general, if we want to distinguish n different symbols,
we will need to use `log'_2 n bits per symbol.  If all our messages are
made up of the eight symbols A, B, C, D, E, F, G, and H, we can choose
a code with three bits per character, for example

     A 000 C 010 E 100 G 110
     B 001 D 011 F 101 H 111

With this code, the message

   BACADAEAFABBAAAGAH

is encoded as the string of 54 bits

   001000010000011000100000101000001001000000000110000111

   Codes such as ASCII and the A-through-H code above are known as "fixed-length"
codes, because they represent each symbol in the message with the same
number of bits.  It is sometimes advantageous to use "variable-length"
codes, in which different symbols may be represented by different
numbers of bits.  For example, Morse code does not use the same number
of dots and dashes for each letter of the alphabet.  In particular, E,
the most frequent letter, is represented by a single dot.  In general,
if our messages are such that some symbols appear very frequently and
some very rarely, we can encode data more efficiently (i.e., using
fewer bits per message) if we assign shorter codes to the frequent
symbols.  Consider the following alternative code for the letters A
through H:

     A 0   C 1010  E 1100  G 1110
     B 100 D 1011  F 1101  H 1111

With this code, the same message as above is encoded as the string

   100010100101101100011010100100000111001111

   This string contains 42 bits, so it saves more than 20% in space in
comparison with the fixed-length code shown above.

   One of the difficulties of using a variable-length code is knowing
when you have reached the end of a symbol in reading a sequence of
zeros and ones.  Morse code solves this problem by using a special "separator
code" (in this case, a pause) after the sequence of dots and dashes for
each letter.  Another solution is to design the code in such a way that
no complete code for any symbol is the beginning (or "prefix") of the
code for another symbol.  Such a code is called a "prefix code".  In
the example above, A is encoded by 0 and B is encoded by 100, so no
other symbol can have a code that begins with 0 or with 100.

   In general, we can attain significant savings if we use
variable-length prefix codes that take advantage of the relative
frequencies of the symbols in the messages to be encoded.  One
particular scheme for doing this is called the Huffman encoding method,
after its discoverer, David Huffman.  A Huffman code can be represented
as a binary tree whose leaves are the symbols that are encoded.  At
each non-leaf node of the tree there is a set containing all the
symbols in the leaves that lie below the node.  In addition, each
symbol at a leaf is assigned a weight (which is its relative
frequency), and each non-leaf node contains a weight that is the sum of
all the weights of the leaves lying below it.  The weights are not used
in the encoding or the decoding process.  We will see below how they
are used to help construct the tree.

     *Figure 2.18:* A Huffman encoding tree.

                     {A B C D E F G H} 17
                              *
                             / \
                            /   \
                          A 8    * {B C D E F G H} 9
                      __________/ \_____________
                     /                          \
          {B C D} 5 *                            * {E F G H} 4
                   / \                       ___/ \___
                  /   \                     /         \
                B 3    * {C D} 2   {E F} 2 *           * {G H} 2
                      / \                 / \         / \
                     /   \               /   \       /   \
                   C 1   D 1           E 1   F 1   G 1   H 1

   *note Figure 2-18:: shows the Huffman tree for the A-through-H code
given above.  The weights at the leaves indicate that the tree was
designed for messages in which A appears with relative frequency 8, B
with relative frequency 3, and the other letters each with relative
frequency 1.

   Given a Huffman tree, we can find the encoding of any symbol by
starting at the root and moving down until we reach the leaf that holds
the symbol.  Each time we move down a left branch we add a 0 to the
code, and each time we move down a right branch we add a 1.  (We decide
which branch to follow by testing to see which branch either is the
leaf node for the symbol or contains the symbol in its set.)  For
example, starting from the root of the tree in *note Figure 2-18::, we
arrive at the leaf for D by following a right branch, then a left
branch, then a right branch, then a right branch; hence, the code for D
is 1011.

   To decode a bit sequence using a Huffman tree, we begin at the root
and use the successive zeros and ones of the bit sequence to determine
whether to move down the left or the right branch.  Each time we come
to a leaf, we have generated a new symbol in the message, at which
point we start over from the root of the tree to find the next symbol.
For example, suppose we are given the tree above and the sequence
10001010.  Starting at the root, we move down the right branch, (since
the first bit of the string is 1), then down the left branch (since the
second bit is 0), then down the left branch (since the third bit is
also 0).  This brings us to the leaf for B, so the first symbol of the
decoded message is B.  Now we start again at the root, and we make a
left move because the next bit in the string is 0.  This brings us to
the leaf for A.  Then we start again at the root with the rest of the
string 1010, so we move right, left, right, left and reach C.  Thus,
the entire message is BAC.

Generating Huffman trees
........................

Given an "alphabet" of symbols and their relative frequencies, how do we
construct the "best" code?  (In other words, which tree will encode
messages with the fewest bits?)  Huffman gave an algorithm for doing
this and showed that the resulting code is indeed the best
variable-length code for messages where the relative frequency of the
symbols matches the frequencies with which the code was constructed.
We will not prove this optimality of Huffman codes here, but we will
show how Huffman trees are constructed.(1)

   The algorithm for generating a Huffman tree is very simple. The idea
is to arrange the tree so that the symbols with the lowest frequency
appear farthest away from the root. Begin with the set of leaf nodes,
containing symbols and their frequencies, as determined by the initial
data from which the code is to be constructed. Now find two leaves with
the lowest weights and merge them to produce a node that has these two
nodes as its left and right branches. The weight of the new node is the
sum of the two weights. Remove the two leaves from the original set and
replace them by this new node. Now continue this process. At each step,
merge two nodes with the smallest weights, removing them from the set
and replacing them with a node that has these two as its left and right
branches. The process stops when there is only one node left, which is
the root of the entire tree.  Here is how the Huffman tree of *note
Figure 2-18:: was generated:

     Initial leaves {(A 8) (B 3) (C 1) (D 1) (E 1) (F 1) (G 1) (H 1)}
     Merge          {(A 8) (B 3) ({C D} 2) (E 1) (F 1) (G 1) (H 1)}
     Merge          {(A 8) (B 3) ({C D} 2) ({E F} 2) (G 1) (H 1)}
     Merge          {(A 8) (B 3) ({C D} 2) ({E F} 2) ({G H} 2)}
     Merge          {(A 8) (B 3) ({C D} 2) ({E F G H} 4)}
     Merge          {(A 8) ({B C D} 5) ({E F G H} 4)}
     Merge          {(A 8) ({B C D E F G H} 9)}
     Final merge    {({A B C D E F G H} 17)}

   The algorithm does not always specify a unique tree, because there
may not be unique smallest-weight nodes at each step.  Also, the choice
of the order in which the two nodes are merged (i.e., which will be the
right branch and which will be the left branch) is arbitrary.

Representing Huffman trees
..........................

In the exercises below we will work with a system that uses Huffman
trees to encode and decode messages and generates Huffman trees
according to the algorithm outlined above.  We will begin by discussing
how trees are represented.

   Leaves of the tree are represented by a list consisting of the symbol
`leaf', the symbol at the leaf, and the weight:

     (define (make-leaf symbol weight)
       (list 'leaf symbol weight))

     (define (leaf? object)
       (eq? (car object) 'leaf))

     (define (symbol-leaf x) (cadr x))

     (define (weight-leaf x) (caddr x))

   A general tree will be a list of a left branch, a right branch, a
set of symbols, and a weight.  The set of symbols will be simply a list
of the symbols, rather than some more sophisticated set representation.
When we make a tree by merging two nodes, we obtain the weight of the
tree as the sum of the weights of the nodes, and the set of symbols as
the union of the sets of symbols for the nodes.  Since our symbol sets
are represented as lists, we can form the union by using the `append'
procedure we defined in section *note 2-2-1:::

     (define (make-code-tree left right)
       (list left
             right
             (append (symbols left) (symbols right))
             (+ (weight left) (weight right))))

   If we make a tree in this way, we have the following selectors:

     (define (left-branch tree) (car tree))

     (define (right-branch tree) (cadr tree))

     (define (symbols tree)
       (if (leaf? tree)
           (list (symbol-leaf tree))
           (caddr tree)))

     (define (weight tree)
       (if (leaf? tree)
           (weight-leaf tree)
           (cadddr tree)))

   The procedures `symbols' and `weight' must do something slightly
different depending on whether they are called with a leaf or a general
tree.  These are simple examples of "generic procedures" (procedures
that can handle more than one kind of data), which we will have much
more to say about in sections *note 2-4:: and *note 2-5::.

The decoding procedure
......................

The following procedure implements the decoding algorithm.  It takes as
arguments a list of zeros and ones, together with a Huffman tree.

     (define (decode bits tree)
       (define (decode-1 bits current-branch)
         (if (null? bits)
             '()
             (let ((next-branch
                    (choose-branch (car bits) current-branch)))
               (if (leaf? next-branch)
                   (cons (symbol-leaf next-branch)
                         (decode-1 (cdr bits) tree))
                   (decode-1 (cdr bits) next-branch)))))
       (decode-1 bits tree))

     (define (choose-branch bit branch)
       (cond ((= bit 0) (left-branch branch))
             ((= bit 1) (right-branch branch))
             (else (error "bad bit -- CHOOSE-BRANCH" bit))))

   The procedure `decode-1' takes two arguments: the list of remaining
bits and the current position in the tree.  It keeps moving "down" the
tree, choosing a left or a right branch according to whether the next
bit in the list is a zero or a one.  (This is done with the procedure
`choose-branch'.)  When it reaches a leaf, it returns the symbol at
that leaf as the next symbol in the message by `cons'ing it onto the
result of decoding the rest of the message, starting at the root of the
tree.  Note the error check in the final clause of `choose-branch',
which complains if the procedure finds something other than a zero or a
one in the input data.

Sets of weighted elements
.........................

In our representation of trees, each non-leaf node contains a set of
symbols, which we have represented as a simple list.  However, the
tree-generating algorithm discussed above requires that we also work
with sets of leaves and trees, successively merging the two smallest
items.  Since we will be required to repeatedly find the smallest item
in a set, it is convenient to use an ordered representation for this
kind of set.

   We will represent a set of leaves and trees as a list of elements,
arranged in increasing order of weight.  The following `adjoin-set'
procedure for constructing sets is similar to the one described in
*note Exercise 2-61::; however, items are compared by their weights,
and the element being added to the set is never already in it.

     (define (adjoin-set x set)
       (cond ((null? set) (list x))
             ((< (weight x) (weight (car set))) (cons x set))
             (else (cons (car set)
                         (adjoin-set x (cdr set))))))

   The following procedure takes a list of symbol-frequency pairs such
as `((A 4) (B 2) (C 1) (D 1))' and constructs an initial ordered set of
leaves, ready to be merged according to the Huffman algorithm:

     (define (make-leaf-set pairs)
       (if (null? pairs)
           '()
           (let ((pair (car pairs)))
             (adjoin-set (make-leaf (car pair)    ; symbol
                                    (cadr pair))  ; frequency
                         (make-leaf-set (cdr pairs))))))

     *Exercise 2.67:* Define an encoding tree and a sample message:

          (define sample-tree
            (make-code-tree (make-leaf 'A 4)
                            (make-code-tree
                             (make-leaf 'B 2)
                             (make-code-tree (make-leaf 'D 1)
                                             (make-leaf 'C 1)))))

          (define sample-message '(0 1 1 0 0 1 0 1 0 1 1 1 0))

     Use the `decode' procedure to decode the message, and give the
     result.

     *Exercise 2.68:* The `encode' procedure takes as arguments a
     message and a tree and produces the list of bits that gives the
     encoded message.

          (define (encode message tree)
            (if (null? message)
                '()
                (append (encode-symbol (car message) tree)
                        (encode (cdr message) tree))))

     `Encode-symbol' is a procedure, which you must write, that returns
     the list of bits that encodes a given symbol according to a given
     tree.  You should design `encode-symbol' so that it signals an
     error if the symbol is not in the tree at all.  Test your
     procedure by encoding the result you obtained in *note Exercise
     2-67:: with the sample tree and seeing whether it is the same as
     the original sample message.

     *Exercise 2.69:* The following procedure takes as its argument a
     list of symbol-frequency pairs (where no symbol appears in more
     than one pair) and generates a Huffman encoding tree according to
     the Huffman algorithm.

          (define (generate-huffman-tree pairs)
            (successive-merge (make-leaf-set pairs)))

     `Make-leaf-set' is the procedure given above that transforms the
     list of pairs into an ordered set of leaves.  `Successive-merge'
     is the procedure you must write, using `make-code-tree' to
     successively merge the smallest-weight elements of the set until
     there is only one element left, which is the desired Huffman tree.
     (This procedure is slightly tricky, but not really complicated.
     If you find yourself designing a complex procedure, then you are
     almost certainly doing something wrong.  You can take significant
     advantage of the fact that we are using an ordered set
     representation.)

     *Exercise 2.70:* The following eight-symbol alphabet with
     associated relative frequencies was designed to efficiently encode
     the lyrics of 1950s rock songs.  (Note that the "symbols" of an
     "alphabet" need not be individual letters.)

          A     2 NA   16
          BOOM  1 SHA  3
          GET   2 YIP  9
          JOB   2 WAH  1

     Use `generate-huffman-tree' (*note Exercise 2-69::) to generate a
     corresponding Huffman tree, and use `encode' (*note Exercise
     2-68::) to encode the following message:

          Get a job

          Sha na na na na na na na na

          Get a job

          Sha na na na na na na na na

          Wah yip yip yip yip yip yip yip yip yip

          Sha boom

     How many bits are required for the encoding?  What is the smallest
     number of bits that would be needed to encode this song if we used
     a fixed-length code for the eight-symbol alphabet?

     *Exercise 2.71:* Suppose we have a Huffman tree for an alphabet of
     n symbols, and that the relative frequencies of the symbols are 1,
     2, 4, ..., 2^(n-1).  Sketch the tree for n=5; for n=10.  In such a
     tree (for general n) how may bits are required to encode the most
     frequent symbol?  the least frequent symbol?

     *Exercise 2.72:* Consider the encoding procedure that you designed
     in *note Exercise 2-68::.  What is the order of growth in the
     number of steps needed to encode a symbol?  Be sure to include the
     number of steps needed to search the symbol list at each node
     encountered.  To answer this question in general is difficult.
     Consider the special case where the relative frequencies of the n
     symbols are as described in *note Exercise 2-71::, and give the
     order of growth (as a function of n) of the number of steps needed
     to encode the most frequent and least frequent symbols in the
     alphabet.

   ---------- Footnotes ----------

   (1) See Hamming 1980 for a discussion of the mathematical properties
of Huffman codes.


File: sicp,  Node: 2-4,  Next: 2-5,  Prev: 2-3,  Up: Chapter 2

2.4 Multiple Representations for Abstract Data
==============================================

We have introduced data abstraction, a methodology for structuring
systems in such a way that much of a program can be specified
independent of the choices involved in implementing the data objects
that the program manipulates.  For example, we saw in section *note
2-1-1:: how to separate the task of designing a program that uses
rational numbers from the task of implementing rational numbers in
terms of the computer language's primitive mechanisms for constructing
compound data.  The key idea was to erect an abstraction barrier - in
this case, the selectors and constructors for rational numbers
(`make-rat', `numer', `denom')--that isolates the way rational numbers
are used from their underlying representation in terms of list
structure.  A similar abstraction barrier isolates the details of the
procedures that perform rational arithmetic (`add-rat', `sub-rat',
`mul-rat', and `div-rat') from the "higher-level" procedures that use
rational numbers.  The resulting program has the structure shown in
*note Figure 2-1::.

   These data-abstraction barriers are powerful tools for controlling
complexity.  By isolating the underlying representations of data
objects, we can divide the task of designing a large program into
smaller tasks that can be performed separately.  But this kind of data
abstraction is not yet powerful enough, because it may not always make
sense to speak of "the underlying representation" for a data object.

   For one thing, there might be more than one useful representation
for a data object, and we might like to design systems that can deal
with multiple representations.  To take a simple example, complex
numbers may be represented in two almost equivalent ways: in
rectangular form (real and imaginary parts) and in polar form
(magnitude and angle).  Sometimes rectangular form is more appropriate
and sometimes polar form is more appropriate.  Indeed, it is perfectly
plausible to imagine a system in which complex numbers are represented
in both ways, and in which the procedures for manipulating complex
numbers work with either representation.

   More importantly, programming systems are often designed by many
people working over extended periods of time, subject to requirements
that change over time.  In such an environment, it is simply not
possible for everyone to agree in advance on choices of data
representation.  So in addition to the data-abstraction barriers that
isolate representation from use, we need abstraction barriers that
isolate different design choices from each other and permit different
choices to coexist in a single program.  Furthermore, since large
programs are often created by combining pre-existing modules that were
designed in isolation, we need conventions that permit programmers to
incorporate modules into larger systems "additively", that is, without
having to redesign or reimplement these modules.

   In this section, we will learn how to cope with data that may be
represented in different ways by different parts of a program.  This
requires constructing "generic procedures"--procedures that can operate
on data that may be represented in more than one way.  Our main
technique for building generic procedures will be to work in terms of
data objects that have tags "type tags", that is, data objects that
include explicit information about how they are to be processed.  We
will also discuss "data-directed" programming, a powerful and
convenient implementation strategy for additively assembling systems
with generic operations.

   We begin with the simple complex-number example. We will see how
type tags and data-directed style enable us to design separate
rectangular and polar representations for complex numbers while
maintaining the notion of an abstract "complex-number" data object.  We
will accomplish this by defining arithmetic procedures for complex
numbers (`add-complex', `sub-complex', `mul-complex', and
`div-complex') in terms of generic selectors that access parts of a
complex number independent of how the number is represented.  The
resulting complex-number system, as shown in *note Figure 2-19::,
contains two different kinds of abstraction barriers.  The "horizontal"
abstraction barriers play the same role as the ones in *note Figure
2-1::.  They isolate "higher-level" operations from "lower-level"
representations.  In addition, there is a "vertical" barrier that gives
us the ability to separately design and install alternative
representations.

     *Figure 2.19:* Data-abstraction barriers in the complex-number
     system.

                     Programs that use complex numbers
            +-------------------------------------------------+
          --| add-complex sub-complex mul-complex div-complex |--
            +-------------------------------------------------+
                        Complex arithmetic package
          ---------------------------+---------------------------
                    Rectangular      |         Polar
                  representation     |     representation
          ---------------------------+---------------------------
              List structure and primitive machine arithmetic

   In section *note 2-5:: we will show how to use type tags and
data-directed style to develop a generic arithmetic package.  This
provides procedures (`add', `mul', and so on) that can be used to
manipulate all sorts of "numbers" and can be easily extended when a new
kind of number is needed.  In section *note 2-5-3::, we'll show how to
use generic arithmetic in a system that performs symbolic algebra.

* Menu:

* 2-4-1::            Representations for Complex Numbers
* 2-4-2::            Tagged data
* 2-4-3::            Data-Directed Programming and Additivity


File: sicp,  Node: 2-4-1,  Next: 2-4-2,  Prev: 2-4,  Up: 2-4

2.4.1 Representations for Complex Numbers
-----------------------------------------

We will develop a system that performs arithmetic operations on complex
numbers as a simple but unrealistic example of a program that uses
generic operations.  We begin by discussing two plausible
representations for complex numbers as ordered pairs: rectangular form
(real part and imaginary part) and polar form (magnitude and angle).(1)
Section *note 2-4-2:: will show how both representations can be made to
coexist in a single system through the use of type tags and generic
operations.

   Like rational numbers, complex numbers are naturally represented as
ordered pairs.  The set of complex numbers can be thought of as a
two-dimensional space with two orthogonal axes, the "real" axis and the
"imaginary" axis. (See *note Figure 2-20::.)  From this point of view,
the complex number z = x + iy (where i^2 = - 1) can be thought of as
the point in the plane whose real coordinate is x and whose imaginary
coordinate is y.  Addition of complex numbers reduces in this
representation to addition of coordinates:

     Real-part(z_1 + z_2) = Real-part(z_1) + Real-part(z_2)

     Imaginary-part(z_1 + z_2) = Imaginary-part(z_1) + Imaginary-part(z_2)

   When multiplying complex numbers, it is more natural to think in
terms of representing a complex number in polar form, as a magnitude
and an angle (r and A in *note Figure 2-20::).  The product of two
complex numbers is the vector obtained by stretching one complex number
by the length of the other and then rotating it through the angle of
the other:

     Magnitude(z_1 * z_2) = Magnitude(z_1) * Magnitude(z_2)

     Angle(z_1 * z_2) = Angle(z_1) + Angle(z_2)

     *Figure 2.20:* Complex numbers as points in the plane.

           Imaginary
              ^
              |
            y |.........................* z = x + ?y = r e^(?A)
              |                    __-- .
              |                __--     .
              |          r __--         .
              |        __--             .
              |    __-- \               .
              |__--    A |              .
          ----+----------+-------------------> Real
                                        x

   Thus, there are two different representations for complex numbers,
which are appropriate for different operations.  Yet, from the
viewpoint of someone writing a program that uses complex numbers, the
principle of data abstraction suggests that all the operations for
manipulating complex numbers should be available regardless of which
representation is used by the computer.  For example, it is often
useful to be able to find the magnitude of a complex number that is
specified by rectangular coordinates.  Similarly, it is often useful to
be able to determine the real part of a complex number that is
specified by polar coordinates.

   To design such a system, we can follow the same data-abstraction
strategy we followed in designing the rational-number package in
section *note 2-1-1::.  Assume that the operations on complex numbers
are implemented in terms of four selectors: `real-part', `imag-part',
`magnitude', and `angle'.  Also assume that we have two procedures for
constructing complex numbers: `make-from-real-imag' returns a complex
number with specified real and imaginary parts, and `make-from-mag-ang'
returns a complex number with specified magnitude and angle.  These
procedures have the property that, for any complex number `z', both

     (make-from-real-imag (real-part z) (imag-part z))

and

     (make-from-mag-ang (magnitude z) (angle z))

produce complex numbers that are equal to `z'.

   Using these constructors and selectors, we can implement arithmetic
on complex numbers using the "abstract data" specified by the
constructors and selectors, just as we did for rational numbers in
section *note 2-1-1::.  As shown in the formulas above, we can add and
subtract complex numbers in terms of real and imaginary parts while
multiplying and dividing complex numbers in terms of magnitudes and
angles:

     (define (add-complex z1 z2)
       (make-from-real-imag (+ (real-part z1) (real-part z2))
                            (+ (imag-part z1) (imag-part z2))))

     (define (sub-complex z1 z2)
       (make-from-real-imag (- (real-part z1) (real-part z2))
                            (- (imag-part z1) (imag-part z2))))

     (define (mul-complex z1 z2)
       (make-from-mag-ang (* (magnitude z1) (magnitude z2))
                          (+ (angle z1) (angle z2))))

     (define (div-complex z1 z2)
       (make-from-mag-ang (/ (magnitude z1) (magnitude z2))
                          (- (angle z1) (angle z2))))

   To complete the complex-number package, we must choose a
representation and we must implement the constructors and selectors in
terms of primitive numbers and primitive list structure.  There are two
obvious ways to do this: We can represent a complex number in
"rectangular form" as a pair (real part, imaginary part) or in "polar
form" as a pair (magnitude, angle).  Which shall we choose?

   In order to make the different choices concrete, imagine that there
are two programmers, Ben Bitdiddle and Alyssa P. Hacker, who are
independently designing representations for the complex-number system.
Ben chooses to represent complex numbers in rectangular form.  With
this choice, selecting the real and imaginary parts of a complex number
is straightforward, as is constructing a complex number with given real
and imaginary parts.  To find the magnitude and the angle, or to
construct a complex number with a given magnitude and angle, he uses
the trigonometric relations

                           __________
     x = r cos A     r = ./ x^2 + y^2

     y = r sin A     A = arctan(y,x)

which relate the real and imaginary parts (x, y) to the magnitude and
the angle (r, A).(2)  Ben's representation is therefore given by the
following selectors and constructors:

     (define (real-part z) (car z))

     (define (imag-part z) (cdr z))

     (define (magnitude z)
       (sqrt (+ (square (real-part z)) (square (imag-part z)))))

     (define (angle z)
       (atan (imag-part z) (real-part z)))

     (define (make-from-real-imag x y) (cons x y))

     (define (make-from-mag-ang r a)
       (cons (* r (cos a)) (* r (sin a))))

   Alyssa, in contrast, chooses to represent complex numbers in polar
form.  For her, selecting the magnitude and angle is straightforward,
but she has to use the trigonometric relations to obtain the real and
imaginary parts.  Alyssa's representation is:

     (define (real-part z)
       (* (magnitude z) (cos (angle z))))

     (define (imag-part z)
       (* (magnitude z) (sin (angle z))))

     (define (magnitude z) (car z))

     (define (angle z) (cdr z))

     (define (make-from-real-imag x y)
       (cons (sqrt (+ (square x) (square y)))
             (atan y x)))

     (define (make-from-mag-ang r a) (cons r a))

   The discipline of data abstraction ensures that the same
implementation of `add-complex', `sub-complex', `mul-complex', and
`div-complex' will work with either Ben's representation or Alyssa's
representation.

   ---------- Footnotes ----------

   (1) In actual computational systems, rectangular form is preferable
to polar form most of the time because of roundoff errors in conversion
between rectangular and polar form.  This is why the complex-number
example is unrealistic.  Nevertheless, it provides a clear illustration
of the design of a system using generic operations and a good
introduction to the more substantial systems to be developed later in
this chapter.

   (2) The arctangent function referred to here, computed by Scheme's
`atan' procedure, is defined so as to take two arguments y and x and to
return the angle whose tangent is y/x.  The signs of the arguments
determine the quadrant of the angle.


File: sicp,  Node: 2-4-2,  Next: 2-4-3,  Prev: 2-4-1,  Up: 2-4

2.4.2 Tagged data
-----------------

One way to view data abstraction is as an application of the "principle
of least commitment."  In implementing the complex-number system in
section *note 2-4-1::, we can use either Ben's rectangular
representation or Alyssa's polar representation.  The abstraction
barrier formed by the selectors and constructors permits us to defer to
the last possible moment the choice of a concrete representation for
our data objects and thus retain maximum flexibility in our system
design.

   The principle of least commitment can be carried to even further
extremes.  If we desire, we can maintain the ambiguity of
representation even _after_ we have designed the selectors and
constructors, and elect to use both Ben's representation _and_ Alyssa's
representation.  If both representations are included in a single
system, however, we will need some way to distinguish data in polar
form from data in rectangular form.  Otherwise, if we were asked, for
instance, to find the `magnitude' of the pair (3,4), we wouldn't know
whether to answer 5 (interpreting the number in rectangular form) or 3
(interpreting the number in polar form).  A straightforward way to
accomplish this distinction is to include a "type tag"--the symbol
`rectangular' or `polar'--as part of each complex number.  Then when we
need to manipulate a complex number we can use the tag to decide which
selector to apply.

   In order to manipulate tagged data, we will assume that we have
procedures `type-tag' and `contents' that extract from a data object
the tag and the actual contents (the polar or rectangular coordinates,
in the case of a complex number).  We will also postulate a procedure
`attach-tag' that takes a tag and contents and produces a tagged data
object.  A straightforward way to implement this is to use ordinary
list structure:

     (define (attach-tag type-tag contents)
       (cons type-tag contents))

     (define (type-tag datum)
       (if (pair? datum)
           (car datum)
           (error "Bad tagged datum -- TYPE-TAG" datum)))

     (define (contents datum)
       (if (pair? datum)
           (cdr datum)
           (error "Bad tagged datum -- CONTENTS" datum)))

   Using these procedures, we can define predicates `rectangular?'  and
`polar?', which recognize polar and rectangular numbers, respectively:

     (define (rectangular? z)
       (eq? (type-tag z) 'rectangular))

     (define (polar? z)
       (eq? (type-tag z) 'polar))

   With type tags, Ben and Alyssa can now modify their code so that
their two different representations can coexist in the same system.
Whenever Ben constructs a complex number, he tags it as rectangular.
Whenever Alyssa constructs a complex number, she tags it as polar.  In
addition, Ben and Alyssa must make sure that the names of their
procedures do not conflict.  One way to do this is for Ben to append
the suffix `rectangular' to the name of each of his representation
procedures and for Alyssa to append `polar' to the names of hers.  Here
is Ben's revised rectangular representation from section *note 2-4-1:::

     (define (real-part-rectangular z) (car z))

     (define (imag-part-rectangular z) (cdr z))

     (define (magnitude-rectangular z)
       (sqrt (+ (square (real-part-rectangular z))
                (square (imag-part-rectangular z)))))

     (define (angle-rectangular z)
       (atan (imag-part-rectangular z)
             (real-part-rectangular z)))

     (define (make-from-real-imag-rectangular x y)
       (attach-tag 'rectangular (cons x y)))

     (define (make-from-mag-ang-rectangular r a)
       (attach-tag 'rectangular
                   (cons (* r (cos a)) (* r (sin a)))))

and here is Alyssa's revised polar representation:

     (define (real-part-polar z)
       (* (magnitude-polar z) (cos (angle-polar z))))

     (define (imag-part-polar z)
       (* (magnitude-polar z) (sin (angle-polar z))))

     (define (magnitude-polar z) (car z))

     (define (angle-polar z) (cdr z))

     (define (make-from-real-imag-polar x y)
       (attach-tag 'polar
                    (cons (sqrt (+ (square x) (square y)))
                          (atan y x))))

     (define (make-from-mag-ang-polar r a)
       (attach-tag 'polar (cons r a)))

   Each generic selector is implemented as a procedure that checks the
tag of its argument and calls the appropriate procedure for handling
data of that type.  For example, to obtain the real part of a complex
number, `real-part' examines the tag to determine whether to use Ben's
`real-part-rectangular' or Alyssa's `real-part-polar'.  In either case,
we use `contents' to extract the bare, untagged datum and send this to
the rectangular or polar procedure as required:

     (define (real-part z)
       (cond ((rectangular? z)
              (real-part-rectangular (contents z)))
             ((polar? z)
              (real-part-polar (contents z)))
             (else (error "Unknown type -- REAL-PART" z))))

     (define (imag-part z)
       (cond ((rectangular? z)
              (imag-part-rectangular (contents z)))
             ((polar? z)
              (imag-part-polar (contents z)))
             (else (error "Unknown type -- IMAG-PART" z))))

     (define (magnitude z)
       (cond ((rectangular? z)
              (magnitude-rectangular (contents z)))
             ((polar? z)
              (magnitude-polar (contents z)))
             (else (error "Unknown type -- MAGNITUDE" z))))

     (define (angle z)
       (cond ((rectangular? z)
              (angle-rectangular (contents z)))
             ((polar? z)
              (angle-polar (contents z)))
             (else (error "Unknown type -- ANGLE" z))))

   To implement the complex-number arithmetic operations, we can use
the same procedures `add-complex', `sub-complex', `mul-complex', and
`div-complex' from section *note 2-4-1::, because the selectors they
call are generic, and so will work with either representation.  For
example, the procedure `add-complex' is still

     (define (add-complex z1 z2)
       (make-from-real-imag (+ (real-part z1) (real-part z2))
                            (+ (imag-part z1) (imag-part z2))))

   Finally, we must choose whether to construct complex numbers using
Ben's representation or Alyssa's representation.  One reasonable choice
is to construct rectangular numbers whenever we have real and imaginary
parts and to construct polar numbers whenever we have magnitudes and
angles:

     (define (make-from-real-imag x y)
       (make-from-real-imag-rectangular x y))

     (define (make-from-mag-ang r a)
       (make-from-mag-ang-polar r a))

     *Figure 2.21:* Structure of the generic complex-arithmetic system.

              +--------------------------------------------------+
          ----| add-complex sub-complex mul-complex- div-complex |----
              +--------------------------------------------------+
                          Complex arithmetic package
                           +-----------------------+
                           | real-part   imag-part |
          -----------------|                       |------------------
                           | magnitude   angle     |
                           +-----------+-----------+
                     Rectangular       |          Polar
                    representation     |     representation
          -----------------------------+------------------------------
                 List structure and primitive machine arithmetic

   The resulting complex-number system has the structure shown in *note
Figure 2-21::.  The system has been decomposed into three relatively
independent parts: the complex-number-arithmetic operations, Alyssa's
polar implementation, and Ben's rectangular implementation.  The polar
and rectangular implementations could have been written by Ben and
Alyssa working separately, and both of these can be used as underlying
representations by a third programmer implementing the
complex-arithmetic procedures in terms of the abstract
constructor/selector interface.

   Since each data object is tagged with its type, the selectors
operate on the data in a generic manner.  That is, each selector is
defined to have a behavior that depends upon the particular type of
data it is applied to.  Notice the general mechanism for interfacing
the separate representations: Within a given representation
implementation (say, Alyssa's polar package) a complex number is an
untyped pair (magnitude, angle).  When a generic selector operates on a
number of `polar' type, it strips off the tag and passes the contents on
to Alyssa's code.  Conversely, when Alyssa constructs a number for
general use, she tags it with a type so that it can be appropriately
recognized by the higher-level procedures.  This discipline of
stripping off and attaching tags as data objects are passed from level
to level can be an important organizational strategy, as we shall see
in section *note 2-5::.


File: sicp,  Node: 2-4-3,  Prev: 2-4-2,  Up: 2-4

2.4.3 Data-Directed Programming and Additivity
----------------------------------------------

The general strategy of checking the type of a datum and calling an
appropriate procedure is called "dispatching on type".  This is a
powerful strategy for obtaining modularity in system design.  Oh the
other hand, implementing the dispatch as in section *note 2-4-2:: has
two significant weaknesses.  One weakness is that the generic interface
procedures (`real-part', `imag-part', `magnitude', and `angle') must
know about all the different representations.  For instance, suppose we
wanted to incorporate a new representation for complex numbers into our
complex-number system.  We would need to identify this new
representation with a type, and then add a clause to each of the
generic interface procedures to check for the new type and apply the
appropriate selector for that representation.

   Another weakness of the technique is that even though the individual
representations can be designed separately, we must guarantee that no
two procedures in the entire system have the same name.  This is why
Ben and Alyssa had to change the names of their original procedures
from section *note 2-4-1::.

   The issue underlying both of these weaknesses is that the technique
for implementing generic interfaces is not "additive".  The person
implementing the generic selector procedures must modify those
procedures each time a new representation is installed, and the people
interfacing the individual representations must modify their code to
avoid name conflicts.  In each of these cases, the changes that must be
made to the code are straightforward, but they must be made
nonetheless, and this is a source of inconvenience and error.  This is
not much of a problem for the complex-number system as it stands, but
suppose there were not two but hundreds of different representations
for complex numbers.  And suppose that there were many generic
selectors to be maintained in the abstract-data interface.  Suppose, in
fact, that no one programmer knew all the interface procedures or all
the representations.  The problem is real and must be addressed in such
programs as large-scale data-base-management systems.

   What we need is a means for modularizing the system design even
further.  This is provided by the programming technique known as programming
"data-directed programming".  To understand how data-directed
programming works, begin with the observation that whenever we deal
with a set of generic operations that are common to a set of different
types we are, in effect, dealing with a two-dimensional table that
contains the possible operations on one axis and the possible types on
the other axis.  The entries in the table are the procedures that
implement each operation for each type of argument presented.  In the
complex-number system developed in the previous section, the
correspondence between operation name, data type, and actual procedure
was spread out among the various conditional clauses in the generic
interface procedures.  But the same information could have been
organized in a table, as shown in *note Figure 2-22::.

   Data-directed programming is the technique of designing programs to
work with such a table directly.  Previously, we implemented the
mechanism that interfaces the complex-arithmetic code with the two
representation packages as a set of procedures that each perform an
explicit dispatch on type.  Here we will implement the interface as a
single procedure that looks up the combination of the operation name
and argument type in the table to find the correct procedure to apply,
and then applies it to the contents of the argument.  If we do this,
then to add a new representation package to the system we need not
change any existing procedures; we need only add new entries to the
table.

     *Figure 2.22:* Table of operations for the complex-number system.

                     |               Types
          Operations | Polar           | Rectangular
          ===========+=================+======================
          real-part  | real-part-polar | real-part-rectangular
          imag-part  | imag-part-polar | imag-part-rectangular
          magnitude  | magnitude-polar | magnitude-rectangular
          angle      | angle-polar     | angle-rectangular

   To implement this plan, assume that we have two procedures, `put' and
`get', for manipulating the operation-and-type table:

   * `(put <OP> <TYPE> <ITEM>)' installs the `<ITEM>' in the table,
     indexed by the `<OP>' and the `<TYPE>'.

   * `(get <OP> <TYPE>)' looks up the `<OP>', `<TYPE>' entry in the
     table and returns the item found there.  If no item is found,
     `get' returns false.


   For now, we can assume that `put' and `get' are included in our
language.  In *note Chapter 3:: (section *note 3-3-3::, *note Exercise
3-24::) we will see how to implement these and other operations for
manipulating tables.

   Here is how data-directed programming can be used in the
complex-number system.  Ben, who developed the rectangular
representation, implements his code just as he did originally.  He
defines a collection of procedures, or a "package", and interfaces
these to the rest of the system by adding entries to the table that
tell the system how to operate on rectangular numbers.  This is
accomplished by calling the following procedure:

     (define (install-rectangular-package)
       ;; internal procedures
       (define (real-part z) (car z))
       (define (imag-part z) (cdr z))
       (define (make-from-real-imag x y) (cons x y))
       (define (magnitude z)
         (sqrt (+ (square (real-part z))
                  (square (imag-part z)))))
       (define (angle z)
         (atan (imag-part z) (real-part z)))
       (define (make-from-mag-ang r a)
         (cons (* r (cos a)) (* r (sin a))))

       ;; interface to the rest of the system
       (define (tag x) (attach-tag 'rectangular x))
       (put 'real-part '(rectangular) real-part)
       (put 'imag-part '(rectangular) imag-part)
       (put 'magnitude '(rectangular) magnitude)
       (put 'angle '(rectangular) angle)
       (put 'make-from-real-imag 'rectangular
            (lambda (x y) (tag (make-from-real-imag x y))))
       (put 'make-from-mag-ang 'rectangular
            (lambda (r a) (tag (make-from-mag-ang r a))))
       'done)

   Notice that the internal procedures here are the same procedures
from section *note 2-4-1:: that Ben wrote when he was working in
isolation.  No changes are necessary in order to interface them to the
rest of the system.  Moreover, since these procedure definitions are
internal to the installation procedure, Ben needn't worry about name
conflicts with other procedures outside the rectangular package.  To
interface these to the rest of the system, Ben installs his `real-part'
procedure under the operation name `real-part' and the type
`(rectangular)', and similarly for the other selectors.(1)  The
interface also defines the constructors to be used by the external
system.(2)  These are identical to Ben's internally defined
constructors, except that they attach the tag.

   Alyssa's polar package is analogous:

     (define (install-polar-package)
       ;; internal procedures
       (define (magnitude z) (car z))
       (define (angle z) (cdr z))
       (define (make-from-mag-ang r a) (cons r a))
       (define (real-part z)
         (* (magnitude z) (cos (angle z))))
       (define (imag-part z)
         (* (magnitude z) (sin (angle z))))
       (define (make-from-real-imag x y)
         (cons (sqrt (+ (square x) (square y)))
               (atan y x)))

       ;; interface to the rest of the system
       (define (tag x) (attach-tag 'polar x))
       (put 'real-part '(polar) real-part)
       (put 'imag-part '(polar) imag-part)
       (put 'magnitude '(polar) magnitude)
       (put 'angle '(polar) angle)
       (put 'make-from-real-imag 'polar
            (lambda (x y) (tag (make-from-real-imag x y))))
       (put 'make-from-mag-ang 'polar
            (lambda (r a) (tag (make-from-mag-ang r a))))
       'done)

   Even though Ben and Alyssa both still use their original procedures
defined with the same names as each other's (e.g., `real-part'), these
definitions are now internal to different procedures (see section *note
1-1-8::), so there is no name conflict.

   The complex-arithmetic selectors access the table by means of a
general "operation" procedure called `apply-generic', which applies a
generic operation to some arguments.  `Apply-generic' looks in the
table under the name of the operation and the types of the arguments
and applies the resulting procedure if one is present:(3)

     (define (apply-generic op . args)
       (let ((type-tags (map type-tag args)))
         (let ((proc (get op type-tags)))
           (if proc
               (apply proc (map contents args))
               (error
                 "No method for these types -- APPLY-GENERIC"
                 (list op type-tags))))))

   Using `apply-generic', we can define our generic selectors as
follows:

     (define (real-part z) (apply-generic 'real-part z))
     (define (imag-part z) (apply-generic 'imag-part z))
     (define (magnitude z) (apply-generic 'magnitude z))
     (define (angle z) (apply-generic 'angle z))

   Observe that these do not change at all if a new representation is
added to the system.

   We can also extract from the table the constructors to be used by
the programs external to the packages in making complex numbers from
real and imaginary parts and from magnitudes and angles.  As in section
*note 2-4-2::, we construct rectangular numbers whenever we have real
and imaginary parts, and polar numbers whenever we have magnitudes and
angles:

     (define (make-from-real-imag x y)
       ((get 'make-from-real-imag 'rectangular) x y))

     (define (make-from-mag-ang r a)
       ((get 'make-from-mag-ang 'polar) r a))

     *Exercise 2.73:* Section *note 2-3-2:: described a program that
     performs symbolic differentiation:

          (define (deriv exp var)
            (cond ((number? exp) 0)
                  ((variable? exp) (if (same-variable? exp var) 1 0))
                  ((sum? exp)
                   (make-sum (deriv (addend exp) var)
                             (deriv (augend exp) var)))
                  ((product? exp)
                   (make-sum
                     (make-product (multiplier exp)
                                   (deriv (multiplicand exp) var))
                     (make-product (deriv (multiplier exp) var)
                                   (multiplicand exp))))
                  <MORE RULES CAN BE ADDED HERE>
                  (else (error "unknown expression type -- DERIV" exp))))

     We can regard this program as performing a dispatch on the type of
     the expression to be differentiated.  In this situation the "type
     tag" of the datum is the algebraic operator symbol (such as `+')
     and the operation being performed is `deriv'.  We can transform
     this program into data-directed style by rewriting the basic
     derivative procedure as

          (define (deriv exp var)
             (cond ((number? exp) 0)
                   ((variable? exp) (if (same-variable? exp var) 1 0))
                   (else ((get 'deriv (operator exp)) (operands exp)
                                                      var))))

          (define (operator exp) (car exp))

          (define (operands exp) (cdr exp))

       a. Explain what was done above.  Why can't we assimilate the
          predicates `number?' and `same-variable?' into the
          data-directed dispatch?

       b. Write the procedures for derivatives of sums and products,
          and the auxiliary code required to install them in the table
          used by the program above.

       c. Choose any additional differentiation rule that you like,
          such as the one for exponents (*note Exercise 2-56::), and
          install it in this data-directed system.

       d. In this simple algebraic manipulator the type of an
          expression is the algebraic operator that binds it together.
          Suppose, however, we indexed the procedures in the opposite
          way, so that the dispatch line in `deriv' looked like

               ((get (operator exp) 'deriv) (operands exp) var)

          What corresponding changes to the derivative system are
          required?


     *Exercise 2.74:* Insatiable Enterprises, Inc., is a highly
     decentralized conglomerate company consisting of a large number of
     independent divisions located all over the world.  The company's
     computer facilities have just been interconnected by means of a
     clever network-interfacing scheme that makes the entire network
     appear to any user to be a single computer.  Insatiable's
     president, in her first attempt to exploit the ability of the
     network to extract administrative information from division files,
     is dismayed to discover that, although all the division files have
     been implemented as data structures in Scheme, the particular data
     structure used varies from division to division.  A meeting of
     division managers is hastily called to search for a strategy to
     integrate the files that will satisfy headquarters' needs while
     preserving the existing autonomy of the divisions.

     Show how such a strategy can be implemented with data-directed
     programming.  As an example, suppose that each division's
     personnel records consist of a single file, which contains a set
     of records keyed on employees' names.  The structure of the set
     varies from division to division.  Furthermore, each employee's
     record is itself a set (structured differently from division to
     division) that contains information keyed under identifiers such
     as `address' and `salary'.  In particular:

       a. Implement for headquarters a `get-record' procedure that
          retrieves a specified employee's record from a specified
          personnel file.  The procedure should be applicable to any
          division's file.  Explain how the individual divisions' files
          should be structured.  In particular, what type information
          must be supplied?

       b. Implement for headquarters a `get-salary' procedure that
          returns the salary information from a given employee's record
          from any division's personnel file.  How should the record be
          structured in order to make this operation work?

       c. Implement for headquarters a `find-employee-record'
          procedure.  This should search all the divisions' files for
          the record of a given employee and return the record.  Assume
          that this procedure takes as arguments an employee's name and
          a list of all the divisions' files.

       d. When Insatiable takes over a new company, what changes must
          be made in order to incorporate the new personnel information
          into the central system?


Message passing
...............

The key idea of data-directed programming is to handle generic
operations in programs by dealing explicitly with operation-and-type
tables, such as the table in *note Figure 2-22::.  The style of
programming we used in section *note 2-4-2:: organized the required
dispatching on type by having each operation take care of its own
dispatching.  In effect, this decomposes the operation-and-type table
into rows, with each generic operation procedure representing a row of
the table.

   An alternative implementation strategy is to decompose the table
into columns and, instead of using "intelligent operations" that
dispatch on data types, to work with "intelligent data objects" that
dispatch on operation names.  We can do this by arranging things so
that a data object, such as a rectangular number, is represented as a
procedure that takes as input the required operation name and performs
the operation indicated.  In such a discipline, `make-from-real-imag'
could be written as

     (define (make-from-real-imag x y)
       (define (dispatch op)
         (cond ((eq? op 'real-part) x)
               ((eq? op 'imag-part) y)
               ((eq? op 'magnitude)
                (sqrt (+ (square x) (square y))))
               ((eq? op 'angle) (atan y x))
               (else
                (error "Unknown op -- MAKE-FROM-REAL-IMAG" op))))
       dispatch)

   The corresponding `apply-generic' procedure, which applies a generic
operation to an argument, now simply feeds the operation's name to the
data object and lets the object do the work:(4)

     (define (apply-generic op arg) (arg op))

   Note that the value returned by `make-from-real-imag' is a
procedure--the internal `dispatch' procedure.  This is the procedure
that is invoked when `apply-generic' requests an operation to be
performed.

   This style of programming is called "message passing".  The name
comes from the image that a data object is an entity that receives the
requested operation name as a "message."  We have already seen an
example of message passing in section *note 2-1-3::, where we saw how
`cons', `car', and `cdr' could be defined with no data objects but only
procedures.  Here we see that message passing is not a mathematical
trick but a useful technique for organizing systems with generic
operations.  In the remainder of this chapter we will continue to use
data-directed programming, rather than message passing, to discuss
generic arithmetic operations.  In *note Chapter 3:: we will return to
message passing, and we will see that it can be a powerful tool for
structuring simulation programs.

     *Exercise 2.75:* Implement the constructor `make-from-mag-ang' in
     message-passing style.  This procedure should be analogous to the
     `make-from-real-imag' procedure given above.

     *Exercise 2.76:* As a large system with generic operations
     evolves, new types of data objects or new operations may be needed.
     For each of the three strategies--generic operations with explicit
     dispatch, data-directed style, and message-passing-style--describe
     the changes that must be made to a system in order to add new
     types or new operations.  Which organization would be most
     appropriate for a system in which new types must often be added?
     Which would be most appropriate for a system in which new
     operations must often be added?

   ---------- Footnotes ----------

   (1) We use the list `(rectangular)' rather than the symbol
`rectangular' to allow for the possibility of operations with multiple
arguments, not all of the same type.

   (2) The type the constructors are installed under needn't be a list
because a constructor is always used to make an object of one
particular type.

   (3) `Apply-generic' uses the dotted-tail notation described in *note
Exercise 2-20::, because different generic operations may take
different numbers of arguments.  In `apply-generic', `op' has as its
value the first argument to `apply-generic' and `args' has as its value
a list of the remaining arguments.

   `Apply-generic' also uses the primitive procedure `apply', which
takes two arguments, a procedure and a list.  `Apply' applies the
procedure, using the elements in the list as arguments.  For example,

     (apply + (list 1 2 3 4))

returns 10.

   (4) One limitation of this organization is it permits only generic
procedures of one argument.


File: sicp,  Node: 2-5,  Prev: 2-4,  Up: Chapter 2

2.5 Systems with Generic Operations
===================================

In the previous section, we saw how to design systems in which data
objects can be represented in more than one way.  The key idea is to
link the code that specifies the data operations to the several
representations by means of generic interface procedures.  Now we will
see how to use this same idea not only to define operations that are
generic over different representations but also to define operations
that are generic over different kinds of arguments.  We have already
seen several different packages of arithmetic operations: the primitive
arithmetic (`+', `-', `*', `/') built into our language, the
rational-number arithmetic (`add-rat', `sub-rat', `mul-rat', `div-rat')
of section *note 2-1-1::, and the complex-number arithmetic that we
implemented in section *note 2-4-3::.  We will now use data-directed
techniques to construct a package of arithmetic operations that
incorporates all the arithmetic packages we have already constructed.

   *note Figure 2-23:: shows the structure of the system we shall
build.  Notice the abstraction barriers.  From the perspective of
someone using "numbers," there is a single procedure `add' that
operates on whatever numbers are supplied.  `Add' is part of a generic
interface that allows the separate ordinary-arithmetic,
rational-arithmetic, and complex-arithmetic packages to be accessed
uniformly by programs that use numbers.  Any individual arithmetic
package (such as the complex package) may itself be accessed through
generic procedures (such as `add-complex') that combine packages
designed for different representations (such as rectangular and polar).
Moreover, the structure of the system is additive, so that one can
design the individual arithmetic packages separately and combine them
to produce a generic arithmetic system.

     *Figure 2.23:* Generic arithmetic system.

                                  Programs that use numbers
                                     +-----------------+
          ---------------------------| add sub mul div |-------------------
                                     +-----------------+
                                  Generic arithmetic package
           +-----------------+   +-------------------------+
           | add-rat sub-rat |   | add-complex sub-complex |   +---------+
          -|                 |-+-|                         |-+-| + - * / |-
           | mul-rat div-rat | | | mul-complex div-complex | | +---------+
           +-----------------+ | +-------------------------+ |
                Rational       |     Complex artithmetic     |   Ordinary
               arithmetic      +--------------+--------------+  arithmetic
                               | Rectangular  |     Polar    |
          ---------------------+--------------+--------------+-------------

* Menu:

* 2-5-1::            Generic Arithmetic Operations
* 2-5-2::            Combining Data of Different Types
* 2-5-3::            Example: Symbolic Algebra


File: sicp,  Node: 2-5-1,  Next: 2-5-2,  Prev: 2-5,  Up: 2-5

2.5.1 Generic Arithmetic Operations
-----------------------------------

The task of designing generic arithmetic operations is analogous to
that of designing the generic complex-number operations.  We would
like, for instance, to have a generic addition procedure `add' that
acts like ordinary primitive addition `+' on ordinary numbers, like
`add-rat' on rational numbers, and like `add-complex' on complex
numbers.  We can implement `add', and the other generic arithmetic
operations, by following the same strategy we used in section *note
2-4-3:: to implement the generic selectors for complex numbers.  We
will attach a type tag to each kind of number and cause the generic
procedure to dispatch to an appropriate package according to the data
type of its arguments.

   The generic arithmetic procedures are defined as follows:

     (define (add x y) (apply-generic 'add x y))
     (define (sub x y) (apply-generic 'sub x y))
     (define (mul x y) (apply-generic 'mul x y))
     (define (div x y) (apply-generic 'div x y))

   We begin by installing a package for handling "ordinary" numbers,
that is, the primitive numbers of our language.  We will tag these with
the symbol `scheme-number'.  The arithmetic operations in this package
are the primitive arithmetic procedures (so there is no need to define
extra procedures to handle the untagged numbers).  Since these
operations each take two arguments, they are installed in the table
keyed by the list `(scheme-number scheme-number)':

     (define (install-scheme-number-package)
       (define (tag x)
         (attach-tag 'scheme-number x))
       (put 'add '(scheme-number scheme-number)
            (lambda (x y) (tag (+ x y))))
       (put 'sub '(scheme-number scheme-number)
            (lambda (x y) (tag (- x y))))
       (put 'mul '(scheme-number scheme-number)
            (lambda (x y) (tag (* x y))))
       (put 'div '(scheme-number scheme-number)
            (lambda (x y) (tag (/ x y))))
       (put 'make 'scheme-number
            (lambda (x) (tag x)))
       'done)

   Users of the Scheme-number package will create (tagged) ordinary
numbers by means of the procedure:

     (define (make-scheme-number n)
       ((get 'make 'scheme-number) n))

   Now that the framework of the generic arithmetic system is in place,
we can readily include new kinds of numbers.  Here is a package that
performs rational arithmetic.  Notice that, as a benefit of additivity,
we can use without modification the rational-number code from section
*note 2-1-1:: as the internal procedures in the package:

     (define (install-rational-package)
       ;; internal procedures
       (define (numer x) (car x))
       (define (denom x) (cdr x))
       (define (make-rat n d)
         (let ((g (gcd n d)))
           (cons (/ n g) (/ d g))))
       (define (add-rat x y)
         (make-rat (+ (* (numer x) (denom y))
                      (* (numer y) (denom x)))
                   (* (denom x) (denom y))))
       (define (sub-rat x y)
         (make-rat (- (* (numer x) (denom y))
                      (* (numer y) (denom x)))
                   (* (denom x) (denom y))))
       (define (mul-rat x y)
         (make-rat (* (numer x) (numer y))
                   (* (denom x) (denom y))))
       (define (div-rat x y)
         (make-rat (* (numer x) (denom y))
                   (* (denom x) (numer y))))

       ;; interface to rest of the system
       (define (tag x) (attach-tag 'rational x))
       (put 'add '(rational rational)
            (lambda (x y) (tag (add-rat x y))))
       (put 'sub '(rational rational)
            (lambda (x y) (tag (sub-rat x y))))
       (put 'mul '(rational rational)
            (lambda (x y) (tag (mul-rat x y))))
       (put 'div '(rational rational)
            (lambda (x y) (tag (div-rat x y))))

       (put 'make 'rational
            (lambda (n d) (tag (make-rat n d))))
       'done)

     (define (make-rational n d)
       ((get 'make 'rational) n d))

   We can install a similar package to handle complex numbers, using
the tag `complex'.  In creating the package, we extract from the table
the operations `make-from-real-imag' and `make-from-mag-ang' that were
defined by the rectangular and polar packages.  Additivity permits us
to use, as the internal operations, the same `add-complex',
`sub-complex', `mul-complex', and `div-complex' procedures from section
*note 2-4-1::.

     (define (install-complex-package)
       ;; imported procedures from rectangular and polar packages
       (define (make-from-real-imag x y)
         ((get 'make-from-real-imag 'rectangular) x y))
       (define (make-from-mag-ang r a)
         ((get 'make-from-mag-ang 'polar) r a))

       ;; internal procedures
       (define (add-complex z1 z2)
         (make-from-real-imag (+ (real-part z1) (real-part z2))
                              (+ (imag-part z1) (imag-part z2))))
       (define (sub-complex z1 z2)
         (make-from-real-imag (- (real-part z1) (real-part z2))
                              (- (imag-part z1) (imag-part z2))))
       (define (mul-complex z1 z2)
         (make-from-mag-ang (* (magnitude z1) (magnitude z2))
                            (+ (angle z1) (angle z2))))
       (define (div-complex z1 z2)
         (make-from-mag-ang (/ (magnitude z1) (magnitude z2))
                            (- (angle z1) (angle z2))))

       ;; interface to rest of the system
       (define (tag z) (attach-tag 'complex z))
       (put 'add '(complex complex)
            (lambda (z1 z2) (tag (add-complex z1 z2))))
       (put 'sub '(complex complex)
            (lambda (z1 z2) (tag (sub-complex z1 z2))))
       (put 'mul '(complex complex)
            (lambda (z1 z2) (tag (mul-complex z1 z2))))
       (put 'div '(complex complex)
            (lambda (z1 z2) (tag (div-complex z1 z2))))
       (put 'make-from-real-imag 'complex
            (lambda (x y) (tag (make-from-real-imag x y))))
       (put 'make-from-mag-ang 'complex
            (lambda (r a) (tag (make-from-mag-ang r a))))
       'done)

   Programs outside the complex-number package can construct complex
numbers either from real and imaginary parts or from magnitudes and
angles.  Notice how the underlying procedures, originally defined in
the rectangular and polar packages, are exported to the complex
package, and exported from there to the outside world.

     (define (make-complex-from-real-imag x y)
       ((get 'make-from-real-imag 'complex) x y))

     (define (make-complex-from-mag-ang r a)
       ((get 'make-from-mag-ang 'complex) r a))

   What we have here is a two-level tag system.  A typical complex
number, such as 3 + 4i in rectangular form, would be represented as
shown in *note Figure 2-24::.  The outer tag (`complex') is used to
direct the number to the complex package.  Once within the complex
package, the next tag (`rectangular') is used to direct the number to
the rectangular package.  In a large and complicated system there might
be many levels, each interfaced with the next by means of generic
operations.  As a data object is passed "downward," the outer tag that
is used to direct it to the appropriate package is stripped off (by
applying `contents') and the next level of tag (if any) becomes visible
to be used for further dispatching.

     *Figure 2.24:* Representation of 3 + 4i in rectangular form.

               +---+---+     +---+---+     +---+---+
          ---->| * | *-+---->| * | *-+---->| * | * |
               +-|-+---+     +-|-+---+     +-|-+-|-+
                 |             |             |   |
                 V             V             V   V
           +---------+   +-------------+  +---+ +---+
           | complex |   | rectangular |  | 3 | | 4 |
           +---------+   +-------------+  +---+ +---+

   In the above packages, we used `add-rat', `add-complex', and the
other arithmetic procedures exactly as originally written.  Once these
definitions are internal to different installation procedures, however,
they no longer need names that are distinct from each other: we could
simply name them `add', `sub', `mul', and `div' in both packages.

     *Exercise 2.77:* Louis Reasoner tries to evaluate the expression
     `(magnitude z)' where `z' is the object shown in *note Figure
     2-24::.  To his surprise, instead of the answer 5 he gets an error
     message from `apply-generic', saying there is no method for the
     operation `magnitude' on the types `(complex)'.  He shows this
     interaction to Alyssa P. Hacker, who says "The problem is that the
     complex-number selectors were never defined for `complex' numbers,
     just for `polar' and `rectangular' numbers.  All you have to do to
     make this work is add the following to the `complex' package:"

          (put 'real-part '(complex) real-part)
          (put 'imag-part '(complex) imag-part)
          (put 'magnitude '(complex) magnitude)
          (put 'angle '(complex) angle)

     Describe in detail why this works.  As an example, trace through
     all the procedures called in evaluating the expression `(magnitude
     z)' where `z' is the object shown in *note Figure 2-24::.  In
     particular, how many times is `apply-generic' invoked?  What
     procedure is dispatched to in each case?

     *Exercise 2.78:* The internal procedures in the `scheme-number'
     package are essentially nothing more than calls to the primitive
     procedures `+', `-', etc.  It was not possible to use the
     primitives of the language directly because our type-tag system
     requires that each data object have a type attached to it.  In
     fact, however, all Lisp implementations do have a type system,
     which they use internally.  Primitive predicates such as `symbol?'
     and `number?'  determine whether data objects have particular
     types.  Modify the definitions of `type-tag', `contents', and
     `attach-tag' from section *note 2-4-2:: so that our generic system
     takes advantage of Scheme's internal type system.  That is to say,
     the system should work as before except that ordinary numbers
     should be represented simply as Scheme numbers rather than as
     pairs whose `car' is the symbol `scheme-number'.

     *Exercise 2.79:* Define a generic equality predicate `equ?' that
     tests the equality of two numbers, and install it in the generic
     arithmetic package.  This operation should work for ordinary
     numbers, rational numbers, and complex numbers.

     *Exercise 2.80:* Define a generic predicate `=zero?' that tests if
     its argument is zero, and install it in the generic arithmetic
     package.  This operation should work for ordinary numbers, rational
     numbers, and complex numbers.


File: sicp,  Node: 2-5-2,  Next: 2-5-3,  Prev: 2-5-1,  Up: 2-5

2.5.2 Combining Data of Different Types
---------------------------------------

We have seen how to define a unified arithmetic system that encompasses
ordinary numbers, complex numbers, rational numbers, and any other type
of number we might decide to invent, but we have ignored an important
issue.  The operations we have defined so far treat the different data
types as being completely independent.  Thus, there are separate
packages for adding, say, two ordinary numbers, or two complex numbers.
What we have not yet considered is the fact that it is meaningful to
define operations that cross the type boundaries, such as the addition
of a complex number to an ordinary number.  We have gone to great pains
to introduce barriers between parts of our programs so that they can be
developed and understood separately.  We would like to introduce the
cross-type operations in some carefully controlled way, so that we can
support them without seriously violating our module boundaries.

   One way to handle cross-type operations is to design a different
procedure for each possible combination of types for which the
operation is valid.  For example, we could extend the complex-number
package so that it provides a procedure for adding complex numbers to
ordinary numbers and installs this in the table using the tag `(complex
scheme-number)':(1)

     ;; to be included in the complex package
     (define (add-complex-to-schemenum z x)
       (make-from-real-imag (+ (real-part z) x)
                            (imag-part z)))

     (put 'add '(complex scheme-number)
          (lambda (z x) (tag (add-complex-to-schemenum z x))))

   This technique works, but it is cumbersome.  With such a system, the
cost of introducing a new type is not just the construction of the
package of procedures for that type but also the construction and
installation of the procedures that implement the cross-type
operations.  This can easily be much more code than is needed to define
the operations on the type itself.  The method also undermines our
ability to combine separate packages additively, or least to limit the
extent to which the implementors of the individual packages need to
take account of other packages.  For instance, in the example above, it
seems reasonable that handling mixed operations on complex numbers and
ordinary numbers should be the responsibility of the complex-number
package.  Combining rational numbers and complex numbers, however,
might be done by the complex package, by the rational package, or by
some third package that uses operations extracted from these two
packages.  Formulating coherent policies on the division of
responsibility among packages can be an overwhelming task in designing
systems with many packages and many cross-type operations.

Coercion
........

In the general situation of completely unrelated operations acting on
completely unrelated types, implementing explicit cross-type operations,
cumbersome though it may be, is the best that one can hope for.
Fortunately, we can usually do better by taking advantage of additional
structure that may be latent in our type system.  Often the different
data types are not completely independent, and there may be ways by
which objects of one type may be viewed as being of another type.  This
process is called "coercion".  For example, if we are asked to
arithmetically combine an ordinary number with a complex number, we can
view the ordinary number as a complex number whose imaginary part is
zero.  This transforms the problem to that of combining two complex
numbers, which can be handled in the ordinary way by the
complex-arithmetic package.

   In general, we can implement this idea by designing coercion
procedures that transform an object of one type into an equivalent
object of another type.  Here is a typical coercion procedure, which
transforms a given ordinary number to a complex number with that real
part and zero imaginary part:

     (define (scheme-number->complex n)
       (make-complex-from-real-imag (contents n) 0))

   We install these coercion procedures in a special coercion table,
indexed under the names of the two types:

     (put-coercion 'scheme-number 'complex scheme-number->complex)

   (We assume that there are `put-coercion' and `get-coercion'
procedures available for manipulating this table.)  Generally some of
the slots in the table will be empty, because it is not generally
possible to coerce an arbitrary data object of each type into all other
types.  For example, there is no way to coerce an arbitrary complex
number to an ordinary number, so there will be no general
`complex->scheme-number' procedure included in the table.

   Once the coercion table has been set up, we can handle coercion in a
uniform manner by modifying the `apply-generic' procedure of section
*note 2-4-3::.  When asked to apply an operation, we first check
whether the operation is defined for the arguments' types, just as
before.  If so, we dispatch to the procedure found in the
operation-and-type table.  Otherwise, we try coercion.  For simplicity,
we consider only the case where there are two arguments.(2)  We check
the coercion table to see if objects of the first type can be coerced
to the second type.  If so, we coerce the first argument and try the
operation again.  If objects of the first type cannot in general be
coerced to the second type, we try the coercion the other way around to
see if there is a way to coerce the second argument to the type of the
first argument.  Finally, if there is no known way to coerce either
type to the other type, we give up.  Here is the procedure:

     (define (apply-generic op . args)
       (let ((type-tags (map type-tag args)))
         (let ((proc (get op type-tags)))
           (if proc
               (apply proc (map contents args))
               (if (= (length args) 2)
                   (let ((type1 (car type-tags))
                         (type2 (cadr type-tags))
                         (a1 (car args))
                         (a2 (cadr args)))
                     (let ((t1->t2 (get-coercion type1 type2))
                           (t2->t1 (get-coercion type2 type1)))
                       (cond (t1->t2
                              (apply-generic op (t1->t2 a1) a2))
                             (t2->t1
                              (apply-generic op a1 (t2->t1 a2)))
                             (else
                              (error "No method for these types"
                                     (list op type-tags))))))
                   (error "No method for these types"
                          (list op type-tags)))))))

   This coercion scheme has many advantages over the method of defining
explicit cross-type operations, as outlined above.  Although we still
need to write coercion procedures to relate the types (possibly n^2
procedures for a system with n types), we need to write only one
procedure for each pair of types rather than a different procedure for
each collection of types and each generic operation.(3)  What we are
counting on here is the fact that the appropriate transformation
between types depends only on the types themselves, not on the
operation to be applied.

   On the other hand, there may be applications for which our coercion
scheme is not general enough.  Even when neither of the objects to be
combined can be converted to the type of the other it may still be
possible to perform the operation by converting both objects to a third
type.  In order to deal with such complexity and still preserve
modularity in our programs, it is usually necessary to build systems
that take advantage of still further structure in the relations among
types, as we discuss next.

Hierarchies of types
....................

The coercion scheme presented above relied on the existence of natural
relations between pairs of types.  Often there is more "global"
structure in how the different types relate to each other.  For
instance, suppose we are building a generic arithmetic system to handle
integers, rational numbers, real numbers, and complex numbers.  In such
a system, it is quite natural to regard an integer as a special kind of
rational number, which is in turn a special kind of real number, which
is in turn a special kind of complex number.  What we actually have is
a so-called "hierarchy of types", in which, for example, integers are a "subtype"
of rational numbers (i.e., any operation that can be applied to a
rational number can automatically be applied to an integer).
Conversely, we say that rational numbers form a "supertype" of
integers.  The particular hierarchy we have here is of a very simple
kind, in which each type has at most one supertype and at most one
subtype.  Such a structure, called a "tower", is illustrated in *note
Figure 2-25::.

     *Figure 2.25:* A tower of types.

           complex
             ^
             |
            real
             ^
             |
          rational
             ^
             |
          integer

   If we have a tower structure, then we can greatly simplify the
problem of adding a new type to the hierarchy, for we need only specify
how the new type is embedded in the next supertype above it and how it
is the supertype of the type below it.  For example, if we want to add
an integer to a complex number, we need not explicitly define a special
coercion procedure `integer->complex'.  Instead, we define how an
integer can be transformed into a rational number, how a rational
number is transformed into a real number, and how a real number is
transformed into a complex number.  We then allow the system to
transform the integer into a complex number through these steps and
then add the two complex numbers.

   We can redesign our `apply-generic' procedure in the following way:
For each type, we need to supply a `raise' procedure, which "raises"
objects of that type one level in the tower.  Then when the system is
required to operate on objects of different types it can successively
raise the lower types until all the objects are at the same level in
the tower.  (*note Exercise 2-83:: and *note Exercise 2-84:: concern
the details of implementing such a strategy.)

   Another advantage of a tower is that we can easily implement the
notion that every type "inherits" all operations defined on a
supertype.  For instance, if we do not supply a special procedure for
finding the real part of an integer, we should nevertheless expect that
`real-part' will be defined for integers by virtue of the fact that
integers are a subtype of complex numbers.  In a tower, we can arrange
for this to happen in a uniform way by modifying `apply-generic'.  If
the required operation is not directly defined for the type of the
object given, we raise the object to its supertype and try again.  We
thus crawl up the tower, transforming our argument as we go, until we
either find a level at which the desired operation can be performed or
hit the top (in which case we give up).

   Yet another advantage of a tower over a more general hierarchy is
that it gives us a simple way to "lower" a data object to the simplest
representation.  For example, if we add 2 + 3i to 4 - 3i, it would be
nice to obtain the answer as the integer 6 rather than as the complex
number 6 + 0i.  *note Exercise 2-85:: discusses a way to implement such
a lowering operation.  (The trick is that we need a general way to
distinguish those objects that can be lowered, such as 6 + 0i, from
those that cannot, such as 6 + 2i.)

     *Figure 2.26:* Relations among types of geometric figures.

                               polygon
                              /       \
                             /         \
                      triangle         quadrilateral
                      /     \              /     \
                     /       \            /       \
               isosceles   right      trapezoid   kite
               triangle    triangle       |         |
                |     \      |            |         |
                |      \     |            |         |
          equilateral   isosceles   parallelogram   |
          triangle      right          |       \    |
                        triangle       |        \   |
                                    rectangle  rhombus
                                          \    /
                                           \  /
                                          square

Inadequacies of hierarchies
...........................

If the data types in our system can be naturally arranged in a tower,
this greatly simplifies the problems of dealing with generic operations
on different types, as we have seen.  Unfortunately, this is usually
not the case.  *note Figure 2-26:: illustrates a more complex
arrangement of mixed types, this one showing relations among different
types of geometric figures.  We see that, in general, a type may have
more than one subtype.  Triangles and quadrilaterals, for instance, are
both subtypes of polygons.  In addition, a type may have more than one
supertype.  For example, an isosceles right triangle may be regarded
either as an isosceles triangle or as a right triangle.  This
multiple-supertypes issue is particularly thorny, since it means that
there is no unique way to "raise" a type in the hierarchy.  Finding the
"correct" supertype in which to apply an operation to an object may
involve considerable searching through the entire type network on the
part of a procedure such as `apply-generic'.  Since there generally are
multiple subtypes for a type, there is a similar problem in coercing a
value "down" the type hierarchy.  Dealing with large numbers of
interrelated types while still preserving modularity in the design of
large systems is very difficult, and is an area of much current
research.(4)

     *Exercise 2.81:* Louis Reasoner has noticed that `apply-generic'
     may try to coerce the arguments to each other's type even if they
     already have the same type.  Therefore, he reasons, we need to put
     procedures in the coercion table to "coerce" arguments of each
     type to their own type.  For example, in addition to the
     `scheme-number->complex' coercion shown above, he would do:

          (define (scheme-number->scheme-number n) n)
          (define (complex->complex z) z)
          (put-coercion 'scheme-number 'scheme-number
                        scheme-number->scheme-number)
          (put-coercion 'complex 'complex complex->complex)

       a. With Louis's coercion procedures installed, what happens if
          `apply-generic' is called with two arguments of type
          `scheme-number' or two arguments of type `complex' for an
          operation that is not found in the table for those types?
          For example, assume that we've defined a generic
          exponentiation operation:

               (define (exp x y) (apply-generic 'exp x y))

          and have put a procedure for exponentiation in the
          Scheme-number package but not in any other package:

               ;; following added to Scheme-number package
               (put 'exp '(scheme-number scheme-number)
                    (lambda (x y) (tag (expt x y)))) ; using primitive `expt'

          What happens if we call `exp' with two complex numbers as
          arguments?

       b. Is Louis correct that something had to be done about coercion
          with arguments of the same type, or does `apply-generic' work
          correctly as is?

       c. Modify `apply-generic' so that it doesn't try coercion if the
          two arguments have the same type.


     *Exercise 2.82:* Show how to generalize `apply-generic' to handle
     coercion in the general case of multiple arguments.  One strategy
     is to attempt to coerce all the arguments to the type of the first
     argument, then to the type of the second argument, and so on.
     Give an example of a situation where this strategy (and likewise
     the two-argument version given above) is not sufficiently general.
     (Hint: Consider the case where there are some suitable mixed-type
     operations present in the table that will not be tried.)

     *Exercise 2.83:* Suppose you are designing a generic arithmetic
     system for dealing with the tower of types shown in *note Figure
     2-25::: integer, rational, real, complex.  For each type (except
     complex), design a procedure that raises objects of that type one
     level in the tower.  Show how to install a generic `raise'
     operation that will work for each type (except complex).

     *Exercise 2.84:* Using the `raise' operation of *note Exercise
     2-83::, modify the `apply-generic' procedure so that it coerces
     its arguments to have the same type by the method of successive
     raising, as discussed in this section.  You will need to devise a
     way to test which of two types is higher in the tower.  Do this in
     a manner that is "compatible" with the rest of the system and will
     not lead to problems in adding new levels to the tower.

     *Exercise 2.85:* This section mentioned a method for "simplifying"
     a data object by lowering it in the tower of types as far as
     possible.  Design a procedure `drop' that accomplishes this for the
     tower described in *note Exercise 2-83::.  The key is to decide,
     in some general way, whether an object can be lowered.  For
     example, the complex number 1.5 + 0i can be lowered as far as
     `real', the complex number 1 + 0i can be lowered as far as
     `integer', and the complex number 2 + 3i cannot be lowered at all.
     Here is a plan for determining whether an object can be lowered:
     Begin by defining a generic operation `project' that "pushes" an
     object down in the tower.  For example, projecting a complex
     number would involve throwing away the imaginary part.  Then a
     number can be dropped if, when we `project' it and `raise' the
     result back to the type we started with, we end up with something
     equal to what we started with.  Show how to implement this idea in
     detail, by writing a `drop' procedure that drops an object as far
     as possible.  You will need to design the various projection
     operations(5) and install `project' as a generic operation in the
     system.  You will also need to make use of a generic equality
     predicate, such as described in *note Exercise 2-79::.  Finally,
     use `drop' to rewrite `apply-generic' from *note Exercise 2-84::
     so that it "simplifies" its answers.

     *Exercise 2.86:* Suppose we want to handle complex numbers whose
     real parts, imaginary parts, magnitudes, and angles can be either
     ordinary numbers, rational numbers, or other numbers we might wish
     to add to the system.  Describe and implement the changes to the
     system needed to accommodate this.  You will have to define
     operations such as `sine' and `cosine' that are generic over
     ordinary numbers and rational numbers.

   ---------- Footnotes ----------

   (1) We also have to supply an almost identical procedure to handle
the types `(scheme-number complex)'.

   (2) See *note Exercise 2-82:: for generalizations.

   (3) If we are clever, we can usually get by with fewer than n^2
coercion procedures.  For instance, if we know how to convert from type
1 to type 2 and from type 2 to type 3, then we can use this knowledge to
convert from type 1 to type 3.  This can greatly decrease the number of
coercion procedures we need to supply explicitly when we add a new type
to the system.  If we are willing to build the required amount of
sophistication into our system, we can have it search the "graph" of
relations among types and automatically generate those coercion
procedures that can be inferred from the ones that are supplied
explicitly.

   (4) This statement, which also appears in the first edition of this
book, is just as true now as it was when we wrote it twelve years ago.
Developing a useful, general framework for expressing the relations
among different types of entities (what philosophers call "ontology")
seems intractably difficult.  The main difference between the confusion
that existed ten years ago and the confusion that exists now is that
now a variety of inadequate ontological theories have been embodied in
a plethora of correspondingly inadequate programming languages.  For
example, much of the complexity of object-oriented programming
languages--and the subtle and confusing differences among contemporary
object-oriented languages--centers on the treatment of generic
operations on interrelated types.  Our own discussion of computational
objects in *note Chapter 3:: avoids these issues entirely.  Readers
familiar with object-oriented programming will notice that we have much
to say in *note Chapter 3:: about local state, but we do not even
mention "classes" or "inheritance."  In fact, we suspect that these
problems cannot be adequately addressed in terms of computer-language
design alone, without also drawing on work in knowledge representation
and automated reasoning.

   (5) A real number can be projected to an integer using the `round'
primitive, which returns the closest integer to its argument.


File: sicp,  Node: 2-5-3,  Prev: 2-5-2,  Up: 2-5

2.5.3 Example: Symbolic Algebra
-------------------------------

The manipulation of symbolic algebraic expressions is a complex process
that illustrates many of the hardest problems that occur in the design
of large-scale systems.  An algebraic expression, in general, can be
viewed as a hierarchical structure, a tree of operators applied to
operands.  We can construct algebraic expressions by starting with a
set of primitive objects, such as constants and variables, and
combining these by means of algebraic operators, such as addition and
multiplication.  As in other languages, we form abstractions that
enable us to refer to compound objects in simple terms.  Typical
abstractions in symbolic algebra are ideas such as linear combination,
polynomial, rational function, or trigonometric function.  We can
regard these as compound "types," which are often useful for directing
the processing of expressions.  For example, we could describe the
expression

     x^2 sin (y^2 + 1) + r cos 2y + cos(y^3 - 2y^2)

as a polynomial in x with coefficients that are trigonometric functions
of polynomials in y whose coefficients are integers.

   We will not attempt to develop a complete algebraic-manipulation
system here.  Such systems are exceedingly complex programs, embodying
deep algebraic knowledge and elegant algorithms.  What we will do is
look at a simple but important part of algebraic manipulation: the
arithmetic of polynomials.  We will illustrate the kinds of decisions
the designer of such a system faces, and how to apply the ideas of
abstract data and generic operations to help organize this effort.

Arithmetic on polynomials
.........................

Our first task in designing a system for performing arithmetic on
polynomials is to decide just what a polynomial is.  Polynomials are
normally defined relative to certain variables (the "indeterminates" of
the polynomial).  For simplicity, we will restrict ourselves to
polynomials having just one indeterminate ("univariate
polynomials").(1) We will define a polynomial to be a sum of terms,
each of which is either a coefficient, a power of the indeterminate, or
a product of a coefficient and a power of the indeterminate.  A
coefficient is defined as an algebraic expression that is not dependent
upon the indeterminate of the polynomial.  For example,

     5x^2 + 3r + 7

is a simple polynomial in x, and

     (y^2 + 1)r^3 + (2y)x + 1

is a polynomial in x whose coefficients are polynomials in y.

   Already we are skirting some thorny issues.  Is the first of these
polynomials the same as the polynomial 5y^2 + 3y + 7, or not?  A
reasonable answer might be "yes, if we are considering a polynomial
purely as a mathematical function, but no, if we are considering a
polynomial to be a syntactic form."  The second polynomial is
algebraically equivalent to a polynomial in y whose coefficients are
polynomials in x.  Should our system recognize this, or not?
Furthermore, there are other ways to represent a polynomial--for
example, as a product of factors, or (for a univariate polynomial) as
the set of roots, or as a listing of the values of the polynomial at a
specified set of points.(2)  We can finesse these questions by deciding
that in our algebraic-manipulation system a "polynomial" will be a
particular syntactic form, not its underlying mathematical meaning.

   Now we must consider how to go about doing arithmetic on
polynomials.  In this simple system, we will consider only addition and
multiplication.  Moreover, we will insist that two polynomials to be
combined must have the same indeterminate.

   We will approach the design of our system by following the familiar
discipline of data abstraction.  We will represent polynomials using a
data structure called a "poly", which consists of a variable and a
collection of terms.  We assume that we have selectors `variable' and
`term-list' that extract those parts from a poly and a constructor
`make-poly' that assembles a poly from a given variable and a term
list.  A variable will be just a symbol, so we can use the
`same-variable?'  procedure of section *note 2-3-2:: to compare
variables.  The following procedures define addition and multiplication
of polys:

     (define (add-poly p1 p2)
       (if (same-variable? (variable p1) (variable p2))
           (make-poly (variable p1)
                      (add-terms (term-list p1)
                                 (term-list p2)))
           (error "Polys not in same var -- ADD-POLY"
                  (list p1 p2))))

     (define (mul-poly p1 p2)
       (if (same-variable? (variable p1) (variable p2))
           (make-poly (variable p1)
                      (mul-terms (term-list p1)
                                 (term-list p2)))
           (error "Polys not in same var -- MUL-POLY"
                  (list p1 p2))))

   To incorporate polynomials into our generic arithmetic system, we
need to supply them with type tags.  We'll use the tag `polynomial',
and install appropriate operations on tagged polynomials in the
operation table.  We'll embed all our code in an installation procedure
for the polynomial package, similar to the ones in section *note
2-5-1:::

     (define (install-polynomial-package)
       ;; internal procedures
       ;; representation of poly
       (define (make-poly variable term-list)
         (cons variable term-list))
       (define (variable p) (car p))
       (define (term-list p) (cdr p))
       <_procedures `same-variable?' and `variable?' from section 2.3.2_>

       ;; representation of terms and term lists
       <_procedures `adjoin-term' ... `coeff' from text below_>

       ;; continued on next page

       (define (add-poly p1 p2) ...)
       <_procedures used by `add-poly'_>
       (define (mul-poly p1 p2) ...)
       <_procedures used by `mul-poly'_>

       ;; interface to rest of the system
       (define (tag p) (attach-tag 'polynomial p))
       (put 'add '(polynomial polynomial)
            (lambda (p1 p2) (tag (add-poly p1 p2))))
       (put 'mul '(polynomial polynomial)
            (lambda (p1 p2) (tag (mul-poly p1 p2))))
       (put 'make 'polynomial
            (lambda (var terms) (tag (make-poly var terms))))
       'done)

   Polynomial addition is performed termwise.  Terms of the same order
(i.e., with the same power of the indeterminate) must be combined.
This is done by forming a new term of the same order whose coefficient
is the sum of the coefficients of the addends.  Terms in one addend for
which there are no terms of the same order in the other addend are
simply accumulated into the sum polynomial being constructed.

   In order to manipulate term lists, we will assume that we have a
constructor `the-empty-termlist' that returns an empty term list and a
constructor `adjoin-term' that adjoins a new term to a term list.  We
will also assume that we have a predicate `empty-termlist?' that tells
if a given term list is empty, a selector `first-term' that extracts
the highest-order term from a term list, and a selector `rest-terms'
that returns all but the highest-order term.  To manipulate terms, we
will suppose that we have a constructor `make-term' that constructs a
term with given order and coefficient, and selectors `order' and
`coeff' that return, respectively, the order and the coefficient of the
term.  These operations allow us to consider both terms and term lists
as data abstractions, whose concrete representations we can worry about
separately.

   Here is the procedure that constructs the term list for the sum of
two polynomials:(3)

     (define (add-terms L1 L2)
       (cond ((empty-termlist? L1) L2)
             ((empty-termlist? L2) L1)
             (else
              (let ((t1 (first-term L1)) (t2 (first-term L2)))
                (cond ((> (order t1) (order t2))
                       (adjoin-term
                        t1 (add-terms (rest-terms L1) L2)))
                      ((< (order t1) (order t2))
                       (adjoin-term
                        t2 (add-terms L1 (rest-terms L2))))
                      (else
                       (adjoin-term
                        (make-term (order t1)
                                   (add (coeff t1) (coeff t2)))
                        (add-terms (rest-terms L1)
                                   (rest-terms L2)))))))))

   The most important point to note here is that we used the generic
addition procedure `add' to add together the coefficients of the terms
being combined.  This has powerful consequences, as we will see below.

   In order to multiply two term lists, we multiply each term of the
first list by all the terms of the other list, repeatedly using
`mul-term-by-all-terms', which multiplies a given term by all terms in
a given term list.  The resulting term lists (one for each term of the
first list) are accumulated into a sum.  Multiplying two terms forms a
term whose order is the sum of the orders of the factors and whose
coefficient is the product of the coefficients of the factors:

     (define (mul-terms L1 L2)
       (if (empty-termlist? L1)
           (the-empty-termlist)
           (add-terms (mul-term-by-all-terms (first-term L1) L2)
                      (mul-terms (rest-terms L1) L2))))

     (define (mul-term-by-all-terms t1 L)
       (if (empty-termlist? L)
           (the-empty-termlist)
           (let ((t2 (first-term L)))
             (adjoin-term
              (make-term (+ (order t1) (order t2))
                         (mul (coeff t1) (coeff t2)))
              (mul-term-by-all-terms t1 (rest-terms L))))))

   This is really all there is to polynomial addition and
multiplication.  Notice that, since we operate on terms using the
generic procedures `add' and `mul', our polynomial package is
automatically able to handle any type of coefficient that is known
about by the generic arithmetic package.  If we include a coercion
mechanism such as one of those discussed in section *note 2-5-2::, then
we also are automatically able to handle operations on polynomials of
different coefficient types, such as

                              /        2                 \
     [3x^2 + (2 + 3i)x + 7] * | x^4 + --- x^2 + (5 + 3i) |
                              \        3                 /

   Because we installed the polynomial addition and multiplication
procedures `add-poly' and `mul-poly' in the generic arithmetic system
as the `add' and `mul' operations for type `polynomial', our system is
also automatically able to handle polynomial operations such as

     [(y + 1)x^2 + (y^2 + 1)x + (y - 1)] * [(y - 2)x + (y^3 + 7)]

   The reason is that when the system tries to combine coefficients, it
will dispatch through `add' and `mul'.  Since the coefficients are
themselves polynomials (in y), these will be combined using `add-poly'
and `mul-poly'.  The result is a kind of "data-directed recursion" in
which, for example, a call to `mul-poly' will result in recursive calls
to `mul-poly' in order to multiply the coefficients.  If the
coefficients of the coefficients were themselves polynomials (as might
be used to represent polynomials in three variables), the data
direction would ensure that the system would follow through another
level of recursive calls, and so on through as many levels as the
structure of the data dictates.(4)

Representing term lists
.......................

Finally, we must confront the job of implementing a good representation
for term lists.  A term list is, in effect, a set of coefficients keyed
by the order of the term.  Hence, any of the methods for representing
sets, as discussed in section *note 2-3-3::, can be applied to this
task.  On the other hand, our procedures `add-terms' and `mul-terms'
always access term lists sequentially from highest to lowest order.
Thus, we will use some kind of ordered list representation.

   How should we structure the list that represents a term list?  One
consideration is the "density" of the polynomials we intend to
manipulate.  A polynomial is said to be "dense" if it has nonzero
coefficients in terms of most orders.  If it has many zero terms it is
said to be "sparse".  For example,

     A : x^5 + 2x^4 + 3x^2 - 2x - 5

is a dense polynomial, whereas

     B : x^100 + 2x^2 + 1

is sparse.

   The term lists of dense polynomials are most efficiently represented
as lists of the coefficients.  For example, A above would be nicely
represented as `(1 2 0 3 -2 -5)'.  The order of a term in this
representation is the length of the sublist beginning with that term's
coefficient, decremented by 1.(5)  This would be a terrible
representation for a sparse polynomial such as B: There would be a
giant list of zeros punctuated by a few lonely nonzero terms.  A more
reasonable representation of the term list of a sparse polynomial is as
a list of the nonzero terms, where each term is a list containing the
order of the term and the coefficient for that order.  In such a
scheme, polynomial B is efficiently represented as `((100 1) (2 2) (0
1))'.  As most polynomial manipulations are performed on sparse
polynomials, we will use this method.  We will assume that term lists
are represented as lists of terms, arranged from highest-order to
lowest-order term.  Once we have made this decision, implementing the
selectors and constructors for terms and term lists is
straightforward:(6)

     (define (adjoin-term term term-list)
       (if (=zero? (coeff term))
           term-list
           (cons term term-list)))

     (define (the-empty-termlist) '())
     (define (first-term term-list) (car term-list))
     (define (rest-terms term-list) (cdr term-list))
     (define (empty-termlist? term-list) (null? term-list))

     (define (make-term order coeff) (list order coeff))
     (define (order term) (car term))
     (define (coeff term) (cadr term))

where `=zero?' is as defined in *note Exercise 2-80::.  (See also *note
Exercise 2-87:: below.)

   Users of the polynomial package will create (tagged) polynomials by
means of the procedure:

     (define (make-polynomial var terms)
       ((get 'make 'polynomial) var terms))

     *Exercise 2.87:* Install `=zero?' for polynomials in the generic
     arithmetic package.  This will allow `adjoin-term' to work for
     polynomials with coefficients that are themselves polynomials.

     *Exercise 2.88:* Extend the polynomial system to include
     subtraction of polynomials.  (Hint: You may find it helpful to
     define a generic negation operation.)

     *Exercise 2.89:* Define procedures that implement the term-list
     representation described above as appropriate for dense
     polynomials.

     *Exercise 2.90:* Suppose we want to have a polynomial system that
     is efficient for both sparse and dense polynomials.  One way to do
     this is to allow both kinds of term-list representations in our
     system.  The situation is analogous to the complex-number example
     of section *note 2-4::, where we allowed both rectangular and
     polar representations.  To do this we must distinguish different
     types of term lists and make the operations on term lists generic.
     Redesign the polynomial system to implement this generalization.
     This is a major effort, not a local change.

     *Exercise 2.91:* A univariate polynomial can be divided by another
     one to produce a polynomial quotient and a polynomial remainder.
     For example,

          x^5 - 1
          ------- = x^3 + x, remainder x - 1
          x^2 - 1

     Division can be performed via long division.  That is, divide the
     highest-order term of the dividend by the highest-order term of
     the divisor.  The result is the first term of the quotient.  Next,
     multiply the result by the divisor, subtract that from the
     dividend, and produce the rest of the answer by recursively
     dividing the difference by the divisor.  Stop when the order of the
     divisor exceeds the order of the dividend and declare the dividend
     to be the remainder.  Also, if the dividend ever becomes zero,
     return zero as both quotient and remainder.

     We can design a `div-poly' procedure on the model of `add-poly' and
     `mul-poly'. The procedure checks to see if the two polys have the
     same variable.  If so, `div-poly' strips off the variable and
     passes the problem to `div-terms', which performs the division
     operation on term lists. `Div-poly' finally reattaches the
     variable to the result supplied by `div-terms'.  It is convenient
     to design `div-terms' to compute both the quotient and the
     remainder of a division.  `Div-terms' can take two term lists as
     arguments and return a list of the quotient term list and the
     remainder term list.

     Complete the following definition of `div-terms' by filling in the
     missing expressions.  Use this to implement `div-poly', which
     takes two polys as arguments and returns a list of the quotient
     and remainder polys.

          (define (div-terms L1 L2)
            (if (empty-termlist? L1)
                (list (the-empty-termlist) (the-empty-termlist))
                (let ((t1 (first-term L1))
                      (t2 (first-term L2)))
                  (if (> (order t2) (order t1))
                      (list (the-empty-termlist) L1)
                      (let ((new-c (div (coeff t1) (coeff t2)))
                            (new-o (- (order t1) (order t2))))
                        (let ((rest-of-result
                               <COMPUTE REST OF RESULT RECURSIVELY>
                               ))
                          <FORM COMPLETE RESULT>
                          ))))))

Hierarchies of types in symbolic algebra
........................................

Our polynomial system illustrates how objects of one type (polynomials)
may in fact be complex objects that have objects of many different
types as parts.  This poses no real difficulty in defining generic
operations.  We need only install appropriate generic operations for
performing the necessary manipulations of the parts of the compound
types.  In fact, we saw that polynomials form a kind of "recursive data
abstraction," in that parts of a polynomial may themselves be
polynomials.  Our generic operations and our data-directed programming
style can handle this complication without much trouble.

   On the other hand, polynomial algebra is a system for which the data
types cannot be naturally arranged in a tower.  For instance, it is
possible to have polynomials in x whose coefficients are polynomials in
y.  It is also possible to have polynomials in y whose coefficients are
polynomials in x.  Neither of these types is "above" the other in any
natural way, yet it is often necessary to add together elements from
each set.  There are several ways to do this.  One possibility is to
convert one polynomial to the type of the other by expanding and
rearranging terms so that both polynomials have the same principal
variable.  One can impose a towerlike structure on this by ordering the
variables and thus always converting any polynomial to a "canonical
form" with the highest-priority variable dominant and the
lower-priority variables buried in the coefficients.  This strategy
works fairly well, except that the conversion may expand a polynomial
unnecessarily, making it hard to read and perhaps less efficient to
work with.  The tower strategy is certainly not natural for this domain
or for any domain where the user can invent new types dynamically using
old types in various combining forms, such as trigonometric functions,
power series, and integrals.

   It should not be surprising that controlling coercion is a serious
problem in the design of large-scale algebraic-manipulation systems.
Much of the complexity of such systems is concerned with relationships
among diverse types.  Indeed, it is fair to say that we do not yet
completely understand coercion.  In fact, we do not yet completely
understand the concept of a data type.  Nevertheless, what we know
provides us with powerful structuring and modularity principles to
support the design of large systems.

     *Exercise 2.92:* By imposing an ordering on variables, extend the
     polynomial package so that addition and multiplication of
     polynomials works for polynomials in different variables.  (This
     is not easy!)

Extended exercise: Rational functions
.....................................

We can extend our generic arithmetic system to include functions
"rational functions".  These are "fractions" whose numerator and
denominator are polynomials, such as

      x + 1
     -------
     x^3 - 1

   The system should be able to add, subtract, multiply, and divide
rational functions, and to perform such computations as

      x + 1       x      x^3 + 2x^2 + 3x + 1
     ------- + ------- = -------------------
     x^3 - 1   x^2 - 1    x^4 + x^3 - x - 1

(Here the sum has been simplified by removing common factors.  Ordinary
"cross multiplication" would have produced a fourth-degree polynomial
over a fifth-degree polynomial.)

   If we modify our rational-arithmetic package so that it uses generic
operations, then it will do what we want, except for the problem of
reducing fractions to lowest terms.

     *Exercise 2.93:* Modify the rational-arithmetic package to use
     generic operations, but change `make-rat' so that it does not
     attempt to reduce fractions to lowest terms.  Test your system by
     calling `make-rational' on two polynomials to produce a rational
     function

          (define p1 (make-polynomial 'x '((2 1)(0 1))))
          (define p2 (make-polynomial 'x '((3 1)(0 1))))
          (define rf (make-rational p2 p1))

     Now add `rf' to itself, using `add'. You will observe that this
     addition procedure does not reduce fractions to lowest terms.

     We can reduce polynomial fractions to lowest terms using the same
     idea we used with integers: modifying `make-rat' to divide both
     the numerator and the denominator by their greatest common
     divisor.  The notion of "greatest common divisor" makes sense for
     polynomials.  In fact, we can compute the GCD of two polynomials
     using essentially the same Euclid's Algorithm that works for
     integers.(7)  The integer version is

          (define (gcd a b)
            (if (= b 0)
                a
                (gcd b (remainder a b))))

     Using this, we could make the obvious modification to define a GCD
     operation that works on term lists:

          (define (gcd-terms a b)
            (if (empty-termlist? b)
                a
                (gcd-terms b (remainder-terms a b))))

     where `remainder-terms' picks out the remainder component of the
     list returned by the term-list division operation `div-terms' that
     was implemented in *note Exercise 2-91::.

     *Exercise 2.94:* Using `div-terms', implement the procedure
     `remainder-terms' and use this to define `gcd-terms' as above.
     Now write a procedure `gcd-poly' that computes the polynomial GCD
     of two polys.  (The procedure should signal an error if the two
     polys are not in the same variable.)  Install in the system a
     generic operation `greatest-common-divisor' that reduces to
     `gcd-poly' for polynomials and to ordinary `gcd' for ordinary
     numbers.  As a test, try

          (define p1 (make-polynomial 'x '((4 1) (3 -1) (2 -2) (1 2))))
          (define p2 (make-polynomial 'x '((3 1) (1 -1))))
          (greatest-common-divisor p1 p2)

     and check your result by hand.

     *Exercise 2.95:* Define P_1, P_2, and P_3 to be the polynomials

          P_1 : x^2 - 2x + 1

          P_2 : 11x^2 + 7

          P_3 : 13x + 5

     Now define Q_1 to be the product of P_1 and P_2 and Q_2 to be the
     product of P_1 and P_3, and use `greatest-common-divisor' (*note
     Exercise 2-94::) to compute the GCD of Q_1 and Q_2.  Note that the
     answer is not the same as P_1.  This example introduces noninteger
     operations into the computation, causing difficulties with the GCD
     algorithm.(8)  To understand what is happening, try tracing
     `gcd-terms' while computing the GCD or try performing the division
     by hand.

     We can solve the problem exhibited in *note Exercise 2-95:: if we
     use the following modification of the GCD algorithm (which really
     works only in the case of polynomials with integer coefficients).
     Before performing any polynomial division in the GCD computation,
     we multiply the dividend by an integer constant factor, chosen to
     guarantee that no fractions will arise during the division
     process.  Our answer will thus differ from the actual GCD by an
     integer constant factor, but this does not matter in the case of
     reducing rational functions to lowest terms; the GCD will be used
     to divide both the numerator and denominator, so the integer
     constant factor will cancel out.

     More precisely, if P and Q are polynomials, let O_1 be the order of
     P (i.e., the order of the largest term of P) and let O_2 be the
     order of Q.  Let c be the leading coefficient of Q.  Then it can be
     shown that, if we multiply P by the "integerizing factor" c^(1+O_1
     -O_2), the resulting polynomial can be divided by Q by using the
     `div-terms' algorithm without introducing any fractions.  The
     operation of multiplying the dividend by this constant and then
     dividing is sometimes called the "pseudodivision" of P by Q.  The
     remainder of the division is called the "pseudoremainder".

     *Exercise 2.96:*
       a. Implement the procedure `pseudoremainder-terms', which is
          just like `remainder-terms' except that it multiplies the
          dividend by the integerizing factor described above before
          calling `div-terms'.  Modify `gcd-terms' to use
          `pseudoremainder-terms', and verify that
          `greatest-common-divisor' now produces an answer with integer
          coefficients on the example in *note Exercise 2-95::.

       b. The GCD now has integer coefficients, but they are larger
          than those of P_1.  Modify `gcd-terms' so that it removes
          common factors from the coefficients of the answer by
          dividing all the coefficients by their (integer) greatest
          common divisor.


     Thus, here is how to reduce a rational function to lowest terms:

        * Compute the GCD of the numerator and denominator, using the
          version of `gcd-terms' from *note Exercise 2-96::.

        * When you obtain the GCD, multiply both numerator and
          denominator by the same integerizing factor before dividing
          through by the GCD, so that division by the GCD will not
          introduce any noninteger coefficients.  As the factor you can
          use the leading coefficient of the GCD raised to the power 1
          + O_1 - O_2, where O_2 is the order of the GCD and O_1 is the
          maximum of the orders of the numerator and denominator.  This
          will ensure that dividing the numerator and denominator by
          the GCD will not introduce any fractions.

        * The result of this operation will be a numerator and
          denominator with integer coefficients.  The coefficients will
          normally be very large because of all of the integerizing
          factors, so the last step is to remove the redundant factors
          by computing the (integer) greatest common divisor of all the
          coefficients of the numerator and the denominator and
          dividing through by this factor.


     *Exercise 2.97:*
       a. Implement this algorithm as a procedure `reduce-terms' that
          takes two term lists `n' and `d' as arguments and returns a
          list `nn', `dd', which are `n' and `d' reduced to lowest
          terms via the algorithm given above.  Also write a procedure
          `reduce-poly', analogous to `add-poly', that checks to see if
          the two polys have the same variable.  If so, `reduce-poly'
          strips off the variable and passes the problem to
          `reduce-terms', then reattaches the variable to the two term
          lists supplied by `reduce-terms'.

       b. Define a procedure analogous to `reduce-terms' that does what
          the original `make-rat' did for integers:

               (define (reduce-integers n d)
                 (let ((g (gcd n d)))
                   (list (/ n g) (/ d g))))

          and define `reduce' as a generic operation that calls
          `apply-generic' to dispatch to either `reduce-poly' (for
          `polynomial' arguments) or `reduce-integers' (for
          `scheme-number' arguments).  You can now easily make the
          rational-arithmetic package reduce fractions to lowest terms
          by having `make-rat' call `reduce' before combining the given
          numerator and denominator to form a rational number.  The
          system now handles rational expressions in either integers or
          polynomials.  To test your program, try the example at the
          beginning of this extended exercise:

               (define p1 (make-polynomial 'x '((1 1)(0 1))))
               (define p2 (make-polynomial 'x '((3 1)(0 -1))))
               (define p3 (make-polynomial 'x '((1 1))))
               (define p4 (make-polynomial 'x '((2 1)(0 -1))))

               (define rf1 (make-rational p1 p2))
               (define rf2 (make-rational p3 p4))

               (add rf1 rf2)

          See if you get the correct answer, correctly reduced to
          lowest terms.

          The GCD computation is at the heart of any system that does
          operations on rational functions.  The algorithm used above,
          although mathematically straightforward, is extremely slow.
          The slowness is due partly to the large number of division
          operations and partly to the enormous size of the
          intermediate coefficients generated by the pseudodivisions.
          One of the active areas in the development of
          algebraic-manipulation systems is the design of better
          algorithms for computing polynomial GCDs.(9)


   ---------- Footnotes ----------

   (1) On the other hand, we will allow polynomials whose coefficients
are themselves polynomials in other variables.  This will give us
essentially the same representational power as a full multivariate
system, although it does lead to coercion problems, as discussed below.

   (2) For univariate polynomials, giving the value of a polynomial at
a given set of points can be a particularly good representation.  This
makes polynomial arithmetic extremely simple.  To obtain, for example,
the sum of two polynomials represented in this way, we need only add
the values of the polynomials at corresponding points.  To transform
back to a more familiar representation, we can use the Lagrange
interpolation formula, which shows how to recover the coefficients of a
polynomial of degree n given the values of the polynomial at n + 1
points.

   (3) This operation is very much like the ordered `union-set'
operation we developed in exercise *note Exercise 2-62::.  In fact, if
we think of the terms of the polynomial as a set ordered according to
the power of the indeterminate, then the program that produces the term
list for a sum is almost identical to `union-set'.

   (4) To make this work completely smoothly, we should also add to our
generic arithmetic system the ability to coerce a "number" to a
polynomial by regarding it as a polynomial of degree zero whose
coefficient is the number.  This is necessary if we are going to
perform operations such as

     [x^2 + (y + 1)x + 5] + [x^2 + 2x + 1]

which requires adding the coefficient y + 1 to the coefficient 2.

   (5) In these polynomial examples, we assume that we have implemented
the generic arithmetic system using the type mechanism suggested in
*note Exercise 2-78::.  Thus, coefficients that are ordinary numbers
will be represented as the numbers themselves rather than as pairs
whose `car' is the symbol `scheme-number'.

   (6) Although we are assuming that term lists are ordered, we have
implemented `adjoin-term' to simply `cons' the new term onto the
existing term list.  We can get away with this so long as we guarantee
that the procedures (such as `add-terms') that use `adjoin-term' always
call it with a higher-order term than appears in the list.  If we did
not want to make such a guarantee, we could have implemented
`adjoin-term' to be similar to the `adjoin-set' constructor for the
ordered-list representation of sets (*note Exercise 2-61::).

   (7) The fact that Euclid's Algorithm works for polynomials is
formalized in algebra by saying that polynomials form a kind of
algebraic domain called a "Euclidean ring".  A Euclidean ring is a
domain that admits addition, subtraction, and commutative
multiplication, together with a way of assigning to each element x of
the ring a positive integer "measure" m(x) with the properties that
m(xy)>= m(x) for any nonzero x and y and that, given any x and y, there
exists a q such that y = qx + r and either r = 0 or m(r)< m(x).  From
an abstract point of view, this is what is needed to prove that
Euclid's Algorithm works.  For the domain of integers, the measure m of
an integer is the absolute value of the integer itself.  For the domain
of polynomials, the measure of a polynomial is its degree.

   (8) In an implementation like MIT Scheme, this produces a polynomial
that is indeed a divisor of Q_1 and Q_2, but with rational
coefficients.  In many other Scheme systems, in which division of
integers can produce limited-precision decimal numbers, we may fail to
get a valid divisor.

   (9) One extremely efficient and elegant method for computing
polynomial GCDs was discovered by Richard Zippel (1979).  The method is
a probabilistic algorithm, as is the fast test for primality that we
discussed in *note Chapter 1::.  Zippel's book (1993) describes this
method, together with other ways to compute polynomial GCDs.


File: sicp,  Node: Chapter 3,  Next: Chapter 4,  Prev: Chapter 2,  Up: Top

3 Modularity, Objects, and State
********************************

     [greek not included here]

     (Even while it changes, it stands still.)

     --Heraclitus

     Plus c,a change, plus c'est la me*me chose.

     --Alphonse Karr

   The preceding chapters introduced the basic elements from which
programs are made.  We saw how primitive procedures and primitive data
are combined to construct compound entities, and we learned that
abstraction is vital in helping us to cope with the complexity of large
systems.  But these tools are not sufficient for designing programs.
Effective program synthesis also requires organizational principles
that can guide us in formulating the overall design of a program.  In
particular, we need strategies to help us structure large systems so
that they will be "modular", that is, so that they can be divided
"naturally" into coherent parts that can be separately developed and
maintained.

   One powerful design strategy, which is particularly appropriate to
the construction of programs for modeling physical systems, is to base
the structure of our programs on the structure of the system being
modeled.  For each object in the system, we construct a corresponding
computational object.  For each system action, we define a symbolic
operation in our computational model.  Our hope in using this strategy
is that extending the model to accommodate new objects or new actions
will require no strategic changes to the program, only the addition of
the new symbolic analogs of those objects or actions.  If we have been
successful in our system organization, then to add a new feature or
debug an old one we will have to work on only a localized part of the
system.

   To a large extent, then, the way we organize a large program is
dictated by our perception of the system to be modeled.  In this
chapter we will investigate two prominent organizational strategies
arising from two rather different "world views" of the structure of
systems.  The first organizational strategy concentrates on "objects",
viewing a large system as a collection of distinct objects whose
behaviors may change over time.  An alternative organizational strategy
concentrates on the "streams" of information that flow in the system,
much as an electrical engineer views a signal-processing system.

   Both the object-based approach and the stream-processing approach
raise significant linguistic issues in programming.  With objects, we
must be concerned with how a computational object can change and yet
maintain its identity.  This will force us to abandon our old
substitution model of computation (section *note 1-1-5::) in favor of a
more mechanistic but less theoretically tractable "environment model"
of computation.  The difficulties of dealing with objects, change, and
identity are a fundamental consequence of the need to grapple with time
in our computational models.  These difficulties become even greater
when we allow the possibility of concurrent execution of programs.  The
stream approach can be most fully exploited when we decouple simulated
time in our model from the order of the events that take place in the
computer during evaluation.  We will accomplish this using a technique
known as "delayed evaluation".

* Menu:

* 3-1::              Assignment and Local State
* 3-2::              The Environment Model of Evaluation
* 3-3::              Modeling with Mutable Data
* 3-4::              Concurrency: Time Is of the Essence
* 3-5::              Streams


File: sicp,  Node: 3-1,  Next: 3-2,  Prev: Chapter 3,  Up: Chapter 3

3.1 Assignment and Local State
==============================

We ordinarily view the world as populated by independent objects, each
of which has a state that changes over time.  An object is said to
"have state" if its behavior is influenced by its history.  A bank
account, for example, has state in that the answer to the question "Can
I withdraw $100?"  depends upon the history of deposit and withdrawal
transactions.  We can characterize an object's state by one or more "state
variables", which among them maintain enough information about history
to determine the object's current behavior.  In a simple banking
system, we could characterize the state of an account by a current
balance rather than by remembering the entire history of account
transactions.

   In a system composed of many objects, the objects are rarely
completely independent.  Each may influence the states of others
through interactions, which serve to couple the state variables of one
object to those of other objects.  Indeed, the view that a system is
composed of separate objects is most useful when the state variables of
the system can be grouped into closely coupled subsystems that are only
loosely coupled to other subsystems.

   This view of a system can be a powerful framework for organizing
computational models of the system.  For such a model to be modular, it
should be decomposed into computational objects that model the actual
objects in the system.  Each computational object must have its own "local
state variables" describing the actual object's state.  Since the
states of objects in the system being modeled change over time, the
state variables of the corresponding computational objects must also
change.  If we choose to model the flow of time in the system by the
elapsed time in the computer, then we must have a way to construct
computational objects whose behaviors change as our programs run.  In
particular, if we wish to model state variables by ordinary symbolic
names in the programming language, then the language must provide an operator
"assignment operator" to enable us to change the value associated with
a name.

* Menu:

* 3-1-1::            Local State Variables
* 3-1-2::            The Benefits of Introducing Assignment
* 3-1-3::            The Costs of Introducing Assignment


File: sicp,  Node: 3-1-1,  Next: 3-1-2,  Prev: 3-1,  Up: 3-1

3.1.1 Local State Variables
---------------------------

To illustrate what we mean by having a computational object with
time-varying state, let us model the situation of withdrawing money
from a bank account.  We will do this using a procedure `withdraw',
which takes as argument an `amount' to be withdrawn.  If there is
enough money in the account to accommodate the withdrawal, then
`withdraw' should return the balance remaining after the withdrawal.
Otherwise, `withdraw' should return the message _Insufficient funds_.
For example, if we begin with $100 in the account, we should obtain the
following sequence of responses using `withdraw':

     (withdraw 25)
     75

     (withdraw 25)
     50

     (withdraw 60)
     "Insufficient funds"

     (withdraw 15)
     35

   Observe that the expression `(withdraw 25)', evaluated twice, yields
different values.  This is a new kind of behavior for a procedure.
Until now, all our procedures could be viewed as specifications for
computing mathematical functions.  A call to a procedure computed the
value of the function applied to the given arguments, and two calls to
the same procedure with the same arguments always produced the same
result.(1)

   To implement `withdraw', we can use a variable `balance' to indicate
the balance of money in the account and define `withdraw' as a procedure
that accesses `balance'.  The `withdraw' procedure checks to see if
`balance' is at least as large as the requested `amount'.  If so,
`withdraw' decrements `balance' by `amount' and returns the new value
of `balance'.  Otherwise, `withdraw' returns the _Insufficient funds_
message.  Here are the definitions of `balance' and `withdraw':

     (define balance 100)

     (define (withdraw amount)
       (if (>= balance amount)
           (begin (set! balance (- balance amount))
                  balance)
           "Insufficient funds"))

   Decrementing `balance' is accomplished by the expression

     (set! balance (- balance amount))

   This uses the `set!' special form, whose syntax is

     (set! <NAME> <NEW-VALUE>)

   Here <NAME> is a symbol and <NEW-VALUE> is any expression.  `Set!'
changes <NAME> so that its value is the result obtained by evaluating
<NEW-VALUE>.  In the case at hand, we are changing `balance' so that
its new value will be the result of subtracting `amount' from the
previous value of `balance'.(2)

   `Withdraw' also uses the `begin' special form to cause two
expressions to be evaluated in the case where the `if' test is true:
first decrementing `balance' and then returning the value of `balance'.
In general, evaluating the expression

     (begin <EXP_1> <EXP_2> ... <EXP_K>)

causes the expressions <EXP_1> through <EXP_K> to be evaluated in
sequence and the value of the final expression <EXP_K> to be returned
as the value of the entire `begin' form.(3)

   Although `withdraw' works as desired, the variable `balance' presents
a problem.  As specified above, `balance' is a name defined in the
global environment and is freely accessible to be examined or modified
by any procedure.  It would be much better if we could somehow make
`balance' internal to `withdraw', so that `withdraw' would be the only
procedure that could access `balance' directly and any other procedure
could access `balance' only indirectly (through calls to `withdraw').
This would more accurately model the notion that `balance' is a local
state variable used by `withdraw' to keep track of the state of the
account.

   We can make `balance' internal to `withdraw' by rewriting the
definition as follows:

     (define new-withdraw
       (let ((balance 100))
         (lambda (amount)
           (if (>= balance amount)
               (begin (set! balance (- balance amount))
                      balance)
               "Insufficient funds"))))

   What we have done here is use `let' to establish an environment with
a local variable `balance', bound to the initial value 100.  Within this
local environment, we use `lambda' to create a procedure that takes
`amount' as an argument and behaves like our previous `withdraw'
procedure.  This procedure--returned as the result of evaluating the
`let' expression--is `new-withdraw', which behaves in precisely the
same way as `withdraw' but whose variable `balance' is not accessible
by any other procedure.(4)

   Combining `set!' with local variables is the general programming
technique we will use for constructing computational objects with local
state.  Unfortunately, using this technique raises a serious problem:
When we first introduced procedures, we also introduced the
substitution model of evaluation (section *note 1-1-5::) to provide an
interpretation of what procedure application means.  We said that
applying a procedure should be interpreted as evaluating the body of
the procedure with the formal parameters replaced by their values.  The
trouble is that, as soon as we introduce assignment into our language,
substitution is no longer an adequate model of procedure application.
(We will see why this is so in section *note 3-1-3::.)  As a
consequence, we technically have at this point no way to understand why
the `new-withdraw' procedure behaves as claimed above.  In order to
really understand a procedure such as `new-withdraw', we will need to
develop a new model of procedure application.  In section *note 3-2::
we will introduce such a model, together with an explanation of `set!'
and local variables.  First, however, we examine some variations on the
theme established by `new-withdraw'.

   The following procedure, `make-withdraw', creates "withdrawal
processors."  The formal parameter `balance' in `make-withdraw'
specifies the initial amount of money in the account.(5)

     (define (make-withdraw balance)
       (lambda (amount)
         (if (>= balance amount)
             (begin (set! balance (- balance amount))
                    balance)
             "Insufficient funds")))

   `Make-withdraw' can be used as follows to create two objects `W1' and
`W2':

     (define W1 (make-withdraw 100))
     (define W2 (make-withdraw 100))

     (W1 50)
     50

     (W2 70)
     30

     (W2 40)
     "Insufficient funds"

     (W1 40)
     10

   Observe that `W1' and `W2' are completely independent objects, each
with its own local state variable `balance'.  Withdrawals from one do
not affect the other.

   We can also create objects that handle deposits as well as
withdrawals, and thus we can represent simple bank accounts.  Here is a
procedure that returns a "bank-account object" with a specified initial
balance:

     (define (make-account balance)
       (define (withdraw amount)
         (if (>= balance amount)
             (begin (set! balance (- balance amount))
                    balance)
             "Insufficient funds"))
       (define (deposit amount)
         (set! balance (+ balance amount))
         balance)
       (define (dispatch m)
         (cond ((eq? m 'withdraw) withdraw)
               ((eq? m 'deposit) deposit)
               (else (error "Unknown request -- MAKE-ACCOUNT"
                            m))))
       dispatch)

   Each call to `make-account' sets up an environment with a local state
variable `balance'.  Within this environment, `make-account' defines
procedures `deposit' and `withdraw' that access `balance' and an
additional procedure `dispatch' that takes a "message" as input and
returns one of the two local procedures.  The `dispatch' procedure
itself is returned as the value that represents the bank-account
object.  This is precisely the "message-passing" style of programming
that we saw in section *note 2-4-3::, although here we are using it in
conjunction with the ability to modify local variables.

   `Make-account' can be used as follows:

     (define acc (make-account 100))

     ((acc 'withdraw) 50)
     50

     ((acc 'withdraw) 60)
     "Insufficient funds"

     ((acc 'deposit) 40)
     90

     ((acc 'withdraw) 60)
     30

   Each call to `acc' returns the locally defined `deposit' or
`withdraw' procedure, which is then applied to the specified `amount'.
As was the case with `make-withdraw', another call to `make-account'

     (define acc2 (make-account 100))

will produce a completely separate account object, which maintains its
own local `balance'.

     *Exercise 3.1:* An "accumulator" is a procedure that is called
     repeatedly with a single numeric argument and accumulates its
     arguments into a sum.  Each time it is called, it returns the
     currently accumulated sum.  Write a procedure `make-accumulator'
     that generates accumulators, each maintaining an independent sum.
     The input to `make-accumulator' should specify the initial value
     of the sum; for example

          (define A (make-accumulator 5))

          (A 10)
          15

          (A 10)
          25

     *Exercise 3.2:* In software-testing applications, it is useful to
     be able to count the number of times a given procedure is called
     during the course of a computation.  Write a procedure
     `make-monitored' that takes as input a procedure, `f', that itself
     takes one input.  The result returned by `make-monitored' is a
     third procedure, say `mf', that keeps track of the number of times
     it has been called by maintaining an internal counter.  If the
     input to `mf' is the special symbol `how-many-calls?', then `mf'
     returns the value of the counter.  If the input is the special
     symbol `reset-count', then `mf' resets the counter to zero.  For
     any other input, `mf' returns the result of calling `f' on that
     input and increments the counter.  For instance, we could make a
     monitored version of the `sqrt' procedure:

          (define s (make-monitored sqrt))

          (s 100)
          10

          (s 'how-many-calls?)
          1

     *Exercise 3.3:* Modify the `make-account' procedure so that it
     creates password-protected accounts.  That is, `make-account'
     should take a symbol as an additional argument, as in

          (define acc (make-account 100 'secret-password))

     The resulting account object should process a request only if it
     is accompanied by the password with which the account was created,
     and should otherwise return a complaint:

          ((acc 'secret-password 'withdraw) 40)
          60

          ((acc 'some-other-password 'deposit) 50)
          "Incorrect password"

     *Exercise 3.4:* Modify the `make-account' procedure of *note
     Exercise 3-3:: by adding another local state variable so that, if
     an account is accessed more than seven consecutive times with an
     incorrect password, it invokes the procedure `call-the-cops'.

   ---------- Footnotes ----------

   (1) Actually, this is not quite true.  One exception was the
random-number generator in section *note 1-2-6::.  Another exception
involved the operation/type tables we introduced in section *note
2-4-3::, where the values of two calls to `get' with the same arguments
depended on intervening calls to `put'.  On the other hand, until we
introduce assignment, we have no way to create such procedures
ourselves.

   (2) The value of a `set!' expression is implementation-dependent.
`Set!' should be used only for its effect, not for its value.

   The name `set!' reflects a naming convention used in Scheme:
Operations that change the values of variables (or that change data
structures, as we will see in section *note 3-3::) are given names that
end with an exclamation point.  This is similar to the convention of
designating predicates by names that end with a question mark.

   (3) We have already used `begin' implicitly in our programs, because
in Scheme the body of a procedure can be a sequence of expressions.
Also, the <CONSEQUENT> part of each clause in a `cond' expression can
be a sequence of expressions rather than a single expression.

   (4) In programming-language jargon, the variable `balance' is said
to be "encapsulated" within the `new-withdraw' procedure.
Encapsulation reflects the general system-design principle known as the "hiding
principle": One can make a system more modular and robust by protecting
parts of the system from each other; that is, by providing information
access only to those parts of the system that have a "need to know."

   (5) In contrast with `new-withdraw' above, we do not have to use
`let' to make `balance' a local variable, since formal parameters are
already local.  This will be clearer after the discussion of the
environment model of evaluation in section *note 3-2::.  (See also
*note Exercise 3-10::.)


File: sicp,  Node: 3-1-2,  Next: 3-1-3,  Prev: 3-1-1,  Up: 3-1

3.1.2 The Benefits of Introducing Assignment
--------------------------------------------

As we shall see, introducing assignment into our programming language
leads us into a thicket of difficult conceptual issues.  Nevertheless,
viewing systems as collections of objects with local state is a
powerful technique for maintaining a modular design.  As a simple
example, consider the design of a procedure `rand' that, whenever it is
called, returns an integer chosen at random.

   It is not at all clear what is meant by "chosen at random."  What we
presumably want is for successive calls to `rand' to produce a sequence
of numbers that has statistical properties of uniform distribution.  We
will not discuss methods for generating suitable sequences here.
Rather, let us assume that we have a procedure `rand-update' that has
the property that if we start with a given number x_1 and form

     x_2 = (rand-update x_1)
     x_3 = (rand-update x_2)

then the sequence of values x_1, x_2, x_3, ..., will have the desired
statistical properties.(1)

   We can implement `rand' as a procedure with a local state variable
`x' that is initialized to some fixed value `random-init'.  Each call
to `rand' computes `rand-update' of the current value of `x', returns
this as the random number, and also stores this as the new value of `x'.

     (define rand
       (let ((x random-init))
         (lambda ()
           (set! x (rand-update x))
           x)))

   Of course, we could generate the same sequence of random numbers
without using assignment by simply calling `rand-update' directly.
However, this would mean that any part of our program that used random
numbers would have to explicitly remember the current value of `x' to
be passed as an argument to `rand-update'.  To realize what an
annoyance this would be, consider using random numbers to implement a
technique called simulation "Monte Carlo simulation".

   The Monte Carlo method consists of choosing sample experiments at
random from a large set and then making deductions on the basis of the
probabilities estimated from tabulating the results of those
experiments.  For example, we can approximate [pi] using the fact that
6/[pi]^2 is the probability that two integers chosen at random will
have no factors in common; that is, that their greatest common divisor
will be 1.(2) To obtain the approximation to [pi], we perform a large
number of experiments.  In each experiment we choose two integers at
random and perform a test to see if their GCD is 1.  The fraction of
times that the test is passed gives us our estimate of 6/[pi]^2, and
from this we obtain our approximation to [pi].

   The heart of our program is a procedure `monte-carlo', which takes as
arguments the number of times to try an experiment, together with the
experiment, represented as a no-argument procedure that will return
either true or false each time it is run.  `Monte-carlo' runs the
experiment for the designated number of trials and returns a number
telling the fraction of the trials in which the experiment was found to
be true.

     (define (estimate-pi trials)
       (sqrt (/ 6 (monte-carlo trials cesaro-test))))

     (define (cesaro-test)
        (= (gcd (rand) (rand)) 1))

     (define (monte-carlo trials experiment)
       (define (iter trials-remaining trials-passed)
         (cond ((= trials-remaining 0)
                (/ trials-passed trials))
               ((experiment)
                (iter (- trials-remaining 1) (+ trials-passed 1)))
               (else
                (iter (- trials-remaining 1) trials-passed))))
       (iter trials 0))

   Now let us try the same computation using `rand-update' directly
rather than `rand', the way we would be forced to proceed if we did not
use assignment to model local state:

     (define (estimate-pi trials)
       (sqrt (/ 6 (random-gcd-test trials random-init))))

     (define (random-gcd-test trials initial-x)
       (define (iter trials-remaining trials-passed x)
         (let ((x1 (rand-update x)))
           (let ((x2 (rand-update x1)))
             (cond ((= trials-remaining 0)
                    (/ trials-passed trials))
                   ((= (gcd x1 x2) 1)
                    (iter (- trials-remaining 1)
                          (+ trials-passed 1)
                          x2))
                   (else
                    (iter (- trials-remaining 1)
                          trials-passed
                          x2))))))
       (iter trials 0 initial-x))

   While the program is still simple, it betrays some painful breaches
of modularity.  In our first version of the program, using `rand', we
can express the Monte Carlo method directly as a general `monte-carlo'
procedure that takes as an argument an arbitrary `experiment' procedure.
In our second version of the program, with no local state for the
random-number generator, `random-gcd-test' must explicitly manipulate
the random numbers `x1' and `x2' and recycle `x2' through the iterative
loop as the new input to `rand-update'.  This explicit handling of the
random numbers intertwines the structure of accumulating test results
with the fact that our particular experiment uses two random numbers,
whereas other Monte Carlo experiments might use one random number or
three.  Even the top-level procedure `estimate-pi' has to be concerned
with supplying an initial random number.  The fact that the
random-number generator's insides are leaking out into other parts of
the program makes it difficult for us to isolate the Monte Carlo idea
so that it can be applied to other tasks.  In the first version of the
program, assignment encapsulates the state of the random-number
generator within the `rand' procedure, so that the details of
random-number generation remain independent of the rest of the program.

   The general phenomenon illustrated by the Monte Carlo example is
this: From the point of view of one part of a complex process, the
other parts appear to change with time.  They have hidden time-varying
local state.  If we wish to write computer programs whose structure
reflects this decomposition, we make computational objects (such as
bank accounts and random-number generators) whose behavior changes with
time.  We model state with local state variables, and we model the
changes of state with assignments to those variables.

   It is tempting to conclude this discussion by saying that, by
introducing assignment and the technique of hiding state in local
variables, we are able to structure systems in a more modular fashion
than if all state had to be manipulated explicitly, by passing
additional parameters.  Unfortunately, as we shall see, the story is
not so simple.

     *Exercise 3.5:* "Monte Carlo integration" is a method of
     estimating definite integrals by means of Monte Carlo simulation.
     Consider computing the area of a region of space described by a
     predicate P(x, y) that is true for points (x, y) in the region and
     false for points not in the region.  For example, the region
     contained within a circle of radius 3 centered at (5, 7) is
     described by the predicate that tests whether (x - 5)^2 + (y -
     7)^2 <= 3^2.  To estimate the area of the region described by such
     a predicate, begin by choosing a rectangle that contains the
     region.  For example, a rectangle with diagonally opposite corners
     at (2, 4) and (8, 10) contains the circle above.  The desired
     integral is the area of that portion of the rectangle that lies in
     the region.  We can estimate the integral by picking, at random,
     points (x,y) that lie in the rectangle, and testing P(x, y) for
     each point to determine whether the point lies in the region.  If
     we try this with many points, then the fraction of points that
     fall in the region should give an estimate of the proportion of
     the rectangle that lies in the region.  Hence, multiplying this
     fraction by the area of the entire rectangle should produce an
     estimate of the integral.

     Implement Monte Carlo integration as a procedure
     `estimate-integral' that takes as arguments a predicate `P', upper
     and lower bounds `x1', `x2', `y1', and `y2' for the rectangle, and
     the number of trials to perform in order to produce the estimate.
     Your procedure should use the same `monte-carlo' procedure that
     was used above to estimate [pi].  Use your `estimate-integral' to
     produce an estimate of [pi] by measuring the area of a unit circle.

     You will find it useful to have a procedure that returns a number
     chosen at random from a given range.  The following
     `random-in-range' procedure implements this in terms of the
     `random' procedure used in section *note 1-2-6::, which returns a
     nonnegative number less than its input.(3)

          (define (random-in-range low high)
            (let ((range (- high low)))
              (+ low (random range))))

     *Exercise 3.6:* It is useful to be able to reset a random-number
     generator to produce a sequence starting from a given value.
     Design a new `rand' procedure that is called with an argument that
     is either the symbol `generate' or the symbol `reset' and behaves
     as follows: `(rand 'generate)' produces a new random number;
     `((rand 'reset) <NEW-VALUE>)' resets the internal state variable
     to the designated <NEW-VALUE>.  Thus, by resetting the state, one
     can generate repeatable sequences.  These are very handy to have
     when testing and debugging programs that use random numbers.

   ---------- Footnotes ----------

   (1) One common way to implement `rand-update' is to use the rule
that x is updated to ax + b modulo m, where a, b, and m are
appropriately chosen integers.  Chapter 3 of Knuth 1981 includes an
extensive discussion of techniques for generating sequences of random
numbers and establishing their statistical properties.  Notice that the
`rand-update' procedure computes a mathematical function: Given the
same input twice, it produces the same output.  Therefore, the number
sequence produced by `rand-update' certainly is not "random," if by
"random" we insist that each number in the sequence is unrelated to the
preceding number.  The relation between "real randomness" and so-called "pseudo-random"
sequences, which are produced by well-determined computations and yet
have suitable statistical properties, is a complex question involving
difficult issues in mathematics and philosophy.  Kolmogorov,
Solomonoff, and Chaitin have made great progress in clarifying these
issues; a discussion can be found in Chaitin 1975.

   (2) This theorem is due to E. Cesa`ro.  See section 4.5.2 of Knuth
1981 for a discussion and a proof.

   (3) MIT Scheme provides such a procedure.  If `random' is given an
exact integer (as in section *note 1-2-6::) it returns an exact
integer, but if it is given a decimal value (as in this exercise) it
returns a decimal value.


File: sicp,  Node: 3-1-3,  Prev: 3-1-2,  Up: 3-1

3.1.3 The Costs of Introducing Assignment
-----------------------------------------

As we have seen, the `set!' operation enables us to model objects that
have local state.  However, this advantage comes at a price.  Our
programming language can no longer be interpreted in terms of the
substitution model of procedure application that we introduced in
section *note 1-1-5::.  Moreover, no simple model with "nice"
mathematical properties can be an adequate framework for dealing with
objects and assignment in programming languages.

   So long as we do not use assignments, two evaluations of the same
procedure with the same arguments will produce the same result, so that
procedures can be viewed as computing mathematical functions.
Programming without any use of assignments, as we did throughout the
first two chapters of this book, is accordingly known as "functional
programming".

   To understand how assignment complicates matters, consider a
simplified version of the `make-withdraw' procedure of section *note
3-1-1:: that does not bother to check for an insufficient amount:

     (define (make-simplified-withdraw balance)
       (lambda (amount)
         (set! balance (- balance amount))
         balance))

     (define W (make-simplified-withdraw 25))

     (W 20)
     5

     (W 10)
      - 5

   Compare this procedure with the following `make-decrementer'
procedure, which does not use `set!':

     (define (make-decrementer balance)
       (lambda (amount)
         (- balance amount)))

   `Make-decrementer' returns a procedure that subtracts its input from
a designated amount `balance', but there is no accumulated effect over
successive calls, as with `make-simplified-withdraw':

     (define D (make-decrementer 25))

     (D 20)
     5

     (D 10)
     15

   We can use the substitution model to explain how `make-decrementer'
works.  For instance, let us analyze the evaluation of the expression

     ((make-decrementer 25) 20)

   We first simplify the operator of the combination by substituting 25
for `balance' in the body of `make-decrementer'.  This reduces the
expression to

     ((lambda (amount) (- 25 amount)) 20)

   Now we apply the operator by substituting 20 for `amount' in the
body of the `lambda' expression:

     (- 25 20)

   The final answer is 5.

   Observe, however, what happens if we attempt a similar substitution
analysis with `make-simplified-withdraw':

     ((make-simplified-withdraw 25) 20)

   We first simplify the operator by substituting 25 for `balance' in
the body of `make-simplified-withdraw'.  This reduces the expression
to(1)

     ((lambda (amount) (set! balance (- 25 amount)) 25) 20)

   Now we apply the operator by substituting 20 for `amount' in the
body of the `lambda' expression:

     (set! balance (- 25 20)) 25

   If we adhered to the substitution model, we would have to say that
the meaning of the procedure application is to first set `balance' to 5
and then return 25 as the value of the expression.  This gets the wrong
answer.  In order to get the correct answer, we would have to somehow
distinguish the first occurrence of `balance' (before the effect of the
`set!')  from the second occurrence of `balance' (after the effect of
the `set!'), and the substitution model cannot do this.

   The trouble here is that substitution is based ultimately on the
notion that the symbols in our language are essentially names for
values.  But as soon as we introduce `set!' and the idea that the value
of a variable can change, a variable can no longer be simply a name.
Now a variable somehow refers to a place where a value can be stored,
and the value stored at this place can change.  In section *note 3-2::
we will see how environments play this role of "place" in our
computational model.

Sameness and change
...................

The issue surfacing here is more profound than the mere breakdown of a
particular model of computation.  As soon as we introduce change into
our computational models, many notions that were previously
straightforward become problematical.  Consider the concept of two
things being "the same."

   Suppose we call `make-decrementer' twice with the same argument to
create two procedures:

     (define D1 (make-decrementer 25))

     (define D2 (make-decrementer 25))

   Are `D1' and `D2' the same?  An acceptable answer is yes, because
`D1' and `D2' have the same computational behavior--each is a procedure
that subtracts its input from 25.  In fact, `D1' could be substituted
for `D2' in any computation without changing the result.

   Contrast this with making two calls to `make-simplified-withdraw':

     (define W1 (make-simplified-withdraw 25))

     (define W2 (make-simplified-withdraw 25))

   Are `W1' and `W2' the same?  Surely not, because calls to `W1' and
`W2' have distinct effects, as shown by the following sequence of
interactions:

     (W1 20)
     5

     (W1 20)
      - 15

     (W2 20)
     5

   Even though `W1' and `W2' are "equal" in the sense that they are
both created by evaluating the same expression,
`(make-simplified-withdraw 25)', it is not true that `W1' could be
substituted for `W2' in any expression without changing the result of
evaluating the expression.

   A language that supports the concept that "equals can be substituted
for equals" in an expresssion without changing the value of the
expression is said to be "referentially transparent".  Referential
transparency is violated when we include `set!' in our computer
language.  This makes it tricky to determine when we can simplify
expressions by substituting equivalent expressions.  Consequently,
reasoning about programs that use assignment becomes drastically more
difficult.

   Once we forgo referential transparency, the notion of what it means
for computational objects to be "the same" becomes difficult to capture
in a formal way.  Indeed, the meaning of "same" in the real world that
our programs model is hardly clear in itself.  In general, we can
determine that two apparently identical objects are indeed "the same
one" only by modifying one object and then observing whether the other
object has changed in the same way.  But how can we tell if an object
has "changed" other than by observing the "same" object twice and
seeing whether some property of the object differs from one observation
to the next?  Thus, we cannot determine "change" without some _a
priori_ notion of "sameness," and we cannot determine sameness without
observing the effects of change.

   As an example of how this issue arises in programming, consider the
situation where Peter and Paul have a bank account with $100 in it.
There is a substantial difference between modeling this as

     (define peter-acc (make-account 100))
     (define paul-acc (make-account 100))

and modeling it as

     (define peter-acc (make-account 100))
     (define paul-acc peter-acc)

   In the first situation, the two bank accounts are distinct.
Transactions made by Peter will not affect Paul's account, and vice
versa.  In the second situation, however, we have defined `paul-acc' to
be _the same thing_ as `peter-acc'.  In effect, Peter and Paul now have
a joint bank account, and if Peter makes a withdrawal from `peter-acc'
Paul will observe less money in `paul-acc'.  These two similar but
distinct situations can cause confusion in building computational
models.  With the shared account, in particular, it can be especially
confusing that there is one object (the bank account) that has two
different names (`peter-acc' and `paul-acc'); if we are searching for
all the places in our program where `paul-acc' can be changed, we must
remember to look also at things that change `peter-acc'.(2)

   With reference to the above remarks on "sameness" and "change,"
observe that if Peter and Paul could only examine their bank balances,
and could not perform operations that changed the balance, then the
issue of whether the two accounts are distinct would be moot.  In
general, so long as we never modify data objects, we can regard a
compound data object to be precisely the totality of its pieces.  For
example, a rational number is determined by giving its numerator and
its denominator.  But this view is no longer valid in the presence of
change, where a compound data object has an "identity" that is
something different from the pieces of which it is composed.  A bank
account is still "the same" bank account even if we change the balance
by making a withdrawal; conversely, we could have two different bank
accounts with the same state information.  This complication is a
consequence, not of our programming language, but of our perception of
a bank account as an object.  We do not, for example, ordinarily regard
a rational number as a changeable object with identity, such that we
could change the numerator and still have "the same" rational number.

Pitfalls of imperative programming
..................................

In contrast to functional programming, programming that makes extensive
use of assignment is known as "imperative programming".  In addition to
raising complications about computational models, programs written in
imperative style are susceptible to bugs that cannot occur in functional
programs.  For example, recall the iterative factorial program from
section *note 1-2-1:::

     (define (factorial n)
       (define (iter product counter)
         (if (> counter n)
             product
             (iter (* counter product)
                   (+ counter 1))))
       (iter 1 1))

   Instead of passing arguments in the internal iterative loop, we
could adopt a more imperative style by using explicit assignment to
update the values of the variables `product' and `counter':

     (define (factorial n)
       (let ((product 1)
             (counter 1))
         (define (iter)
           (if (> counter n)
               product
               (begin (set! product (* counter product))
                      (set! counter (+ counter 1))
                      (iter))))
         (iter)))

   This does not change the results produced by the program, but it
does introduce a subtle trap.  How do we decide the order of the
assignments?  As it happens, the program is correct as written.  But
writing the assignments in the opposite order

     (set! counter (+ counter 1))
     (set! product (* counter product))

would have produced a different, incorrect result.  In general,
programming with assignment forces us to carefully consider the
relative orders of the assignments to make sure that each statement is
using the correct version of the variables that have been changed.
This issue simply does not arise in functional programs.(3)

   The complexity of imperative programs becomes even worse if we
consider applications in which several processes execute concurrently.
We will return to this in section *note 3-4::.  First, however, we will
address the issue of providing a computational model for expressions
that involve assignment, and explore the uses of objects with local
state in designing simulations.

     *Exercise 3.7:* Consider the bank account objects created by
     `make-account', with the password modification described in *note
     Exercise 3-3::.  Suppose that our banking system requires the
     ability to make joint accounts.  Define a procedure `make-joint'
     that accomplishes this.  `Make-joint' should take three arguments.
     The first is a password-protected account.  The second argument
     must match the password with which the account was defined in
     order for the `make-joint' operation to proceed.  The third
     argument is a new password.  `Make-joint' is to create an
     additional access to the original account using the new password.
     For example, if `peter-acc' is a bank account with password
     `open-sesame', then

          (define paul-acc
            (make-joint peter-acc 'open-sesame 'rosebud))

     will allow one to make transactions on `peter-acc' using the name
     `paul-acc' and the password `rosebud'.  You may wish to modify your
     solution to *note Exercise 3-3:: to accommodate this new feature

     *Exercise 3.8:* When we defined the evaluation model in section
     *note 1-1-3::, we said that the first step in evaluating an
     expression is to evaluate its subexpressions.  But we never
     specified the order in which the subexpressions should be
     evaluated (e.g., left to right or right to left).  When we
     introduce assignment, the order in which the arguments to a
     procedure are evaluated can make a difference to the result.
     Define a simple procedure `f' such that evaluating `(+ (f 0) (f
     1))' will return 0 if the arguments to `+' are evaluated from left
     to right but will return 1 if the arguments are evaluated from
     right to left.

   ---------- Footnotes ----------

   (1) We don't substitute for the occurrence of `balance' in the
`set!' expression because the <NAME> in a `set!' is not evaluated.  If
we did substitute for it, we would get `(set! 25 (- 25 amount))', which
makes no sense.

   (2) The phenomenon of a single computational object being accessed
by more than one name is known as "aliasing".  The joint bank account
situation illustrates a very simple example of an alias.  In section
*note 3-3:: we will see much more complex examples, such as "distinct"
compound data structures that share parts.  Bugs can occur in our
programs if we forget that a change to an object may also, as a "side
effect," change a "different" object because the two "different"
objects are actually a single object appearing under different aliases.
These so-called "side-effect bugs" are so difficult to locate and to
analyze that some people have proposed that programming languages be
designed in such a way as to not allow side effects or aliasing
(Lampson et al. 1981; Morris, Schmidt, and Wadler 1980).

   (3) In view of this, it is ironic that introductory programming is
most often taught in a highly imperative style.  This may be a vestige
of a belief, common throughout the 1960s and 1970s, that programs that
call procedures must inherently be less efficient than programs that
perform assignments.  (Steele (1977) debunks this argument.)
Alternatively it may reflect a view that step-by-step assignment is
easier for beginners to visualize than procedure call.  Whatever the
reason, it often saddles beginning programmers with "should I set this
variable before or after that one" concerns that can complicate
programming and obscure the important ideas.


File: sicp,  Node: 3-2,  Next: 3-3,  Prev: 3-1,  Up: Chapter 3

3.2 The Environment Model of Evaluation
=======================================

When we introduced compound procedures in *note Chapter 1::, we used the
substitution model of evaluation (section *note 1-1-5::) to define what
is meant by applying a procedure to arguments:

   * To apply a compound procedure to arguments, evaluate the body of
     the procedure with each formal parameter replaced by the
     corresponding argument.


   Once we admit assignment into our programming language, such a
definition is no longer adequate.  In particular, section *note 3-1-3::
argued that, in the presence of assignment, a variable can no longer be
considered to be merely a name for a value.  Rather, a variable must
somehow designate a "place" in which values can be stored.  In our new
model of evaluation, these places will be maintained in structures
called "environments".

   An environment is a sequence of "frames".  Each frame is a table
(possibly empty) of "bindings", which associate variable names with
their corresponding values.  (A single frame may contain at most one
binding for any variable.)  Each frame also has a pointer to its environment
"enclosing environment", unless, for the purposes of discussion, the
frame is considered to be "global".  The "value of a variable" with
respect to an environment is the value given by the binding of the
variable in the first frame in the environment that contains a binding
for that variable.  If no frame in the sequence specifies a binding for
the variable, then the variable is said to be "unbound" in the
environment.

     *Figure 3.1:* A simple environment structure.

                     +--------+
                     |      I |
                     | x: 3   |
                     | y: 5   |
                     +--------+
                        ^  ^
                        |  |
                      C |  | D
          +---------+   |  |   +----------+
          |      II |   |  |   |      III |
          | z: 6    +---+  +---+ m: 1     |
          | x: 7    |          | y: 2     |
          +---------+          +----------+

   *note Figure 3-1:: shows a simple environment structure consisting
of three frames, labeled I, II, and III.  In the diagram, A, B, C, and
D are pointers to environments.  C and D point to the same environment.
The variables `z' and `x' are bound in frame II, while `y' and `x' are
bound in frame I.  The value of `x' in environment D is 3.  The value
of `x' with respect to environment B is also 3.  This is determined as
follows: We examine the first frame in the sequence (frame III) and do
not find a binding for `x', so we proceed to the enclosing environment
D and find the binding in frame I.  On the other hand, the value of `x'
in environment A is 7, because the first frame in the sequence (frame
II) contains a binding of `x' to 7.  With respect to environment A, the
binding of `x' to 7 in frame II is said to "shadow" the binding of `x'
to 3 in frame I.

   The environment is crucial to the evaluation process, because it
determines the context in which an expression should be evaluated.
Indeed, one could say that expressions in a programming language do
not, in themselves, have any meaning.  Rather, an expression acquires a
meaning only with respect to some environment in which it is evaluated.
Even the interpretation of an expression as straightforward as `(+ 1
1)' depends on an understanding that one is operating in a context in
which `+' is the symbol for addition.  Thus, in our model of evaluation
we will always speak of evaluating an expression with respect to some
environment.  To describe interactions with the interpreter, we will
suppose that there is a global environment, consisting of a single frame
(with no enclosing environment) that includes values for the symbols
associated with the primitive procedures.  For example, the idea that
`+' is the symbol for addition is captured by saying that the symbol
`+' is bound in the global environment to the primitive addition
procedure.

* Menu:

* 3-2-1::            The Rules for Evaluation
* 3-2-2::            Applying Simple Procedures
* 3-2-3::            Frames as the Repository of Local State
* 3-2-4::            Internal Definitions


File: sicp,  Node: 3-2-1,  Next: 3-2-2,  Prev: 3-2,  Up: 3-2

3.2.1 The Rules for Evaluation
------------------------------

The overall specification of how the interpreter evaluates a combination
remains the same as when we first introduced it in section *note
1-1-3:::

   * To evaluate a combination:


  1. Evaluate the subexpressions of the combination.(1)

  2. Apply the value of the operator subexpression to the values of the
     operand subexpressions.


   The environment model of evaluation replaces the substitution model
in specifying what it means to apply a compound procedure to arguments.

   In the environment model of evaluation, a procedure is always a pair
consisting of some code and a pointer to an environment.  Procedures
are created in one way only: by evaluating a `lambda' expression.  This
produces a procedure whose code is obtained from the text of the
`lambda' expression and whose environment is the environment in which
the `lambda' expression was evaluated to produce the procedure.  For
example, consider the procedure definition

     (define (square x)
       (* x x))

evaluated in the global environment.  The procedure definition syntax
is just syntactic sugar for an underlying implicit `lambda' expression.
It would have been equivalent to have used

     (define square
       (lambda (x) (* x x)))

which evaluates `(lambda (x) (* x x))' and binds `square' to the
resulting value, all in the global environment.

   *note Figure 3-2:: shows the result of evaluating this `define'
expression.  The procedure object is a pair whose code specifies that
the procedure has one formal parameter, namely `x', and a procedure
body `(* x x)'.  The environment part of the procedure is a pointer to
the global environment, since that is the environment in which the
`lambda' expression was evaluated to produce the procedure. A new
binding, which associates the procedure object with the symbol
`square', has been added to the global frame.  In general, `define'
creates definitions by adding bindings to frames.

     *Figure 3.2:* Environment structure produced by evaluating
     `(define (square x) (* x x))' in the global environment.

                     +----------------------+
                     | other variables      |
          global --->|                      |
          env        | square: --+          |
                     +-----------|----------+
                                 |       ^
          (define (square x)     |       |
            (* x x))             V       |
                             .---.---.   |
                             | O | O-+---+
                             `-|-^---'
                               |
                               V
                             parameters: x
                             body: (* x x)

   Now that we have seen how procedures are created, we can describe how
procedures are applied.  The environment model specifies: To apply a
procedure to arguments, create a new environment containing a frame
that binds the parameters to the values of the arguments.  The
enclosing environment of this frame is the environment specified by the
procedure.  Now, within this new environment, evaluate the procedure
body.

   To show how this rule is followed, *note Figure 3-3:: illustrates
the environment structure created by evaluating the expression `(square
5)' in the global environment, where `square' is the procedure
generated in *note Figure 3-2::.  Applying the procedure results in the
creation of a new environment, labeled E1 in the figure, that begins
with a frame in which `x', the formal parameter for the procedure, is
bound to the argument 5.  The pointer leading upward from this frame
shows that the frame's enclosing environment is the global environment.
The global environment is chosen here, because this is the environment
that is indicated as part of the `square' procedure object.  Within E1,
we evaluate the body of the procedure, `(* x x)'.  Since the value of
`x' in E1 is 5, the result is `(* 5 5)', or 25.

     *Figure 3.3:* Environment created by evaluating `(square 5)' in
     the global environment.

                    +------------------------------------+
                    | other variables                    |
          global -->|                                    |
          env       | square: --+                        |
                    +-----------|---------------------+--+
                                |       ^             ^
          (square 5)            |       |             |
                                V       |             |
                            .---.---.   |         +---+--+
                            | O | O-+---+   E1 -->| x: 5 |
                            `-|-^---'             +------+
                              |
                              V
                            parameters: x
                            body: (* x x)

   The environment model of procedure application can be summarized by
two rules:

   * A procedure object is applied to a set of arguments by
     constructing a frame, binding the formal parameters of the
     procedure to the arguments of the call, and then evaluating the
     body of the procedure in the context of the new environment
     constructed.  The new frame has as its enclosing environment the
     environment part of the procedure object being applied.

   * A procedure is created by evaluating a `lambda' expression
     relative to a given environment.  The resulting procedure object
     is a pair consisting of the text of the `lambda' expression and a
     pointer to the environment in which the procedure was created.


   We also specify that defining a symbol using `define' creates a
binding in the current environment frame and assigns to the symbol the
indicated value.(2) Finally, we specify the behavior of `set!', the
operation that forced us to introduce the environment model in the
first place.  Evaluating the expression `(set! <VARIABLE> <VALUE>)' in
some environment locates the binding of the variable in the environment
and changes that binding to indicate the new value.  That is, one finds
the first frame in the environment that contains a binding for the
variable and modifies that frame.  If the variable is unbound in the
environment, then `set!' signals an error.

   These evaluation rules, though considerably more complex than the
substitution model, are still reasonably straightforward.  Moreover,
the evaluation model, though abstract, provides a correct description
of how the interpreter evaluates expressions.  In *note Chapter 4:: we
shall see how this model can serve as a blueprint for implementing a
working interpreter.  The following sections elaborate the details of
the model by analyzing some illustrative programs.

   ---------- Footnotes ----------

   (1) ssignment introduces a subtlety into step 1 of the evaluation
rule.  As shown in *note Exercise 3-8::, the presence of assignment
allows us to write expressions that will produce different values
depending on the order in which the subexpressions in a combination are
evaluated.  Thus, to be precise, we should specify an evaluation order
in step 1 (e.g., left to right or right to left).  However, this order
should always be considered to be an implementation detail, and one
should never write programs that depend on some particular order.  For
instance, a sophisticated compiler might optimize a program by varying
the order in which subexpressions are evaluated.

   (2) If there is already a binding for the variable in the current
frame, then the binding is changed.  This is convenient because it
allows redefinition of symbols; however, it also means that `define'
can be used to change values, and this brings up the issues of
assignment without explicitly using `set!'.  Because of this, some
people prefer redefinitions of existing symbols to signal errors or
warnings.


File: sicp,  Node: 3-2-2,  Next: 3-2-3,  Prev: 3-2-1,  Up: 3-2

3.2.2 Applying Simple Procedures
--------------------------------

When we introduced the substitution model in section *note 1-1-5:: we
showed how the combination `(f 5)' evaluates to 136, given the
following procedure definitions:

     (define (square x)
       (* x x))

     (define (sum-of-squares x y)
       (+ (square x) (square y)))

     (define (f a)
       (sum-of-squares (+ a 1) (* a 2)))

   We can analyze the same example using the environment model.  *note
Figure 3-4:: shows the three procedure objects created by evaluating
the definitions of `f', `square', and `sum-of-squares' in the global
environment.  Each procedure object consists of some code, together
with a pointer to the global environment.

     *Figure 3.4:* Procedure objects in the global frame.

                    +--------------------------------------------+
                    | sum-of-squares:                            |
          global -->| square:                                    |
          env       | f: --+                                     |
                    +------|--------------+--------------+-------+
                           |     ^        |     ^        |     ^
                           |     |        |     |        |     |
                           V     |        V     |        V     |
                       .---.---. |    .---.---. |    .---.---. |
                       | O | O-+-+    | O | O-+-+    | O | O-+-+
                       `-|-^---'      `-|-^---'      `-|-^---'
                         |              |              |
                         V              V              V
             parameters: a          parameters: x  parameters: x, y
             body: (sum-of-squares  body: (* x x)  body: (+ (square x)
                     (+ a 1)                                (square y))
                     (* a 2))

   In *note Figure 3-5:: we see the environment structure created by
evaluating the expression `(f 5)'.  The call to `f' creates a new
environment E1 beginning with a frame in which `a', the formal
parameter of `f', is bound to the argument 5.  In E1, we evaluate the
body of `f':

     (sum-of-squares (+ a 1) (* a 2))

     *Figure 3.5:* Environments created by evaluating `(f 5)' using the
     procedures in *note Figure 3-4::.

                    +-----------------------------------------------------+
          global -->|                                                     |
          env       +-----------------------------------------------------+
                      ^              ^                ^               ^
          (f 5)       |              |                |               |
                  +------+       +-------+        +------+        +-------+
            E1 -->| a: 5 |  E2 ->| x: 6  |  E3 -->| x: 6 |  E4 -->| x: 10 |
                  |      |       | y: 10 |        |      |        |       |
                  +------+       +-------+        +------+        +-------+
             (sum-of-squares   (+ (square x)       (* x x)         (* x x)
               (+ a 1)            (square u))
               (+ a 2))

   To evaluate this combination, we first evaluate the subexpressions.
The first subexpression, `sum-of-squares', has a value that is a
procedure object.  (Notice how this value is found: We first look in
the first frame of E1, which contains no binding for `sum-of-squares'.
Then we proceed to the enclosing environment, i.e. the global
environment, and find the binding shown in *note Figure 3-4::.)  The
other two subexpressions are evaluated by applying the primitive
operations `+' and `*' to evaluate the two combinations `(+ a 1)' and
`(* a 2)' to obtain 6 and 10, respectively.

   Now we apply the procedure object `sum-of-squares' to the arguments
6 and 10.  This results in a new environment E2 in which the formal
parameters `x' and `y' are bound to the arguments.  Within E2 we
evaluate the combination `(+ (square x) (square y))'.  This leads us to
evaluate `(square x)', where `square' is found in the global frame and
`x' is 6.  Once again, we set up a new environment, E3, in which `x' is
bound to 6, and within this we evaluate the body of `square', which is
`(* x x)'.  Also as part of applying `sum-of-squares', we must evaluate
the subexpression `(square y)', where `y' is 10.  This second call to
`square' creates another environment, E4, in which `x', the formal
parameter of `square', is bound to 10.  And within E4 we must evaluate
`(* x x)'.

   The important point to observe is that each call to `square' creates
a new environment containing a binding for `x'.  We can see here how the
different frames serve to keep separate the different local variables
all named `x'.  Notice that each frame created by `square' points to
the global environment, since this is the environment indicated by the
`square' procedure object.

   After the subexpressions are evaluated, the results are returned.
The values generated by the two calls to `square' are added by
`sum-of-squares', and this result is returned by `f'.  Since our focus
here is on the environment structures, we will not dwell on how these
returned values are passed from call to call; however, this is also an
important aspect of the evaluation process, and we will return to it in
detail in *note Chapter 5::.

     *Exercise 3.9:* In section *note 1-2-1:: we used the substitution
     model to analyze two procedures for computing factorials, a
     recursive version

          (define (factorial n)
            (if (= n 1)
                1
                (* n (factorial (- n 1)))))

     and an iterative version

          (define (factorial n)
            (fact-iter 1 1 n))

          (define (fact-iter product counter max-count)
            (if (> counter max-count)
                product
                (fact-iter (* counter product)
                           (+ counter 1)
                           max-count)))

     Show the environment structures created by evaluating `(factorial
     6)' using each version of the `factorial' procedure.(1)

   ---------- Footnotes ----------

   (1) The environment model will not clarify our claim in section
*note 1-2-1:: that the interpreter can execute a procedure such as
`fact-iter' in a constant amount of space using tail recursion.  We
will discuss tail recursion when we deal with the control structure of
the interpreter in section *note 5-4::.


File: sicp,  Node: 3-2-3,  Next: 3-2-4,  Prev: 3-2-2,  Up: 3-2

3.2.3 Frames as the Repository of Local State
---------------------------------------------

We can turn to the environment model to see how procedures and
assignment can be used to represent objects with local state.  As an
example, consider the "withdrawal processor" from section *note 3-1-1::
created by calling the procedure

     (define (make-withdraw balance)
       (lambda (amount)
         (if (>= balance amount)
             (begin (set! balance (- balance amount))
                    balance)
             "Insufficient funds")))

   Let us describe the evaluation of

     (define W1 (make-withdraw 100))

followed by

     (W1 50)
     50

   *note Figure 3-6:: shows the result of defining the `make-withdraw'
procedure in the global environment.  This produces a procedure object
that contains a pointer to the global environment.  So far, this is no
different from the examples we have already seen, except that the body
of the procedure is itself a `lambda' expression.

     *Figure 3.6:* Result of defining `make-withdraw' in the global
     environment.

                    +---------------------------+
          global -->| make-withdraw: --+        |
          env       +------------------|--------+
                                       |      ^
                                       V      |
                                   .---.---.  |
                                   | O | O-+--+
                                   `-|-^---'
                                     |
                                     V
                   parameters: balance
                   body: (lambda (amount)
                           (if (>= balance amount)
                               (begin (set! balance
                                            (- balance amount))
                                      balance)
                               "Insufficient funds"))

   The interesting part of the computation happens when we apply the
procedure `make-withdraw' to an argument:

     (define W1 (make-withdraw 100))

   We begin, as usual, by setting up an environment E1 in which the
formal parameter `balance' is bound to the argument 100.  Within this
environment, we evaluate the body of `make-withdraw', namely the
`lambda' expression.  This constructs a new procedure object, whose code
is as specified by the `lambda' and whose environment is E1, the
environment in which the `lambda' was evaluated to produce the
procedure.  The resulting procedure object is the value returned by the
call to `make-withdraw'.  This is bound to `W1' in the global
environment, since the `define' itself is being evaluated in the global
environment.  *note Figure 3-7:: shows the resulting environment
structure.

     *Figure 3.7:* Result of evaluating `(define W1 (make-withdraw
     100))'.

                    +-----------------------------------------------+
                    | make-withdraw: -----------------------+       |
          global -->|                                       |       |
                    | W1: --+                               |       |
                    +-------|-------------------------------|-------+
                            |                ^              |     ^
                            |                |              V     |
                            |        +-------+------+   .---.---. |
                            |  E1 -->| balance: 100 |   | O | O-+-+
                            |        +--------------+   `-|-^---'
                            V                ^            |
                        .---.---.            |            V
                      +-+-O | O-+------------+    parameters: balance
                      | `---^---'                 body: ...
                      V
              parameters: amount
              body: (if (>= balance amount)
                        (begin (set! balance (- balance amount))
                               balance)
                        "Insufficient funds")

   Now we can analyze what happens when `W1' is applied to an argument:

     (W1 50)
     50

   We begin by constructing a frame in which `amount', the formal
parameter of `W1', is bound to the argument 50.  The crucial point to
observe is that this frame has as its enclosing environment not the
global environment, but rather the environment E1, because this is the
environment that is specified by the `W1' procedure object.  Within
this new environment, we evaluate the body of the procedure:

     (if (>= balance amount)
         (begin (set! balance (- balance amount))
                balance)
         "Insufficient funds")

   The resulting environment structure is shown in *note Figure 3-8::.
The expression being evaluated references both `amount' and `balance'.
`Amount' will be found in the first frame in the environment, while
`balance' will be found by following the enclosing-environment pointer
to E1.

     *Figure 3.8:* Environments created by applying the procedure
     object `W1'.

                    +---------------------------------------------------+
                    | make-withdraw: ...                                |
          global -->|                                                   |
          env       | W1: --+                                           |
                    +-------|-------------------------------------------+
                            |               ^
                            |               |
                            |       +-------+------+ Here is the balance
                            | E1 -->| balance: 100 | that will be changed
                            |       +--------------+ by the set!.
                            V               ^   ^
                        .---.---.           |   +----+
                        | O | O-+-----------+        |
                        `-|-^---'             +------+-----+
                          |                   | amount: 50 |
                          V                   +------------+
                parameters: amount   (if (>= balance amount)
                body: ...                (begin (set! balance
                                                      (- balance amount))
                                                balance)
                                         "Insufficient funds")

   When the `set!' is executed, the binding of `balance' in E1 is
changed.  At the completion of the call to `W1', `balance' is 50, and
the frame that contains `balance' is still pointed to by the procedure
object `W1'.  The frame that binds `amount' (in which we executed the
code that changed `balance') is no longer relevant, since the procedure
call that constructed it has terminated, and there are no pointers to
that frame from other parts of the environment.  The next time `W1' is
called, this will build a new frame that binds `amount' and whose
enclosing environment is E1.  We see that E1 serves as the "place" that
holds the local state variable for the procedure object `W1'.  *note
Figure 3-9:: shows the situation after the call to `W1'.

     *Figure 3.9:* Environments after the call to `W1'.

                     +------------------------------------+
                     | make-withdraw: ...                 |
          global --->|                                    |
          env        | W1: --+                            |
                     +-------|----------------------------+
                             |                   ^
                             |                   |
                             |            +------+------+
                             |     E1 --->| balance: 50 |
                             |            +-------------+
                             V                   ^
                         .---.---.               |
                         | O | O-+---------------+
                         `-|-^---'
                           |
                           V
                    parameters: amount
                    body: ...

   Observe what happens when we create a second "withdraw" object by
making another call to `make-withdraw':

     (define W2 (make-withdraw 100))

   This produces the environment structure of *note Figure 3-10::,
which shows that `W2' is a procedure object, that is, a pair with some
code and an environment.  The environment E2 for `W2' was created by
the call to `make-withdraw'.  It contains a frame with its own local
binding for `balance'.  On the other hand, `W1' and `W2' have the same
code: the code specified by the `lambda' expression in the body of
`make-withdraw'.(1) We see here why `W1' and `W2' behave as independent
objects.  Calls to `W1' reference the state variable `balance' stored
in E1, whereas calls to `W2' reference the `balance' stored in E2.
Thus, changes to the local state of one object do not affect the other
object.

     *Figure 3.10:* Using `(define W2 (make-withdraw 100))' to create a
     second object.

                   +-------------------------------------------------+
                   | make-withdraw: ...                              |
          global ->| W2: ---------------------------+                |
          env      | W1: --+                        |                |
                   +-------|------------------------|----------------+
                           |              ^         |              ^
                           |              |         |              |
                           |       +------+------+  |       +------+-------+
                           |  E1 ->| balance: 50 |  |  E2 ->| balance: 100 |
                           |       +-------------+  |       +--------------+
                           V              ^         V              ^
                       .---.---.          |     .---.---.          |
                       | O | O-+----------+     | O | O-+----------+
                       `-|-^---'                `-|-^---'
                         | +----------------------+
                         V V
                  parameters: amount
                  body: ...

     *Exercise 3.10:* In the `make-withdraw' procedure, the local
     variable `balance' is created as a parameter of `make-withdraw'.
     We could also create the local state variable explicitly, using
     `let', as follows:

          (define (make-withdraw initial-amount)
            (let ((balance initial-amount))
              (lambda (amount)
                (if (>= balance amount)
                    (begin (set! balance (- balance amount))
                           balance)
                    "Insufficient funds"))))

     Recall from section *note 1-3-2:: that `let' is simply syntactic
     sugar for a procedure call:

          (let ((<VAR> <EXP>)) <BODY>)

     is interpreted as an alternate syntax for

          ((lambda (<VAR>) <BODY>) <EXP>)

     Use the environment model to analyze this alternate version of
     `make-withdraw', drawing figures like the ones above to illustrate
     the interactions

          (define W1 (make-withdraw 100))

          (W1 50)

          (define W2 (make-withdraw 100))

     Show that the two versions of `make-withdraw' create objects with
     the same behavior.  How do the environment structures differ for
     the two versions?

   ---------- Footnotes ----------

   (1) Whether `W1' and `W2' share the same physical code stored in the
computer, or whether they each keep a copy of the code, is a detail of
the implementation.  For the interpreter we implement in *note Chapter
4::, the code is in fact shared.


File: sicp,  Node: 3-2-4,  Prev: 3-2-3,  Up: 3-2

3.2.4 Internal Definitions
--------------------------

Section *note 1-1-8:: introduced the idea that procedures can have
internal definitions, thus leading to a block structure as in the
following procedure to compute square roots:

     (define (sqrt x)
       (define (good-enough? guess)
         (< (abs (- (square guess) x)) 0.001))
       (define (improve guess)
         (average guess (/ x guess)))
       (define (sqrt-iter guess)
         (if (good-enough? guess)
             guess
             (sqrt-iter (improve guess))))
       (sqrt-iter 1.0))

   Now we can use the environment model to see why these internal
definitions behave as desired.  *note Figure 3-11:: shows the point in
the evaluation of the expression `(sqrt 2)' where the internal
procedure `good-enough?' has been called for the first time with
`guess' equal to 1.

     *Figure 3.11:* `Sqrt' procedure with internal definitions.

                    +--------------------------------------------------+
          global -->| sqrt: --+                                        |
          env       |         |                                        |
                    +---------|----------------------------------------+
                              V       ^                   ^
                          .---.---.   |                   |
               +----------+-O | O-+---+        +----------+------------+
               |          `---^---'            | x: 2                  |
               V                         E1 -->| good-enough?: -+      |
          parameters: x                        | improve: ...   |      |
          body: (define good-enough? ...)      | sqrt-iter: ... |      |
                (define improve ...)           +----------------|------+
                (define sqrt-iter ...)          ^  ^            |     ^
                (sqrt-iter 1.0)                 |  |            V     |
                                      +---------++ |        .---.---. |
                                E2 -->| guess: 1 | |        | O | O-+-+
                                      +----------+ |        `-|-^---'
                                call to sqrt-iter  |          |
                                                   |          V
                                         +---------++    parameters: guess
                                   E3 -->| guess: 1 |    body: (< (abs ...)
                                         +----------+             ...)
                                   call to good-enough?

   Observe the structure of the environment.  `Sqrt' is a symbol in the
global environment that is bound to a procedure object whose associated
environment is the global environment.  When `sqrt' was called, a new
environment E1 was formed, subordinate to the global environment, in
which the parameter `x' is bound to 2.  The body of `sqrt' was then
evaluated in E1.  Since the first expression in the body of `sqrt' is

     (define (good-enough? guess)
       (< (abs (- (square guess) x)) 0.001))

evaluating this expression defined the procedure `good-enough?'  in the
environment E1.  To be more precise, the symbol `good-enough?' was added
to the first frame of E1, bound to a procedure object whose associated
environment is E1.  Similarly, `improve' and `sqrt-iter' were defined
as procedures in E1.  For conciseness, *note Figure 3-11:: shows only
the procedure object for `good-enough?'.

   After the local procedures were defined, the expression `(sqrt-iter
1.0)' was evaluated, still in environment E1.  So the procedure object
bound to `sqrt-iter' in E1 was called with 1 as an argument.  This
created an environment E2 in which `guess', the parameter of
`sqrt-iter', is bound to 1.  `Sqrt-iter' in turn called `good-enough?'
with the value of `guess' (from E2) as the argument for `good-enough?'.
This set up another environment, E3, in which `guess' (the parameter of
`good-enough?') is bound to 1.  Although `sqrt-iter' and `good-enough?'
both have a parameter named `guess', these are two distinct local
variables located in different frames.  Also, E2 and E3 both have E1 as
their enclosing environment, because the `sqrt-iter' and `good-enough?'
procedures both have E1 as their environment part.  One consequence of
this is that the symbol `x' that appears in the body of `good-enough?'
will reference the binding of `x' that appears in E1, namely the value
of `x' with which the original `sqrt' procedure was called.

   The environment model thus explains the two key properties that make
local procedure definitions a useful technique for modularizing
programs:

   * The names of the local procedures do not interfere with names
     external to the enclosing procedure, because the local procedure
     names will be bound in the frame that the procedure creates when
     it is run, rather than being bound in the global environment.

   * The local procedures can access the arguments of the enclosing
     procedure, simply by using parameter names as free variables.
     This is because the body of the local procedure is evaluated in an
     environment that is subordinate to the evaluation environment for
     the enclosing procedure.


     *Exercise 3.11:* In section *note 3-2-3:: we saw how the
     environment model described the behavior of procedures with local
     state.  Now we have seen how internal definitions work.  A typical
     message-passing procedure contains both of these aspects.
     Consider the bank account procedure of section *note 3-1-1:::

          (define (make-account balance)
            (define (withdraw amount)
              (if (>= balance amount)
                  (begin (set! balance (- balance amount))
                         balance)
                  "Insufficient funds"))
            (define (deposit amount)
              (set! balance (+ balance amount))
              balance)
            (define (dispatch m)
              (cond ((eq? m 'withdraw) withdraw)
                    ((eq? m 'deposit) deposit)
                    (else (error "Unknown request -- MAKE-ACCOUNT"
                                 m))))
            dispatch)

     Show the environment structure generated by the sequence of
     interactions

          (define acc (make-account 50))

          ((acc 'deposit) 40)
          90

          ((acc 'withdraw) 60)
          30

     Where is the local state for `acc' kept?  Suppose we define another
     account

          (define acc2 (make-account 100))

     How are the local states for the two accounts kept distinct?
     Which parts of the environment structure are shared between `acc'
     and `acc2'?


File: sicp,  Node: 3-3,  Next: 3-4,  Prev: 3-2,  Up: Chapter 3

3.3 Modeling with Mutable Data
==============================

Chapter 2 dealt with compound data as a means for constructing
computational objects that have several parts, in order to model
real-world objects that have several aspects.  In that chapter we
introduced the discipline of data abstraction, according to which data
structures are specified in terms of constructors, which create data
objects, and selectors, which access the parts of compound data
objects.  But we now know that there is another aspect of data that
*note Chapter 2:: did not address.  The desire to model systems
composed of objects that have changing state leads us to the need to
modify compound data objects, as well as to construct and select from
them.  In order to model compound objects with changing state, we will
design data abstractions to include, in addition to selectors and
constructors, operations called "mutators", which modify data objects.
For instance, modeling a banking system requires us to change account
balances.  Thus, a data structure for representing bank accounts might
admit an operation

     (set-balance! <ACCOUNT> <NEW-VALUE>)

that changes the balance of the designated account to the designated
new value.  Data objects for which mutators are defined are known as objects
"mutable data objects".

   *note Chapter 2:: introduced pairs as a general-purpose "glue" for
synthesizing compound data.  We begin this section by defining basic
mutators for pairs, so that pairs can serve as building blocks for
constructing mutable data objects.  These mutators greatly enhance the
representational power of pairs, enabling us to build data structures
other than the sequences and trees that we worked with in section *note
2-2::.  We also present some examples of simulations in which complex
systems are modeled as collections of objects with local state.

* Menu:

* 3-3-1::            Mutable List Structure
* 3-3-2::            Representing Queues
* 3-3-3::            Representing Tables
* 3-3-4::            A Simulator for Digital Circuits
* 3-3-5::            Propagation of Constraints


File: sicp,  Node: 3-3-1,  Next: 3-3-2,  Prev: 3-3,  Up: 3-3

3.3.1 Mutable List Structure
----------------------------

The basic operations on pairs--`cons', `car', and `cdr'--can be used to
construct list structure and to select parts from list structure, but
they are incapable of modifying list structure.  The same is true of the
list operations we have used so far, such as `append' and `list', since
these can be defined in terms of `cons', `car', and `cdr'.  To modify
list structures we need new operations.

     *Figure 3.12:* Lists `x': `((a b) c d)' and `y': `(e f)'.

               +---+---+     +---+---+     +---+---+
          x -->| * | *-+---->| * | *-+---->| * | / |
               +-|-+---+     +-|-+---+     +-|-+---+
                 |             V             V
                 |           +---+         +---+
                 |           | c |         | d |
                 |           +---+         +---+
                 |           +---+---+     +---+---+
                 +---------->| * | *-+---->| * | / |
                             +-|-+---+     +-|-+---+
                               V             V
                             +---+         +---+
                             | a |         | b |
                             +---+         +---+
                             +---+---+     +---+---+
                        y -->| * | *-+---->| * | / |
                             +-|-+---+     +-|-+---+
                               V             V
                             +---+         +---+
                             | e |         | f |
                             +---+         +---+

     *Figure 3.13:* Effect of `(set-car! x y)' on the lists in *note
     Figure 3-12::.

               +---+---+     +---+---+     +---+---+
          x -->| * | *-+---->| * | *-+---->| * | / |
               +-|-+---+     +-|-+---+     +-|-+---+
                 |             V             V
                 |           +---+         +---+
                 |           | c |         | d |
                 |           +---+         +---+
                 |           +---+---+     +---+---+
                 |           | * | *-+---->| * | / |
                 |           +-|-+---+     +-|-+---+
                 |             V             V
                 |           +---+         +---+
                 |           | a |         | b |
                 |           +---+         +---+
                 +---------->+---+---+     +---+---+
                             | * | *-+---->| * | / |
                        y -->+-|-+---+     +-|-+---+
                               V             V
                             +---+         +---+
                             | e |         | f |
                             +---+         +---+

     *Figure 3.14:* Effect of `(define z (cons y (cdr x)))' on the
     lists in *note Figure 3-12::.

               +---+---+     +---+---+     +---+---+
          x -->| * | *-+---->| * | *-+---->| * | / |
               +-|-+---+ +-->+-|-+---+     +-|-+---+
                 |       |     V             V
                 |       |   +---+         +---+
                 |       |   | c |         | d |
                 |       |   +---+         +---+
                 |       |   +---+---+     +---+---+
                 +-------+-->| * | *-+---->| * | / |
                         |   +-|-+---+     +-|-+---+
               +---+---+ |     V             V
          z -->| * | *-+-+   +---+         +---+
               +-|-+---+     | a |         | b |
                 |           +---+         +---+
                 +---------->+---+---+     +---+---+
                             | * | *-+---->| * | / |
                        y -->+-|-+---+     +-|-+---+
                               V             V
                             +---+         +---+
                             | e |         | f |
                             +---+         +---+

     *Figure 3.15:* Effect of `(set-cdr! x y)' on the lists in *note
     Figure 3-12::.

               +---+---+     +---+---+     +---+---+
          x -->| * | * |     | * | *-+---->| * | / |
               +-|-+-|-+     +-|-+---+     +-|-+---+
                 |   |         V             V
                 |   |       +---+         +---+
                 |   |       | c |         | d |
                 |   |       +---+         +---+
                 |   |       +---+---+     +---+---+
                 +---+------>| * | *-+---->| * | / |
                     |       +-|-+---+     +-|-+---+
                     |         V             V
                     |       +---+         +---+
                     |       | a |         | b |
                     |       +---+         +---+
                     +------>+---+---+     +---+---+
                             | * | *-+---->| * | / |
                        y -->+-|-+---+     +-|-+---+
                               V             V
                             +---+         +---+
                             | e |         | f |
                             +---+         +---+

   The primitive mutators for pairs are `set-car!' and `set-cdr!'.
`Set-car!' takes two arguments, the first of which must be a pair.  It
modifies this pair, replacing the `car' pointer by a pointer to the
second argument of `set-car!'.(1)

   As an example, suppose that `x' is bound to the list `((a b) c d)'
and `y' to the list `(e f)' as illustrated in *note Figure 3-12::.
Evaluating the expression ` (set-car!  x y)' modifies the pair to which
`x' is bound, replacing its `car' by the value of `y'.  The result of
the operation is shown in *note Figure 3-13::.  The structure `x' has
been modified and would now be printed as `((e f) c d)'.  The pairs
representing the list `(a b)', identified by the pointer that was
replaced, are now detached from the original structure.(2)

   Compare *note Figure 3-13:: with *note Figure 3-14::, which
illustrates the result of executing `(define z (cons y (cdr x)))' with
`x' and `y' bound to the original lists of *note Figure 3-12::.  The
variable `z' is now bound to a new pair created by the `cons'
operation; the list to which `x' is bound is unchanged.

   The `set-cdr!' operation is similar to `set-car!'.  The only
difference is that the `cdr' pointer of the pair, rather than the `car'
pointer, is replaced.  The effect of executing `(set-cdr! x y)' on the
lists of *note Figure 3-12:: is shown in *note Figure 3-15::.  Here the
`cdr' pointer of `x' has been replaced by the pointer to `(e f)'.
Also, the list `(c d)', which used to be the `cdr' of `x', is now
detached from the structure.

   `Cons' builds new list structure by creating new pairs, while
`set-car!' and `set-cdr!' modify existing pairs.  Indeed, we could
implement `cons' in terms of the two mutators, together with a procedure
`get-new-pair', which returns a new pair that is not part of any
existing list structure.  We obtain the new pair, set its `car' and
`cdr' pointers to the designated objects, and return the new pair as
the result of the `cons'.(3)

     (define (cons x y)
       (let ((new (get-new-pair)))
         (set-car! new x)
         (set-cdr! new y)
         new))

     *Exercise 3.12:* The following procedure for appending lists was
     introduced in section *note 2-2-1:::

          (define (append x y)
            (if (null? x)
                y
                (cons (car x) (append (cdr x) y))))

     `Append' forms a new list by successively `cons'ing the elements of
     `x' onto `y'.  The procedure `append!' is similar to `append', but
     it is a mutator rather than a constructor.  It appends the lists
     by splicing them together, modifying the final pair of `x' so that
     its `cdr' is now `y'.  (It is an error to call `append!' with an
     empty `x'.)

          (define (append! x y)
            (set-cdr! (last-pair x) y)
            x)

     Here `last-pair' is a procedure that returns the last pair in its
     argument:

          (define (last-pair x)
            (if (null? (cdr x))
                x
                (last-pair (cdr x))))

     Consider the interaction

          (define x (list 'a 'b))

          (define y (list 'c 'd))

          (define z (append x y))

          z
          (a b c d)

          (cdr x)
          <RESPONSE>

          (define w (append! x y))

          w
          (a b c d)

          (cdr x)
          <RESPONSE>

     What are the missing <RESPONSE>s?  Draw box-and-pointer diagrams to
     explain your answer.

     *Exercise 3.13:* Consider the following `make-cycle' procedure,
     which uses the `last-pair' procedure defined in *note Exercise
     3-12:::

          (define (make-cycle x)
            (set-cdr! (last-pair x) x)
            x)

     Draw a box-and-pointer diagram that shows the structure `z'
     created by

          (define z (make-cycle (list 'a 'b 'c)))

     What happens if we try to compute `(last-pair z)'?

     *Exercise 3.14:* The following procedure is quite useful, although
     obscure:

          (define (mystery x)
            (define (loop x y)
              (if (null? x)
                  y
                  (let ((temp (cdr x)))
                    (set-cdr! x y)
                    (loop temp x))))
            (loop x '()))

     `Loop' uses the "temporary" variable `temp' to hold the old value
     of the `cdr' of `x', since the `set-cdr!'  on the next line
     destroys the `cdr'.  Explain what `mystery' does in general.
     Suppose `v' is defined by `(define v (list 'a 'b 'c 'd))'. Draw the
     box-and-pointer diagram that represents the list to which `v' is
     bound.  Suppose that we now evaluate `(define w (mystery v))'. Draw
     box-and-pointer diagrams that show the structures `v' and `w' after
     evaluating this expression.  What would be printed as the values
     of `v' and `w'?

Sharing and identity
....................

We mentioned in section *note 3-1-3:: the theoretical issues of
"sameness" and "change" raised by the introduction of assignment.
These issues arise in practice when individual pairs are "shared" among
different data objects.  For example, consider the structure formed by

     (define x (list 'a 'b))
     (define z1 (cons x x))

   As shown in *note Figure 3-16::, `z1' is a pair whose `car' and
`cdr' both point to the same pair `x'.  This sharing of `x' by the
`car' and `cdr' of `z1' is a consequence of the straightforward way in
which `cons' is implemented.  In general, using `cons' to construct
lists will result in an interlinked structure of pairs in which many
individual pairs are shared by many different structures.

     *Figure 3.16:* The list `z1' formed by `(cons x x)'.

                +---+---+
          z1 -->| * | * |
                +-|-+-|-+
                  V   V
                +---+---+     +---+---+
           x -->| * | *-+---->| * | / |
                +-|-+---+     +-|-+---+
                  V             V
                +---+         +---+
                | a |         | b |
                +---+         +---+

     *Figure 3.17:* The list `z2' formed by `(cons (list 'a 'b) (list
     'a 'b))'.

                +---+---+     +---+---+     +---+---+
          z2 -->| * | *-+---->| * | *-+---->| * | / |
                +-|-+---+     +-|-+---+     +-|-+---+
                  |             V             V
                  |           +---+         +---+
                  |           | a |         | b |
                  |           +---+         +---+
                  |             ^             ^
                  |             |             |
                  |           +-|-+---+     +-|-+---+
                  +---------->| * | *-+---->| * | / |
                              +---+---+     +---+---+

   In contrast to *note Figure 3-16::, *note Figure 3-17:: shows the
structure created by

     (define z2 (cons (list 'a 'b) (list 'a 'b)))

   In this structure, the pairs in the two `(a b)' lists are distinct,
although the actual symbols are shared.(4)

   When thought of as a list, `z1' and `z2' both represent "the same"
list, `((a b) a b)'.  In general, sharing is completely undetectable if
we operate on lists using only `cons', `car', and `cdr'.  However, if
we allow mutators on list structure, sharing becomes significant.  As an
example of the difference that sharing can make, consider the following
procedure, which modifies the `car' of the structure to which it is
applied:

     (define (set-to-wow! x)
       (set-car! (car x) 'wow)
       x)

   Even though `z1' and `z2' are "the same" structure, applying
`set-to-wow!' to them yields different results.  With `z1', altering
the `car' also changes the `cdr', because in `z1' the `car' and the
`cdr' are the same pair.  With `z2', the `car' and `cdr' are distinct,
so `set-to-wow!' modifies only the `car':

     z1
     ((a b) a b)

     (set-to-wow! z1)
     ((wow b) wow b)

     z2
     ((a b) a b)

     (set-to-wow! z2)
     ((wow b) a b)

   One way to detect sharing in list structures is to use the predicate
`eq?', which we introduced in section *note 2-3-1:: as a way to test
whether two symbols are equal.  More generally, `(eq?  x y)' tests
whether `x' and `y' are the same object (that is, whether `x' and `y'
are equal as pointers).  Thus, with `z1' and `z2' as defined in figures
*note Figure 3-16:: and *note Figure 3-17::, `(eq?  (car z1) (cdr z1))'
is true and `(eq? (car z2) (cdr z2))' is false.

   As will be seen in the following sections, we can exploit sharing to
greatly extend the repertoire of data structures that can be
represented by pairs.  On the other hand, sharing can also be
dangerous, since modifications made to structures will also affect
other structures that happen to share the modified parts.  The mutation
operations `set-car!' and `set-cdr!' should be used with care; unless
we have a good understanding of how our data objects are shared,
mutation can have unanticipated results.(5)

     *Exercise 3.15:* Draw box-and-pointer diagrams to explain the
     effect of `set-to-wow!' on the structures `z1' and `z2' above.

     *Exercise 3.16:* Ben Bitdiddle decides to write a procedure to
     count the number of pairs in any list structure.  "It's easy," he
     reasons.  "The number of pairs in any structure is the number in
     the `car' plus the number in the `cdr' plus one more to count the
     current pair."  So Ben writes the following procedure:

          (define (count-pairs x)
            (if (not (pair? x))
                0
                (+ (count-pairs (car x))
                   (count-pairs (cdr x))
                   1)))

     Show that this procedure is not correct.  In particular, draw
     box-and-pointer diagrams representing list structures made up of
     exactly three pairs for which Ben's procedure would return 3;
     return 4; return 7; never return at all.

     *Exercise 3.17:* Devise a correct version of the `count-pairs'
     procedure of *note Exercise 3-16:: that returns the number of
     distinct pairs in any structure.  (Hint: Traverse the structure,
     maintaining an auxiliary data structure that is used to keep track
     of which pairs have already been counted.)

     *Exercise 3.18:* Write a procedure that examines a list and
     determines whether it contains a cycle, that is, whether a program
     that tried to find the end of the list by taking successive `cdr's
     would go into an infinite loop.  *note Exercise 3-13:: constructed
     such lists.

     *Exercise 3.19:* Redo *note Exercise 3-18:: using an algorithm
     that takes only a constant amount of space.  (This requires a very
     clever idea.)

Mutation is just assignment
...........................

When we introduced compound data, we observed in section *note 2-1-3::
that pairs can be represented purely in terms of procedures:

     (define (cons x y)
       (define (dispatch m)
         (cond ((eq? m 'car) x)
               ((eq? m 'cdr) y)
               (else (error "Undefined operation -- CONS" m))))
       dispatch)

     (define (car z) (z 'car))

     (define (cdr z) (z 'cdr))

   The same observation is true for mutable data.  We can implement
mutable data objects as procedures using assignment and local state.
For instance, we can extend the above pair implementation to handle
`set-car!' and `set-cdr!' in a manner analogous to the way we
implemented bank accounts using `make-account' in section *note 3-1-1:::

     (define (cons x y)
       (define (set-x! v) (set! x v))
       (define (set-y! v) (set! y v))
       (define (dispatch m)
         (cond ((eq? m 'car) x)
               ((eq? m 'cdr) y)
               ((eq? m 'set-car!) set-x!)
               ((eq? m 'set-cdr!) set-y!)
               (else (error "Undefined operation -- CONS" m))))
       dispatch)

     (define (car z) (z 'car))

     (define (cdr z) (z 'cdr))

     (define (set-car! z new-value)
       ((z 'set-car!) new-value)
       z)

     (define (set-cdr! z new-value)
       ((z 'set-cdr!) new-value)
       z)

   Assignment is all that is needed, theoretically, to account for the
behavior of mutable data.  As soon as we admit `set!' to our language,
we raise all the issues, not only of assignment, but of mutable data in
general.(6)

     *Exercise 3.20:* Draw environment diagrams to illustrate the
     evaluation of the sequence of expressions

          (define x (cons 1 2))
          (define z (cons x x))
          (set-car! (cdr z) 17)

          (car x)
          17

     using the procedural implementation of pairs given above.  (Compare
     *note Exercise 3-11::.)

   ---------- Footnotes ----------

   (1) `Set-car!' and `set-cdr!' return implementation-dependent
values.  Like `set!', they should be used only for their effect.

   (2) We see from this that mutation operations on lists can create
"garbage" that is not part of any accessible structure.  We will see in
section *note 5-3-2:: that Lisp memory-management systems include a "garbage
collector", which identifies and recycles the memory space used by
unneeded pairs.

   (3) `Get-new-pair' is one of the operations that must be implemented
as part of the memory management required by a Lisp implementation.  We
will discuss this in section *note 5-3-1::.

   (4) The two pairs are distinct because each call to `cons' returns a
new pair.  The symbols are shared; in Scheme there is a unique symbol
with any given name.  Since Scheme provides no way to mutate a symbol,
this sharing is undetectable.  Note also that the sharing is what
enables us to compare symbols using `eq?', which simply checks equality
of pointers.

   (5) The subtleties of dealing with sharing of mutable data objects
reflect the underlying issues of "sameness" and "change" that were
raised in section *note 3-1-3::.  We mentioned there that admitting
change to our language requires that a compound object must have an
"identity" that is something different from the pieces from which it is
composed.  In Lisp, we consider this "identity" to be the quality that
is tested by `eq?', i.e., by equality of pointers.  Since in most Lisp
implementations a pointer is essentially a memory address, we are
"solving the problem" of defining the identity of objects by
stipulating that a data object "itself" is the information stored in
some particular set of memory locations in the computer.  This suffices
for simple Lisp programs, but is hardly a general way to resolve the
issue of "sameness" in computational models.

   (6) On the other hand, from the viewpoint of implementation,
assignment requires us to modify the environment, which is itself a
mutable data structure.  Thus, assignment and mutation are equipotent:
Each can be implemented in terms of the other.

